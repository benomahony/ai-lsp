{"system":"You are an AI code analyzer that provides semantic insights that traditional LSPs cannot detect.\n\nONLY flag issues that require deep semantic understanding:\n- Logic errors in algorithms or business logic\n- Subtle race conditions or concurrency issues  \n- Architectural problems and design pattern violations\n- Security vulnerabilities requiring context understanding\n- Performance anti-patterns that need semantic analysis\n- Complex data flow issues\n- Domain-specific best practice violations\n- Accessibility issues requiring UX understanding\n\nDO NOT flag issues that normal LSPs handle:\n- Syntax errors\n- Basic type errors  \n- Undefined variables\n- Import issues\n- Basic formatting problems\n- Simple linting rules\n\nFor each issue, provide:\n- The exact issue_snippet that has the problem (ONLY the problematic token\/value, e.g. just \"python\" not 'command = \"python\"')\n- Clear explanation of WHY this needs human attention in the message\n- Use severity: \"info\" for suggestions, \"warning\" for concerns, \"error\" for serious logic issues\n- When possible, provide suggested_fixes with:\n  - target_snippet: the exact code to replace (same as issue_snippet usually)\n  - replacement_snippet: the replacement code\n  - title: clear description of the fix\n\nFocus on insights that require understanding code intent and context. Keep issue_snippet to the absolute minimum - just the problematic token.","user":"Analyze this python code for issues:\n\n```python\nimport asyncio\nimport os\nfrom pathlib import Path\nfrom typing import Any, Literal\nfrom importlib.metadata import version\nimport logfire\n\n# pyrefly: ignore [missing-import]\nfrom lsprotocol.types import (\n    TEXT_DOCUMENT_CODE_ACTION,\n    TEXT_DOCUMENT_DID_CHANGE,\n    TEXT_DOCUMENT_DID_OPEN,\n    TEXT_DOCUMENT_DID_SAVE,\n    CodeAction,\n    CodeActionKind,\n    CodeActionOptions,\n    CodeActionParams,\n    Command,\n    Diagnostic,\n    DiagnosticSeverity,\n    DidChangeTextDocumentParams,\n    DidOpenTextDocumentParams,\n    DidSaveTextDocumentParams,\n    Position,\n    Range,\n    TextEdit,\n    WorkspaceEdit,\n)\nfrom pydantic import BaseModel, Field\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models import KnownModelName\nfrom pydantic_settings import BaseSettings\n\n# pyrefly: ignore [missing-import]\nfrom pygls.server import LanguageServer\n\n\nclass Settings(BaseSettings):\n    ai_lsp_model: KnownModelName = Field(default=\"google-gla:gemini-2.5-flash\")\n    debounce_ms: int = Field(default=1000)\n    max_cache_size: int = Field(default=50)\n    configure_logfire: bool = Field(default=True)\n    otel_exporter_otlp_endpoint: str = Field(default=\"http:\/\/localhost:4318\")\n\n\nsettings = Settings()\n\n\nos.environ[\"OTEL_EXPORTER_OTLP_ENDPOINT\"] = settings.otel_exporter_otlp_endpoint\n\nif settings.configure_logfire:\n    logfire.configure(send_to_logfire=False, service_name=\"ai-lsp\")\n    logfire.instrument_pydantic_ai()\n    logfire.instrument_httpx(capture_all=True)\n\n\nclass SuggestedFix(BaseModel):\n    title: str\n    target_snippet: str\n    replacement_snippet: str\n\n\nclass CodeIssue(BaseModel):\n    issue_snippet: str\n    severity: Literal[\"error\", \"warning\", \"info\", \"hint\"]\n    message: str\n    suggested_fixes: list[SuggestedFix] | None = None\n\n\nclass DiagnosticResult(BaseModel):\n    issues: list[CodeIssue]\n\n\nclass AILanguageServer(LanguageServer):\n    def __init__(self):\n        super().__init__(\"ai-lsp\", version(\"ai-lsp\"))\n        logfire.info(\"Initializing AI Language Server\")\n        self._pending_tasks: dict[str, asyncio.Task[Any]] = {}\n        self._analysis_locks: dict[str, asyncio.Lock] = {}\n\n        self.agent: Agent[DiagnosticResult, Any] = Agent(\n            model=settings.ai_lsp_model,\n            output_type=DiagnosticResult,\n            system_prompt=\"\"\"You are an AI code analyzer that provides semantic insights that traditional LSPs cannot detect.\n\nONLY flag issues that require deep semantic understanding:\n- Logic errors in algorithms or business logic\n- Subtle race conditions or concurrency issues  \n- Architectural problems and design pattern violations\n- Security vulnerabilities requiring context understanding\n- Performance anti-patterns that need semantic analysis\n- Complex data flow issues\n- Domain-specific best practice violations\n- Accessibility issues requiring UX understanding\n\nDO NOT flag issues that normal LSPs handle:\n- Syntax errors\n- Basic type errors  \n- Undefined variables\n- Import issues\n- Basic formatting problems\n- Simple linting rules\n\nFor each issue, provide:\n- The exact issue_snippet that has the problem (ONLY the problematic token\/value, e.g. just \"python\" not 'command = \"python\"')\n- Clear explanation of WHY this needs human attention in the message\n- Use severity: \"info\" for suggestions, \"warning\" for concerns, \"error\" for serious logic issues\n- When possible, provide suggested_fixes with:\n  - target_snippet: the exact code to replace (same as issue_snippet usually)\n  - replacement_snippet: the replacement code\n  - title: clear description of the fix\n\nFocus on insights that require understanding code intent and context. Keep issue_snippet to the absolute minimum - just the problematic token.\"\"\",\n        )\n        logfire.info(\"AI agent initialized successfully\")\n\n    def find_snippet_in_text(\n        self, text: str, snippet: str\n    ) -> list[tuple[int, int, int, int]]:\n        \"\"\"Find all occurrences of code snippet in text, return positions as (start_line, start_col, end_line, end_col)\"\"\"\n        snippet = snippet.strip()\n        positions = []\n\n        # Search for all occurrences of snippet\n        start_pos = 0\n        while True:\n            start_pos = text.find(snippet, start_pos)\n            if start_pos == -1:\n                break\n\n            # Convert character position to line\/column\n            lines = text[:start_pos].split(\"\\n\")\n            start_line = len(lines) - 1\n            start_col = len(lines[-1])\n\n            # Calculate end position\n            snippet_lines = snippet.split(\"\\n\")\n            if len(snippet_lines) == 1:\n                end_line = start_line\n                end_col = start_col + len(snippet)\n            else:\n                end_line = start_line + len(snippet_lines) - 1\n                end_col = len(snippet_lines[-1])\n\n            positions.append((start_line, start_col, end_line, end_col))\n            start_pos += 1  # Move past this occurrence\n\n        if not positions:\n            logfire.warn(f\"Could not find snippet '{snippet}' in text\")\n        else:\n            logfire.debug(f\"Found {len(positions)} occurrences of '{snippet[:20]}...'\")\n\n        return positions\n\n    async def debounced_analyze(self, uri: str, text: str):\n        \"\"\"Debounced analysis that cancels previous calls\"\"\"\n        # Cancel any existing task for this URI\n        if uri in self._pending_tasks:\n            self._pending_tasks[uri].cancel()\n            _ = self._pending_tasks.pop(uri, None)\n\n        # Create new task\n        task: asyncio.Task[None] = asyncio.create_task(self._delayed_analyze(uri, text))\n        self._pending_tasks[uri] = task\n\n        try:\n            await task\n        except asyncio.CancelledError:\n            logfire.debug(f\"Analysis cancelled for {uri}\")\n        finally:\n            # Clean up completed task\n            if uri in self._pending_tasks and self._pending_tasks[uri] == task:\n                _ = self._pending_tasks.pop(uri)\n\n    async def _delayed_analyze(self, uri: str, text: str):\n        \"\"\"Wait for debounce period then analyze\"\"\"\n        await asyncio.sleep(settings.debounce_ms \/ 1000.0)\n        diagnostics = await self.analyze_document(uri, text)\n        # pyrefly: ignore [missing-attribute]\n        self.publish_diagnostics(uri, diagnostics)\n        logfire.debug(f\"Published {len(diagnostics)} diagnostics for {uri}\")\n\n    async def analyze_document(self, uri: str, text: str) -> list[Diagnostic]:\n        # Ensure we have a lock for this URI\n        lock = self._analysis_locks.setdefault(uri, asyncio.Lock())\n        async with lock:\n            with logfire.span(\"analyze_document\", uri=uri):\n                logfire.info(f\"Starting AI analysis for {uri}\")\n\n                try:\n                    file_path = Path(uri.replace(\"file:\/\/\", \"\"))\n                    language = self._detect_language(file_path)\n\n                    prompt = f\"\"\"Analyze this {language} code for issues:\n\n```{language}\n{text}\n```\n\nFile: {file_path.name}\"\"\"\n\n                    result = await self.agent.run(prompt)\n                    logfire.info(\n                        f\"AI analysis completed, found {len(result.output.issues)} issues\"\n                    )\n\n                    diagnostics = []\n                    for issue in result.output.issues:\n                        positions = self.find_snippet_in_text(text, issue.issue_snippet)\n\n                        if positions:\n                            start_line, start_col, end_line, end_col = positions[0]\n                            diagnostic = Diagnostic(\n                                range=Range(\n                                    start=Position(\n                                        line=start_line, character=start_col\n                                    ),\n                                    end=Position(line=end_line, character=end_col),\n                                ),\n                                message=f\"AI LSP: {issue.message}\",\n                                severity=self._get_diagnostic_severity(issue.severity),\n                                source=\"ai-lsp\",\n                                data={\n                                    \"issue_snippet\": issue.issue_snippet,\n                                    \"suggested_fixes\": [\n                                        {\n                                            \"title\": fix.title,\n                                            \"target_snippet\": fix.target_snippet,\n                                            \"replacement_snippet\": fix.replacement_snippet,\n                                        }\n                                        for fix in (issue.suggested_fixes or [])\n                                    ],\n                                },\n                            )\n                            diagnostics.append(diagnostic)\n\n                    return diagnostics\n\n                except Exception as e:\n                    logfire.error(\n                        f\"AI analysis failed for {uri}: {str(e)}\", _exc_info=True\n                    )\n                    return []\n\n    def _get_diagnostic_severity(self, severity: str) -> DiagnosticSeverity:\n        match severity:\n            case \"error\":\n                return DiagnosticSeverity.Error\n            case \"warning\":\n                return DiagnosticSeverity.Warning\n            case \"info\":\n                return DiagnosticSeverity.Information\n            case \"hint\":\n                return DiagnosticSeverity.Hint\n            case _:\n                return DiagnosticSeverity.Information\n\n    def _detect_language(self, file_path: Path) -> str:\n        match file_path.suffix:\n            case \".py\":\n                return \"python\"\n            case \".js\":\n                return \"javascript\"\n            case \".ts\":\n                return \"typescript\"\n            case \".jsx\":\n                return \"jsx\"\n            case \".tsx\":\n                return \"tsx\"\n            case \".rs\":\n                return \"rust\"\n            case \".go\":\n                return \"go\"\n            case \".java\":\n                return \"java\"\n            case \".cpp\":\n                return \"cpp\"\n            case \".c\":\n                return \"c\"\n            case \".lua\":\n                return \"lua\"\n            case _:\n                return \"text\"\n\n\nserver = AILanguageServer()\n\n\n@server.feature(TEXT_DOCUMENT_DID_OPEN)\nasync def did_open(params: DidOpenTextDocumentParams):\n    logfire.info(f\"Document opened: {params.text_document.uri}\")\n    doc = params.text_document\n    await server.debounced_analyze(doc.uri, doc.text)\n\n\n@server.feature(TEXT_DOCUMENT_DID_SAVE)\nasync def did_save(params: DidSaveTextDocumentParams):\n    logfire.info(f\"Document saved: {params.text_document.uri}\")\n    doc = server.workspace.get_text_document(params.text_document.uri)\n    await server.debounced_analyze(doc.uri, doc.source)\n\n\n@server.feature(TEXT_DOCUMENT_DID_CHANGE)\nasync def did_change(params: DidChangeTextDocumentParams):\n    logfire.debug(f\"Document changed: {params.text_document.uri}\")\n    doc = server.workspace.get_text_document(params.text_document.uri)\n    await server.debounced_analyze(doc.uri, doc.source)\n\n\n@server.feature(\n    TEXT_DOCUMENT_CODE_ACTION,\n    CodeActionOptions(code_action_kinds=[CodeActionKind.QuickFix]),\n)\nasync def code_actions(params: CodeActionParams) -> list[CodeAction]:\n    with logfire.span(\"code_actions\", uri=params.text_document.uri):\n        actions: list[CodeAction] = []\n        uri = params.text_document.uri\n        doc = server.workspace.get_text_document(uri)\n\n        for diagnostic in params.context.diagnostics:\n            if diagnostic.source != \"ai-lsp\" or not diagnostic.data:\n                continue\n\n            suggested_fixes = diagnostic.data.get(\"suggested_fixes\", [])\n\n            for fix_data in suggested_fixes:\n                target_positions = server.find_snippet_in_text(\n                    doc.source, fix_data[\"target_snippet\"]\n                )\n\n                if target_positions:\n                    with logfire.span(\"creating_quick_fix\", title=fix_data[\"title\"]):\n                        start_line, start_col, end_line, end_col = target_positions[0]\n                        fix_range = Range(\n                            start=Position(line=start_line, character=start_col),\n                            end=Position(line=end_line, character=end_col),\n                        )\n\n                        edit = WorkspaceEdit(\n                            changes={\n                                uri: [\n                                    TextEdit(\n                                        range=fix_range,\n                                        new_text=fix_data[\"replacement_snippet\"],\n                                    )\n                                ]\n                            }\n                        )\n\n                        action = CodeAction(\n                            title=f\"Apply: {fix_data['title']}\",\n                            kind=CodeActionKind.QuickFix,\n                            edit=edit,\n                            diagnostics=[diagnostic],\n                            is_preferred=True,\n                        )\n                        actions.append(action)\n\n            actions.append(\n                CodeAction(\n                    title=\"Regenerate AI fix\",\n                    kind=CodeActionKind.QuickFix,\n                    command=Command(\n                        title=\"Regenerate fix\",\n                        command=\"ai-lsp.regenerateFix\",\n                        arguments=[\n                            uri,\n                            diagnostic.data.get(\"issue_snippet\"),\n                            diagnostic.range.start.line,\n                            diagnostic.range.start.character,\n                        ],\n                    ),\n                    diagnostics=[diagnostic],\n                )\n            )\n\n            actions.append(\n                CodeAction(\n                    title=\"Dismiss AI suggestion\",\n                    kind=CodeActionKind.QuickFix,\n                    command=Command(\n                        title=\"Dismiss\",\n                        command=\"ai-lsp.dismiss\",\n                        arguments=[\n                            uri,\n                            diagnostic.range.start.line,\n                            diagnostic.range.start.character,\n                        ],\n                    ),\n                    diagnostics=[diagnostic],\n                )\n            )\n\n        return actions\n\n\n@server.command(\"ai-lsp.regenerateFix\")\nasync def regenerate_fix(*args):\n    if len(args) < 4:\n        return\n\n    uri, issue_snippet, line, character = args[0], args[1], args[2], args[3]\n\n    with logfire.span(\"regenerate_fix\", uri=uri, issue_snippet=issue_snippet):\n        logfire.info(\n            f\"Regenerating fix for '{issue_snippet}' at {uri}:{line}:{character}\"\n        )\n\n        doc = server.workspace.get_text_document(uri)\n        file_path = Path(uri.replace(\"file:\/\/\", \"\"))\n        language = server._detect_language(file_path)\n\n        prompt = f\"\"\"Analyze this specific code issue and provide NEW suggested fixes.\n\nIssue snippet: {issue_snippet}\n\nFull code context:\n```{language}\n{doc.source}\n```\n\nFile: {file_path.name}\n\nFocus ONLY on the issue at the snippet shown. Provide fresh, alternative fixes if possible.\"\"\"\n\n        try:\n            result = await server.agent.run(prompt)\n\n            if not result.output.issues:\n                logfire.warn(\"No issues returned for regeneration\")\n                return\n\n            regenerated_issue = result.output.issues[0]\n\n            current_diags = getattr(server.lsp, \"diagnostics\", {}).get(uri, [])\n            updated_diags = []\n\n            for diag in current_diags:\n                if (\n                    diag.source == \"ai-lsp\"\n                    and diag.range.start.line == line\n                    and diag.range.start.character == character\n                ):\n                    positions = server.find_snippet_in_text(\n                        doc.source, regenerated_issue.issue_snippet\n                    )\n                    if positions:\n                        start_line, start_col, end_line, end_col = positions[0]\n                        updated_diag = Diagnostic(\n                            range=Range(\n                                start=Position(line=start_line, character=start_col),\n                                end=Position(line=end_line, character=end_col),\n                            ),\n                            message=f\"AI LSP: {regenerated_issue.message}\",\n                            severity=server._get_diagnostic_severity(\n                                regenerated_issue.severity\n                            ),\n                            source=\"ai-lsp\",\n                            data={\n                                \"issue_snippet\": regenerated_issue.issue_snippet,\n                                \"suggested_fixes\": [\n                                    {\n                                        \"title\": fix.title,\n                                        \"target_snippet\": fix.target_snippet,\n                                        \"replacement_snippet\": fix.replacement_snippet,\n                                    }\n                                    for fix in (regenerated_issue.suggested_fixes or [])\n                                ],\n                            },\n                        )\n                        updated_diags.append(updated_diag)\n                        logfire.info(\n                            f\"Regenerated diagnostic with {len(regenerated_issue.suggested_fixes or [])} new fixes\"\n                        )\n                else:\n                    updated_diags.append(diag)\n\n            server.publish_diagnostics(uri, updated_diags)\n\n        except Exception as e:\n            logfire.error(f\"Failed to regenerate fix: {str(e)}\", _exc_info=True)\n\n\n@server.command(\"ai-lsp.dismiss\")\ndef dismiss_suggestion(*args):\n    if len(args) < 3:\n        return\n\n    uri, line, character = args[0], args[1], args[2]\n\n    with logfire.span(\"dismiss_suggestion\", uri=uri, line=line, character=character):\n        logfire.info(f\"Dismissing suggestion at {uri}:{line}:{character}\")\n\n        doc = server.workspace.get_text_document(uri)\n        diagnostics = []\n\n        current_diags = getattr(server.lsp, \"diagnostics\", {}).get(uri, [])\n        for diag in current_diags:\n            if (\n                diag.source == \"ai-lsp\"\n                and diag.range.start.line == line\n                and diag.range.start.character == character\n            ):\n                continue\n            diagnostics.append(diag)\n\n        server.publish_diagnostics(uri, diagnostics)\n\n\ndef app():\n    server.start_io()\n\n\nif __name__ == \"__main__\":\n    app()\n\n```\n\nFile: main.py","assistant":"{\n  \"issues\": [\n    {\n      \"issue_snippet\": \"text[:start_pos].split(\\\"\\\\n\\\")\",\n      \"severity\": \"warning\",\n      \"message\": \"Repeatedly calling `split('\\\\n')` on a growing string slice within a loop to calculate line and column numbers is inefficient for large documents or many snippet occurrences. This leads to quadratic time complexity in the worst case for text processing. Pre-calculating line start offsets or iterating line-by-line would be more performant to avoid redundant work.\",\n      \"suggested_fixes\": null\n    },\n    {\n      \"issue_snippet\": \"positions[0]\",\n      \"severity\": \"info\",\n      \"message\": \"The `find_snippet_in_text` method correctly identifies all occurrences of an `issue_snippet`, but only the first occurrence (`positions[0]`) is used to generate a diagnostic. If the same semantic issue appears multiple times in a document, only the first instance will be flagged by the AI LSP, potentially missing other relevant issues for the user. Consider iterating over all `positions` to generate diagnostics for every occurrence.\",\n      \"suggested_fixes\": null\n    },\n    {\n      \"issue_snippet\": \"getattr(server.lsp, \\\"diagnostics\\\", {}).get(uri, [])\",\n      \"severity\": \"warning\",\n      \"message\": \"Accessing `server.lsp.diagnostics` relies on an internal, potentially private, attribute of the `pygls` LanguageServer implementation. This approach is fragile and might break with future updates to `pygls`, coupling your code tightly to its internal structure. It's generally safer to interact with LSP features through documented public APIs or to manage diagnostic state more explicitly within `AILanguageServer` if direct access is unavoidable.\",\n      \"suggested_fixes\": null\n    }\n  ]\n}"}
{"system":"You are an AI code analyzer that provides semantic insights that traditional LSPs cannot detect.\n\nONLY flag issues that require deep semantic understanding:\n- Logic errors in algorithms or business logic\n- Subtle race conditions or concurrency issues  \n- Architectural problems and design pattern violations\n- Security vulnerabilities requiring context understanding\n- Performance anti-patterns that need semantic analysis\n- Complex data flow issues\n- Domain-specific best practice violations\n- Accessibility issues requiring UX understanding\n\nDO NOT flag issues that normal LSPs handle:\n- Syntax errors\n- Basic type errors  \n- Undefined variables\n- Import issues\n- Basic formatting problems\n- Simple linting rules\n\nFor each issue, provide:\n- The exact issue_snippet that has the problem (ONLY the problematic token\/value, e.g. just \"python\" not 'command = \"python\"')\n- Clear explanation of WHY this needs human attention in the message\n- Use severity: \"info\" for suggestions, \"warning\" for concerns, \"error\" for serious logic issues\n- When possible, provide suggested_fixes with:\n  - target_snippet: the exact code to replace (same as issue_snippet usually)\n  - replacement_snippet: the replacement code\n  - title: clear description of the fix\n\nFocus on insights that require understanding code intent and context. Keep issue_snippet to the absolute minimum - just the problematic token.","user":"Analyze this lua code for issues:\n\n```lua\n-- uv.nvim - Neovim plugin for uv Python package management integration\n-- Author: Ben O'Mahony\n-- License: MIT\n\nlocal M = {}\n\n-- Default configuration\nM.config = {\n\t-- Auto-activate virtual environments when found\n\tauto_activate_venv = true,\n\tnotify_activate_venv = true,\n\n\t-- Auto commands for directory changes\n\tauto_commands = true,\n\n\t-- Integration with picker (like Telescope or other UI components)\n\tpicker_integration = true,\n\n\t-- Keymaps to register (set to false to disable)\n\tkeymaps = {\n\t\tprefix = \"<leader>x\", -- Main prefix for UV commands\n\t\tcommands = true, -- Show UV commands menu (<leader>x)\n\t\trun_file = true, -- Run current file (<leader>xr)\n\t\trun_selection = true, -- Run selection (<leader>xs)\n\t\trun_function = true, -- Run function (<leader>xf)\n\t\tvenv = true, -- Environment management (<leader>xe)\n\t\tinit = true, -- Initialize UV project (<leader>xi)\n\t\tadd = true, -- Add a package (<leader>xa)\n\t\tremove = true, -- Remove a package (<leader>xd)\n\t\tsync = true, -- Sync packages (<leader>xc)\n\t\tsync_all = true, -- uv sync --all-extras --all-groups --all-packages (<leader>xC)\n\t},\n\n\t-- Execution options\n\texecution = {\n\t\t-- Python run command template\n\t\trun_command = \"uv run python\",\n\n\t\t-- Show output in notifications\n\t\tnotify_output = true,\n\n\t\t-- Notification timeout in ms\n\t\tnotification_timeout = 10000,\n\t},\n}\n\n-- Command runner - runs shell commands and captures output\nfunction M.run_command(cmd)\n\t-- Run command in background and capture output\n\tvim.fn.jobstart(cmd, {\n\t\ton_exit = function(_, exit_code)\n\t\t\tif exit_code == 0 then\n\t\t\t\tvim.notify(\"Command completed successfully: \" .. cmd, vim.log.levels.INFO)\n\t\t\telse\n\t\t\t\tvim.notify(\"Command failed: \" .. cmd, vim.log.levels.ERROR)\n\t\t\tend\n\t\tend,\n\t\ton_stdout = function(_, data)\n\t\t\tif data and #data > 1 then\n\t\t\t\t-- Only show meaningful output (not empty lines)\n\t\t\t\tlocal output = table.concat(data, \"\\n\")\n\t\t\t\tif output and output:match(\"%S\") then\n\t\t\t\t\tvim.notify(output, vim.log.levels.INFO)\n\t\t\t\tend\n\t\t\tend\n\t\tend,\n\t\ton_stderr = function(_, data)\n\t\t\tif data and #data > 1 then\n\t\t\t\t-- Show errors\n\t\t\t\tlocal output = table.concat(data, \"\\n\")\n\t\t\t\tif output and output:match(\"%S\") then\n\t\t\t\t\tvim.notify(output, vim.log.levels.WARN)\n\t\t\t\tend\n\t\t\tend\n\t\tend,\n\t\tstdout_buffered = true,\n\t\tstderr_buffered = true,\n\t})\nend\n\n-- Virtual environment activation\nfunction M.activate_venv(venv_path)\n\t-- For Mac, run the source command to apply to the current shell\n\tlocal command = \"source \" .. venv_path .. \"\/bin\/activate\"\n\t-- Set environment variables for the current Neovim instance\n\tvim.env.VIRTUAL_ENV = venv_path\n\tvim.env.PATH = venv_path .. \"\/bin:\" .. vim.env.PATH\n\t-- Notify user\n\tif M.config.notify_activate_venv then\n\t\tvim.notify(\"Activated virtual environment: \" .. venv_path, vim.log.levels.INFO)\n\tend\nend\n\n-- Auto-activate the .venv if it exists at the project root\nfunction M.auto_activate_venv()\n\tlocal venv_path = vim.fn.getcwd() .. \"\/.venv\"\n\tif vim.fn.isdirectory(venv_path) == 1 then\n\t\tM.activate_venv(venv_path)\n\t\treturn true\n\tend\n\treturn false\nend\n\n-- Function to create a temporary file with the necessary context and selected code\nfunction M.run_python_selection()\n\t-- Get visual selection\n\tlocal get_visual_selection = function()\n\t\tlocal start_pos = vim.fn.getpos(\"'<\")\n\t\tlocal end_pos = vim.fn.getpos(\"'>\")\n\t\tlocal lines = vim.fn.getline(start_pos[2], end_pos[2])\n\n\t\tif #lines == 0 then\n\t\t\treturn \"\"\n\t\tend\n\n\t\t-- Adjust last line to end at the column position of end_pos\n\t\tif #lines > 0 then\n\t\t\tlines[#lines] = lines[#lines]:sub(1, end_pos[3])\n\t\tend\n\n\t\t-- Adjust first line to start at the column position of start_pos\n\t\tif #lines > 0 then\n\t\t\tlines[1] = lines[1]:sub(start_pos[3])\n\t\tend\n\n\t\treturn table.concat(lines, \"\\n\")\n\tend\n\n\t-- Get current buffer content to extract imports and global variables\n\tlocal get_buffer_globals = function()\n\t\tlocal lines = vim.api.nvim_buf_get_lines(0, 0, -1, false)\n\t\tlocal imports = {}\n\t\tlocal globals = {}\n\t\tlocal in_class = false\n\t\tlocal class_indent = 0\n\n\t\tfor _, line in ipairs(lines) do\n\t\t\t-- Detect imports\n\t\t\tif line:match(\"^%s*import \") or line:match(\"^%s*from .+ import\") then\n\t\t\t\ttable.insert(imports, line)\n\t\t\tend\n\n\t\t\t-- Detect class definitions to skip class variables\n\t\t\tif line:match(\"^%s*class \") then\n\t\t\t\tin_class = true\n\t\t\t\tclass_indent = line:match(\"^(%s*)\"):len()\n\t\t\tend\n\n\t\t\t-- Check if we're exiting a class block\n\t\t\tif in_class and line:match(\"^%s*[^%s#]\") then\n\t\t\t\tlocal current_indent = line:match(\"^(%s*)\"):len()\n\t\t\t\tif current_indent <= class_indent then\n\t\t\t\t\tin_class = false\n\t\t\t\tend\n\t\t\tend\n\n\t\t\t-- Detect global variable assignments (not in class, not inside functions)\n\t\t\tif not in_class and not line:match(\"^%s*def \") and line:match(\"^%s*[%w_]+ *=\") then\n\t\t\t\t-- Check if it's not indented (global scope)\n\t\t\t\tif not line:match(\"^%s%s+\") then\n\t\t\t\t\ttable.insert(globals, line)\n\t\t\t\tend\n\t\t\tend\n\t\tend\n\n\t\treturn imports, globals\n\tend\n\n\t-- Get selected code\n\tlocal selection = get_visual_selection()\n\tif selection == \"\" then\n\t\tvim.notify(\"No code selected\", vim.log.levels.WARN)\n\t\treturn\n\tend\n\n\t-- Get imports and globals\n\tlocal imports, globals = get_buffer_globals()\n\n\t-- Create temp file\n\tlocal temp_dir = vim.fn.expand(\"$HOME\") .. \"\/.cache\/nvim\/uv_run\"\n\tvim.fn.mkdir(temp_dir, \"p\")\n\tlocal temp_file = temp_dir .. \"\/run_selection.py\"\n\tlocal file = io.open(temp_file, \"w\")\n\tif not file then\n\t\tvim.notify(\"Failed to create temporary file\", vim.log.levels.ERROR)\n\t\treturn\n\tend\n\n\t-- Write imports\n\tfor _, imp in ipairs(imports) do\n\t\tfile:write(imp .. \"\\n\")\n\tend\n\tfile:write(\"\\n\")\n\n\t-- Write globals\n\tfor _, glob in ipairs(globals) do\n\t\tfile:write(glob .. \"\\n\")\n\tend\n\tfile:write(\"\\n\")\n\n\t-- Write selected code\n\tfile:write(\"# SELECTED CODE\\n\")\n\n\t-- Check if the selection is all indented (which would cause syntax errors)\n\tlocal is_all_indented = true\n\tfor line in selection:gmatch(\"[^\\r\\n]+\") do\n\t\tif not line:match(\"^%s+\") and line ~= \"\" then\n\t\t\tis_all_indented = false\n\t\t\tbreak\n\t\tend\n\tend\n\n\t-- Process the selection to determine what type of code it is\n\tlocal is_function_def = selection:match(\"^%s*def%s+[%w_]+%s*%(\")\n\tlocal is_class_def = selection:match(\"^%s*class%s+[%w_]+\")\n\tlocal has_print = selection:match(\"print%s*%(\")\n\tlocal is_expression = not is_function_def\n\t\tand not is_class_def\n\t\tand not selection:match(\"=\")\n\t\tand not selection:match(\"%s*for%s+\")\n\t\tand not selection:match(\"%s*if%s+\")\n\t\tand not has_print\n\n\t-- If the selection is all indented, we need to dedent it or wrap it in a function\n\tif is_all_indented then\n\t\tfile:write(\"def run_selection():\\n\")\n\t\t-- Write the selection with original indentation\n\t\tfor line in selection:gmatch(\"[^\\r\\n]+\") do\n\t\t\tfile:write(\"    \" .. line .. \"\\n\")\n\t\tend\n\t\tfile:write(\"\\n# Auto-call the wrapper function\\n\")\n\t\tfile:write(\"run_selection()\\n\")\n\telse\n\t\t-- Write the original selection\n\t\tfile:write(selection .. \"\\n\")\n\n\t\t-- For expressions, we'll add a print statement to see the result\n\t\tif is_expression then\n\t\t\tfile:write(\"\\n# Auto-added print for expression\\n\")\n\t\t\tfile:write('print(f\"Expression result: {' .. selection:gsub(\"^%s+\", \"\"):gsub(\"%s+$\", \"\") .. '}\")\\n')\n\t\t-- For function definitions without calls, we'll add a call\n\t\telseif is_function_def then\n\t\t\tlocal function_name = selection:match(\"def%s+([%w_]+)%s*%(\")\n\t\t\t-- Check if the function is already called in the selection\n\t\t\tif function_name and not selection:match(function_name .. \"%s*%(.-%)\") then\n\t\t\t\tfile:write(\"\\n# Auto-added function call\\n\")\n\t\t\t\tfile:write('if __name__ == \"__main__\":\\n')\n\t\t\t\tfile:write('    print(f\"Auto-executing function: ' .. function_name .. '\")\\n')\n\t\t\t\tfile:write(\"    result = \" .. function_name .. \"()\\n\")\n\t\t\t\tfile:write(\"    if result is not None:\\n\")\n\t\t\t\tfile:write('        print(f\"Return value: {result}\")\\n')\n\t\t\tend\n\t\t-- If there's no print statement in the code, add an output marker\n\t\telseif not has_print and not selection:match(\"^%s*#\") then\n\t\t\tfile:write(\"\\n# Auto-added execution marker\\n\")\n\t\t\tfile:write('print(\"Code executed successfully.\")\\n')\n\t\tend\n\tend\n\n\tfile:close()\n\n\t-- Run the temp file\n\tvim.notify(\"Running selected code...\", vim.log.levels.INFO)\n\tvim.fn.jobstart(M.config.execution.run_command .. \" \" .. vim.fn.shellescape(temp_file), {\n\t\ton_stdout = function(_, data)\n\t\t\tif data and #data > 1 then\n\t\t\t\tlocal output = table.concat(data, \"\\n\")\n\t\t\t\tif output and output:match(\"%S\") then\n\t\t\t\t\tvim.notify(output, vim.log.levels.INFO, {\n\t\t\t\t\t\ttitle = \"Python Output\",\n\t\t\t\t\t\ttimeout = M.config.execution.notification_timeout,\n\t\t\t\t\t})\n\t\t\t\tend\n\t\t\tend\n\t\tend,\n\t\ton_stderr = function(_, data)\n\t\t\tif data and #data > 1 then\n\t\t\t\tlocal output = table.concat(data, \"\\n\")\n\t\t\t\tif output and output:match(\"%S\") then\n\t\t\t\t\tvim.notify(output, vim.log.levels.ERROR, {\n\t\t\t\t\t\ttitle = \"Python Error\",\n\t\t\t\t\t\ttimeout = M.config.execution.notification_timeout,\n\t\t\t\t\t})\n\t\t\t\tend\n\t\t\tend\n\t\tend,\n\t\ton_exit = function(_, exit_code)\n\t\t\tif exit_code == 0 then\n\t\t\t\tvim.notify(\"Selected code executed successfully\", vim.log.levels.INFO)\n\t\t\telse\n\t\t\t\tvim.notify(\"Selected code execution failed with exit code: \" .. exit_code, vim.log.levels.ERROR)\n\t\t\tend\n\t\tend,\n\t\tstdout_buffered = true,\n\t\tstderr_buffered = true,\n\t})\nend\n\n-- Function to run a specific Python function\nfunction M.run_python_function()\n\t-- Get current buffer content\n\tlocal lines = vim.api.nvim_buf_get_lines(0, 0, -1, false)\n\tlocal buffer_content = table.concat(lines, \"\\n\")\n\n\t-- Find all function definitions\n\tlocal functions = {}\n\tfor line in buffer_content:gmatch(\"[^\\r\\n]+\") do\n\t\tlocal func_name = line:match(\"^def%s+([%w_]+)%s*%(\")\n\t\tif func_name then\n\t\t\ttable.insert(functions, func_name)\n\t\tend\n\tend\n\n\tif #functions == 0 then\n\t\tvim.notify(\"No functions found in current file\", vim.log.levels.WARN)\n\t\treturn\n\tend\n\n\t-- Create temp file for function selection picker\n\tlocal run_function = function(func_name)\n\t\t-- Create a temporary file with a main block to call the function\n\t\tlocal temp_dir = vim.fn.expand(\"$HOME\") .. \"\/.cache\/nvim\/uv_run\"\n\t\tvim.fn.mkdir(temp_dir, \"p\")\n\t\tlocal temp_file = temp_dir .. \"\/run_function.py\"\n\t\tlocal current_file = vim.fn.expand(\"%:p\")\n\n\t\t-- Create a wrapper script that imports the current file and calls the function\n\t\tlocal file = io.open(temp_file, \"w\")\n\t\tif not file then\n\t\t\tvim.notify(\"Failed to create temporary file\", vim.log.levels.ERROR)\n\t\t\treturn\n\t\tend\n\n\t\t-- Get the module name (file name without .py)\n\t\tlocal module_name = vim.fn.fnamemodify(current_file, \":t:r\")\n\t\tlocal module_dir = vim.fn.fnamemodify(current_file, \":h\")\n\n\t\t-- Write imports\n\t\tfile:write(\"import sys\\n\")\n\t\tfile:write(\"sys.path.insert(0, \" .. vim.inspect(module_dir) .. \")\\n\")\n\t\tfile:write(\"import \" .. module_name .. \"\\n\\n\")\n\t\tfile:write('if __name__ == \"__main__\":\\n')\n\t\tfile:write('    print(f\"Running function: ' .. func_name .. '\")\\n')\n\t\tfile:write(\"    result = \" .. module_name .. \".\" .. func_name .. \"()\\n\")\n\t\tfile:write(\"    if result is not None:\\n\")\n\t\tfile:write('        print(f\"Return value: {result}\")\\n')\n\t\tfile:close()\n\n\t\t-- Run the temp file\n\t\tvim.notify(\"Running function: \" .. func_name, vim.log.levels.INFO)\n\t\tvim.fn.jobstart(M.config.execution.run_command .. \" \" .. vim.fn.shellescape(temp_file), {\n\t\t\ton_stdout = function(_, data)\n\t\t\t\tif data and #data > 1 then\n\t\t\t\t\tlocal output = table.concat(data, \"\\n\")\n\t\t\t\t\tif output and output:match(\"%S\") then\n\t\t\t\t\t\tvim.notify(output, vim.log.levels.INFO, {\n\t\t\t\t\t\t\ttitle = \"Function Output\",\n\t\t\t\t\t\t\ttimeout = M.config.execution.notification_timeout,\n\t\t\t\t\t\t})\n\t\t\t\t\tend\n\t\t\t\tend\n\t\t\tend,\n\t\t\ton_stderr = function(_, data)\n\t\t\t\tif data and #data > 1 then\n\t\t\t\t\tlocal output = table.concat(data, \"\\n\")\n\t\t\t\t\tif output and output:match(\"%S\") then\n\t\t\t\t\t\tvim.notify(output, vim.log.levels.ERROR, {\n\t\t\t\t\t\t\ttitle = \"Function Error\",\n\t\t\t\t\t\t\ttimeout = M.config.execution.notification_timeout,\n\t\t\t\t\t\t})\n\t\t\t\t\tend\n\t\t\t\tend\n\t\t\tend,\n\t\t\ton_exit = function(_, exit_code)\n\t\t\t\tif exit_code == 0 then\n\t\t\t\t\tvim.notify(\"Function executed successfully\", vim.log.levels.INFO)\n\t\t\t\telse\n\t\t\t\t\tvim.notify(\"Function execution failed with exit code: \" .. exit_code, vim.log.levels.ERROR)\n\t\t\t\tend\n\t\t\tend,\n\t\t\tstdout_buffered = true,\n\t\t\tstderr_buffered = true,\n\t\t})\n\tend\n\n\t-- If there's only one function, run it directly\n\tif #functions == 1 then\n\t\trun_function(functions[1])\n\t\treturn\n\tend\n\n\t-- Otherwise, show a picker to select the function\n\tvim.ui.select(functions, {\n\t\tprompt = \"Select function to run:\",\n\t\tformat_item = function(item)\n\t\t\treturn \"def \" .. item .. \"()\"\n\t\tend,\n\t}, function(choice)\n\t\tif choice then\n\t\t\trun_function(choice)\n\t\tend\n\tend)\nend\n\n-- Run current file\nfunction M.run_file()\n\tlocal current_file = vim.fn.expand(\"%:p\")\n\tif current_file and current_file ~= \"\" then\n\t\tvim.notify(\"Running: \" .. vim.fn.expand(\"%:t\"), vim.log.levels.INFO)\n\t\t-- Run python on the current file and capture output to notifications\n\t\tvim.fn.jobstart(M.config.execution.run_command .. \" \" .. vim.fn.shellescape(current_file), {\n\t\t\ton_stdout = function(_, data)\n\t\t\t\tif data and #data > 1 then\n\t\t\t\t\tlocal output = table.concat(data, \"\\n\")\n\t\t\t\t\tif output and output:match(\"%S\") then\n\t\t\t\t\t\tvim.notify(output, vim.log.levels.INFO, {\n\t\t\t\t\t\t\ttitle = \"Python Output\",\n\t\t\t\t\t\t\ttimeout = M.config.execution.notification_timeout,\n\t\t\t\t\t\t})\n\t\t\t\t\tend\n\t\t\t\tend\n\t\t\tend,\n\t\t\ton_stderr = function(_, data)\n\t\t\t\tif data and #data > 1 then\n\t\t\t\t\tlocal output = table.concat(data, \"\\n\")\n\t\t\t\t\tif output and output:match(\"%S\") then\n\t\t\t\t\t\tvim.notify(output, vim.log.levels.ERROR, {\n\t\t\t\t\t\t\ttitle = \"Python Error\",\n\t\t\t\t\t\t\ttimeout = M.config.execution.notification_timeout,\n\t\t\t\t\t\t})\n\t\t\t\t\tend\n\t\t\t\tend\n\t\t\tend,\n\t\t\ton_exit = function(_, exit_code)\n\t\t\t\tif exit_code == 0 then\n\t\t\t\t\tvim.notify(\"Program execution completed successfully\", vim.log.levels.INFO, {\n\t\t\t\t\t\ttitle = \"Python Execution\",\n\t\t\t\t\t})\n\t\t\t\telse\n\t\t\t\t\tvim.notify(\"Program execution failed with exit code: \" .. exit_code, vim.log.levels.ERROR, {\n\t\t\t\t\t\ttitle = \"Python Execution\",\n\t\t\t\t\t})\n\t\t\t\tend\n\t\t\tend,\n\t\t\tstdout_buffered = true,\n\t\t\tstderr_buffered = true,\n\t\t})\n\telse\n\t\tvim.notify(\"No file is open\", vim.log.levels.WARN)\n\tend\nend\n\n-- Set up command pickers for integration with UI plugins\nfunction M.setup_pickers()\n\t-- Check if Snacks is available\n\tif _G.Snacks and _G.Snacks.picker then\n\t\t-- Register UV command source\n\t\tSnacks.picker.sources.uv_commands = {\n\t\t\tfinder = function()\n\t\t\t\treturn {\n\t\t\t\t\t{ text = \"Run current file\", desc = \"Run current file with Python\", is_run_current = true },\n\t\t\t\t\t{ text = \"Run selection\", desc = \"Run selected Python code\", is_run_selection = true },\n\t\t\t\t\t{ text = \"Run function\", desc = \"Run specific Python function\", is_run_function = true },\n\t\t\t\t\t{ text = \"uv add [package]\", desc = \"Install a package\" },\n\t\t\t\t\t{ text = \"uv sync\", desc = \"Sync packages from lockfile\" },\n\t\t\t\t\t{\n\t\t\t\t\t\ttext = \"uv sync --all-extras --all-packages --all-groups\",\n\t\t\t\t\t\tdesc = \"Sync all extras, groups and packages\",\n\t\t\t\t\t},\n\t\t\t\t\t{ text = \"uv remove [package]\", desc = \"Remove a package\" },\n\t\t\t\t\t{ text = \"uv init\", desc = \"Initialize a new project\" },\n\t\t\t\t}\n\t\t\tend,\n\t\t\tformat = function(item)\n\t\t\t\treturn { { item.text .. \" - \" .. item.desc } }\n\t\t\tend,\n\t\t\tconfirm = function(picker, item)\n\t\t\t\tif item then\n\t\t\t\t\tpicker:close()\n\t\t\t\t\tif item.is_run_current then\n\t\t\t\t\t\tM.run_file()\n\t\t\t\t\t\treturn\n\t\t\t\t\telseif item.is_run_selection then\n\t\t\t\t\t\t-- Check if there's a visual selection\n\t\t\t\t\t\tlocal mode = vim.fn.mode()\n\n\t\t\t\t\t\tif mode == \"v\" or mode == \"V\" or mode == \"\" then\n\t\t\t\t\t\t\tvim.cmd(\"normal! \\27\") -- Exit visual mode\n\t\t\t\t\t\t\tvim.defer_fn(function()\n\t\t\t\t\t\t\t\tM.run_python_selection()\n\t\t\t\t\t\t\tend, 100)\n\t\t\t\t\t\telse\n\t\t\t\t\t\t\t-- If not in visual mode, prompt the user to select text\n\t\t\t\t\t\t\tvim.notify(\n\t\t\t\t\t\t\t\t\"Please select text first. Enter visual mode (v) and select code to run.\",\n\t\t\t\t\t\t\t\tvim.log.levels.INFO\n\t\t\t\t\t\t\t)\n\t\t\t\t\t\t\t-- After notification, we'll set up a one-time autocmd to catch when visual mode is exited\n\t\t\t\t\t\t\tvim.api.nvim_create_autocmd(\"ModeChanged\", {\n\t\t\t\t\t\t\t\tpattern = \"[vV\\x16]*:n\", -- When changing from any visual mode to normal mode\n\t\t\t\t\t\t\t\tcallback = function(ev)\n\t\t\t\t\t\t\t\t\tM.run_python_selection()\n\t\t\t\t\t\t\t\t\treturn true -- Delete the autocmd after it's been triggered\n\t\t\t\t\t\t\t\tend,\n\t\t\t\t\t\t\t\tonce = true,\n\t\t\t\t\t\t\t})\n\t\t\t\t\t\tend\n\t\t\t\t\t\treturn\n\t\t\t\t\telseif item.is_run_function then\n\t\t\t\t\t\tM.run_python_function()\n\t\t\t\t\t\treturn\n\t\t\t\t\tend\n\n\t\t\t\t\tlocal cmd = item.text\n\t\t\t\t\t-- Check if command needs input\n\t\t\t\t\tif cmd:match(\"%[(.-)%]\") then\n\t\t\t\t\t\tlocal param_name = cmd:match(\"%[(.-)%]\")\n\t\t\t\t\t\tvim.ui.input({ prompt = \"Enter \" .. param_name .. \": \" }, function(input)\n\t\t\t\t\t\t\tif not input or input == \"\" then\n\t\t\t\t\t\t\t\tvim.notify(\"Cancelled\", vim.log.levels.INFO)\n\t\t\t\t\t\t\t\treturn\n\t\t\t\t\t\t\tend\n\t\t\t\t\t\t\t-- Replace the placeholder with actual input\n\t\t\t\t\t\t\tlocal actual_cmd = cmd:gsub(\"%[\" .. param_name .. \"%]\", input)\n\t\t\t\t\t\t\tM.run_command(actual_cmd)\n\t\t\t\t\t\tend)\n\t\t\t\t\telse\n\t\t\t\t\t\t-- Run the command directly\n\t\t\t\t\t\tM.run_command(cmd)\n\t\t\t\t\tend\n\t\t\t\tend\n\t\t\tend,\n\t\t}\n\n\t\t-- Register UV venv source\n\t\tSnacks.picker.sources.uv_venv = {\n\t\t\tfinder = function()\n\t\t\t\tlocal venvs = {}\n\t\t\t\t-- Check for .venv directory (uv's default)\n\t\t\t\tif vim.fn.isdirectory(\".venv\") == 1 then\n\t\t\t\t\ttable.insert(venvs, {\n\t\t\t\t\t\ttext = \".venv\",\n\t\t\t\t\t\tpath = vim.fn.getcwd() .. \"\/.venv\",\n\t\t\t\t\t\tis_current = vim.env.VIRTUAL_ENV and vim.env.VIRTUAL_ENV:match(\".venv$\") ~= nil,\n\t\t\t\t\t})\n\t\t\t\tend\n\t\t\t\tif #venvs == 0 then\n\t\t\t\t\ttable.insert(venvs, {\n\t\t\t\t\t\ttext = \"Create new virtual environment (uv venv)\",\n\t\t\t\t\t\tis_create = true,\n\t\t\t\t\t})\n\t\t\t\tend\n\t\t\t\treturn venvs\n\t\t\tend,\n\t\t\tformat = function(item)\n\t\t\t\tif item.is_create then\n\t\t\t\t\treturn { { \"+ \" .. item.text } }\n\t\t\t\telse\n\t\t\t\t\tlocal icon = item.is_current and \"\u25cf \" or \"\u25cb \"\n\t\t\t\t\treturn { { icon .. item.text .. \" (Activate)\" } }\n\t\t\t\tend\n\t\t\tend,\n\t\t\tconfirm = function(picker, item)\n\t\t\t\tpicker:close()\n\t\t\t\tif item then\n\t\t\t\t\tif item.is_create then\n\t\t\t\t\t\tM.run_command(\"uv venv\")\n\t\t\t\t\telse\n\t\t\t\t\t\tM.activate_venv(item.path)\n\t\t\t\t\tend\n\t\t\t\tend\n\t\t\tend,\n\t\t}\n\tend\n\n\t-- Check if Telescope is available\n\tlocal has_telescope, telescope = pcall(require, \"telescope\")\n\tif has_telescope then\n\t\tlocal pickers = require(\"telescope.pickers\")\n\t\tlocal finders = require(\"telescope.finders\")\n\t\tlocal sorters = require(\"telescope.sorters\")\n\t\tlocal actions = require(\"telescope.actions\")\n\t\tlocal action_state = require(\"telescope.actions.state\")\n\n\t\t-- UV Commands picker for Telescope\n\t\tM.pick_uv_commands = function()\n\t\t\tlocal items = {\n\t\t\t\t{ text = \"Run current file\", is_run_current = true },\n\t\t\t\t{ text = \"Run selection\", is_run_selection = true },\n\t\t\t\t{ text = \"Run function\", is_run_function = true },\n\t\t\t\t{ text = \"uv add [package]\", cmd = \"uv add \", needs_input = true },\n\t\t\t\t{ text = \"uv sync\", cmd = \"uv sync\" },\n\t\t\t\t{\n\t\t\t\t\ttext = \"uv sync --all-extras --all-packages --all-groups\",\n\t\t\t\t\tcmd = \"uv sync --all-extras --all-packages --all-groups\",\n\t\t\t\t},\n\t\t\t\t{ text = \"uv remove [package]\", cmd = \"uv remove \", needs_input = true },\n\t\t\t\t{ text = \"uv init\", cmd = \"uv init\" },\n\t\t\t}\n\n\t\t\tpickers\n\t\t\t\t.new({}, {\n\t\t\t\t\tprompt_title = \"UV Commands\",\n\t\t\t\t\tfinder = finders.new_table({\n\t\t\t\t\t\tresults = items,\n\t\t\t\t\t\tentry_maker = function(entry)\n\t\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\t\tvalue = entry,\n\t\t\t\t\t\t\t\tdisplay = entry.text,\n\t\t\t\t\t\t\t\tordinal = entry.text,\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\tend,\n\t\t\t\t\t}),\n\t\t\t\t\tsorter = sorters.get_generic_fuzzy_sorter(),\n\t\t\t\t\tattach_mappings = function(prompt_bufnr, map)\n\t\t\t\t\t\tlocal function on_select()\n\t\t\t\t\t\t\tlocal selection = action_state.get_selected_entry().value\n\t\t\t\t\t\t\tactions.close(prompt_bufnr)\n\t\t\t\t\t\t\tif selection.is_run_current then\n\t\t\t\t\t\t\t\tM.run_file()\n\t\t\t\t\t\t\telseif selection.is_run_selection then\n\t\t\t\t\t\t\t\tlocal mode = vim.fn.mode()\n\t\t\t\t\t\t\t\tif mode == \"v\" or mode == \"V\" or mode == \"\" then\n\t\t\t\t\t\t\t\t\tvim.cmd(\"normal! \\27\")\n\t\t\t\t\t\t\t\t\tvim.defer_fn(function()\n\t\t\t\t\t\t\t\t\t\tM.run_python_selection()\n\t\t\t\t\t\t\t\t\tend, 100)\n\t\t\t\t\t\t\t\telse\n\t\t\t\t\t\t\t\t\tvim.notify(\n\t\t\t\t\t\t\t\t\t\t\"Please select text first. Enter visual mode (v) and select code to run.\",\n\t\t\t\t\t\t\t\t\t\tvim.log.levels.INFO\n\t\t\t\t\t\t\t\t\t)\n\t\t\t\t\t\t\t\t\tvim.api.nvim_create_autocmd(\"ModeChanged\", {\n\t\t\t\t\t\t\t\t\t\tpattern = \"[vV\\x16]*:n\",\n\t\t\t\t\t\t\t\t\t\tcallback = function()\n\t\t\t\t\t\t\t\t\t\t\tM.run_python_selection()\n\t\t\t\t\t\t\t\t\t\t\treturn true\n\t\t\t\t\t\t\t\t\t\tend,\n\t\t\t\t\t\t\t\t\t\tonce = true,\n\t\t\t\t\t\t\t\t\t})\n\t\t\t\t\t\t\t\tend\n\t\t\t\t\t\t\telseif selection.is_run_function then\n\t\t\t\t\t\t\t\tM.run_python_function()\n\t\t\t\t\t\t\telse\n\t\t\t\t\t\t\t\tif selection.needs_input then\n\t\t\t\t\t\t\t\t\tlocal placeholder = selection.text:match(\"%[(.-)%]\")\n\t\t\t\t\t\t\t\t\tvim.ui.input(\n\t\t\t\t\t\t\t\t\t\t{ prompt = \"Enter \" .. (placeholder or \"value\") .. \": \" },\n\t\t\t\t\t\t\t\t\t\tfunction(input)\n\t\t\t\t\t\t\t\t\t\t\tif input and input ~= \"\" then\n\t\t\t\t\t\t\t\t\t\t\t\tlocal cmd = selection.cmd .. input\n\t\t\t\t\t\t\t\t\t\t\t\tM.run_command(cmd)\n\t\t\t\t\t\t\t\t\t\t\telse\n\t\t\t\t\t\t\t\t\t\t\t\tvim.notify(\"Cancelled\", vim.log.levels.INFO)\n\t\t\t\t\t\t\t\t\t\t\tend\n\t\t\t\t\t\t\t\t\t\tend\n\t\t\t\t\t\t\t\t\t)\n\t\t\t\t\t\t\t\telse\n\t\t\t\t\t\t\t\t\tM.run_command(selection.cmd)\n\t\t\t\t\t\t\t\tend\n\t\t\t\t\t\t\tend\n\t\t\t\t\t\tend\n\n\t\t\t\t\t\tmap(\"i\", \"<CR>\", on_select)\n\t\t\t\t\t\tmap(\"n\", \"<CR>\", on_select)\n\t\t\t\t\t\treturn true\n\t\t\t\t\tend,\n\t\t\t\t})\n\t\t\t\t:find()\n\t\tend\n\n\t\t-- UV venv picker for Telescope\n\t\tM.pick_uv_venv = function()\n\t\t\tlocal items = {}\n\t\t\tif vim.fn.isdirectory(\".venv\") == 1 then\n\t\t\t\ttable.insert(items, {\n\t\t\t\t\ttext = \".venv\",\n\t\t\t\t\tpath = vim.fn.getcwd() .. \"\/.venv\",\n\t\t\t\t\tis_current = vim.env.VIRTUAL_ENV and vim.env.VIRTUAL_ENV:match(\".venv$\") ~= nil,\n\t\t\t\t})\n\t\t\tend\n\t\t\tif #items == 0 then\n\t\t\t\ttable.insert(items, { text = \"Create new virtual environment (uv venv)\", is_create = true })\n\t\t\tend\n\n\t\t\tpickers\n\t\t\t\t.new({}, {\n\t\t\t\t\tprompt_title = \"UV Virtual Environments\",\n\t\t\t\t\tfinder = finders.new_table({\n\t\t\t\t\t\tresults = items,\n\t\t\t\t\t\tentry_maker = function(entry)\n\t\t\t\t\t\t\tlocal display = entry.is_create and \"+ \" .. entry.text\n\t\t\t\t\t\t\t\tor ((entry.is_current and \"\u25cf \" or \"\u25cb \") .. entry.text .. \" (Activate)\")\n\t\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\t\tvalue = entry,\n\t\t\t\t\t\t\t\tdisplay = display,\n\t\t\t\t\t\t\t\tordinal = display,\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\tend,\n\t\t\t\t\t}),\n\t\t\t\t\tsorter = sorters.get_generic_fuzzy_sorter(),\n\t\t\t\t\tattach_mappings = function(prompt_bufnr, map)\n\t\t\t\t\t\tlocal function on_select()\n\t\t\t\t\t\t\tlocal selection = action_state.get_selected_entry().value\n\t\t\t\t\t\t\tactions.close(prompt_bufnr)\n\t\t\t\t\t\t\tif selection.is_create then\n\t\t\t\t\t\t\t\tM.run_command(\"uv venv\")\n\t\t\t\t\t\t\telse\n\t\t\t\t\t\t\t\tM.activate_venv(selection.path)\n\t\t\t\t\t\t\tend\n\t\t\t\t\t\tend\n\n\t\t\t\t\t\tmap(\"i\", \"<CR>\", on_select)\n\t\t\t\t\t\tmap(\"n\", \"<CR>\", on_select)\n\t\t\t\t\t\treturn true\n\t\t\t\t\tend,\n\t\t\t\t})\n\t\t\t\t:find()\n\t\tend\n\tend\nend\n\n-- Set up user commands\nfunction M.setup_commands()\n\t-- Set up UV commands\n\tvim.api.nvim_create_user_command(\"UVInit\", function()\n\t\tM.run_command(\"uv init\")\n\tend, {})\n\n\t-- Command to run selected code\n\tvim.api.nvim_create_user_command(\"UVRunSelection\", function()\n\t\tM.run_python_selection()\n\tend, { range = true })\n\n\t-- Command to run a specific function\n\tvim.api.nvim_create_user_command(\"UVRunFunction\", function()\n\t\tM.run_python_function()\n\tend, {})\n\n\t-- Command to run the current file\n\tvim.api.nvim_create_user_command(\"UVRunFile\", function()\n\t\tM.run_file()\n\tend, {})\n\n\t-- Command to add a package\n\tvim.api.nvim_create_user_command(\"UVAddPackage\", function(opts)\n\t\tM.run_command(\"uv add \" .. opts.args)\n\tend, { nargs = 1 })\n\n\t-- Command to remove a package\n\tvim.api.nvim_create_user_command(\"UVRemovePackage\", function(opts)\n\t\tM.run_command(\"uv remove \" .. opts.args)\n\tend, { nargs = 1 })\nend\n\n-- Set up keymaps\nfunction M.setup_keymaps()\n\tlocal keymaps = M.config.keymaps\n\tlocal prefix = keymaps.prefix or \"<leader>x\"\n\n\t-- Main UV command menu\n\tif keymaps.commands then\n\t\tif _G.Snacks and _G.Snacks.picker then\n\t\t\tvim.api.nvim_set_keymap(\n\t\t\t\t\"n\",\n\t\t\t\tprefix,\n\t\t\t\t\"<cmd>lua Snacks.picker.pick('uv_commands')<CR>\",\n\t\t\t\t{ noremap = true, silent = true, desc = \"UV Commands\" }\n\t\t\t)\n\t\t\tvim.api.nvim_set_keymap(\n\t\t\t\t\"v\",\n\t\t\t\tprefix,\n\t\t\t\t\":<C-u>lua Snacks.picker.pick('uv_commands')<CR>\",\n\t\t\t\t{ noremap = true, silent = true, desc = \"UV Commands\" }\n\t\t\t)\n\t\tend\n\t\tlocal has_telescope = pcall(require, \"telescope\")\n\t\tif has_telescope then\n\t\t\tvim.api.nvim_set_keymap(\n\t\t\t\t\"n\",\n\t\t\t\tprefix,\n\t\t\t\t\"<cmd>lua require('uv').pick_uv_commands()<CR>\",\n\t\t\t\t{ noremap = true, silent = true, desc = \"UV Commands (Telescope)\" }\n\t\t\t)\n\t\t\tvim.api.nvim_set_keymap(\n\t\t\t\t\"v\",\n\t\t\t\tprefix,\n\t\t\t\t\":<C-u>lua require('uv').pick_uv_commands()<CR>\",\n\t\t\t\t{ noremap = true, silent = true, desc = \"UV Commands (Telescope)\" }\n\t\t\t)\n\t\tend\n\tend\n\n\t-- Run current file\n\tif keymaps.run_file then\n\t\tvim.api.nvim_set_keymap(\n\t\t\t\"n\",\n\t\t\tprefix .. \"r\",\n\t\t\t\"<cmd>UVRunFile<CR>\",\n\t\t\t{ noremap = true, silent = true, desc = \"UV Run Current File\" }\n\t\t)\n\tend\n\n\t-- Run selection\n\tif keymaps.run_selection then\n\t\tvim.api.nvim_set_keymap(\n\t\t\t\"v\",\n\t\t\tprefix .. \"s\",\n\t\t\t\":<C-u>UVRunSelection<CR>\",\n\t\t\t{ noremap = true, silent = true, desc = \"UV Run Selection\" }\n\t\t)\n\tend\n\n\t-- Run function\n\tif keymaps.run_function then\n\t\tvim.api.nvim_set_keymap(\n\t\t\t\"n\",\n\t\t\tprefix .. \"f\",\n\t\t\t\"<cmd>UVRunFunction<CR>\",\n\t\t\t{ noremap = true, silent = true, desc = \"UV Run Function\" }\n\t\t)\n\tend\n\n\t-- Environment management\n\tif keymaps.venv then\n\t\tif _G.Snacks and _G.Snacks.picker then\n\t\t\tvim.api.nvim_set_keymap(\n\t\t\t\t\"n\",\n\t\t\t\tprefix .. \"e\",\n\t\t\t\t\"<cmd>lua Snacks.picker.pick('uv_venv')<CR>\",\n\t\t\t\t{ noremap = true, silent = true, desc = \"UV Environment\" }\n\t\t\t)\n\t\tend\n\t\tlocal has_telescope_venv = pcall(require, \"telescope\")\n\t\tif has_telescope_venv then\n\t\t\tvim.api.nvim_set_keymap(\n\t\t\t\t\"n\",\n\t\t\t\tprefix .. \"e\",\n\t\t\t\t\"<cmd>lua require('uv').pick_uv_venv()<CR>\",\n\t\t\t\t{ noremap = true, silent = true, desc = \"UV Environment (Telescope)\" }\n\t\t\t)\n\t\tend\n\tend\n\n\t-- Initialize UV project\n\tif keymaps.init then\n\t\tvim.api.nvim_set_keymap(\n\t\t\t\"n\",\n\t\t\tprefix .. \"i\",\n\t\t\t\"<cmd>UVInit<CR>\",\n\t\t\t{ noremap = true, silent = true, desc = \"UV Init\" }\n\t\t)\n\tend\n\n\t-- Add a package\n\tif keymaps.add then\n\t\tvim.api.nvim_set_keymap(\n\t\t\t\"n\",\n\t\t\tprefix .. \"a\",\n\t\t\t\"<cmd>lua vim.ui.input({prompt = 'Enter package name: '}, function(input) if input and input ~= '' then require('uv').run_command('uv add ' .. input) end end)<CR>\",\n\t\t\t{ noremap = true, silent = true, desc = \"UV Add Package\" }\n\t\t)\n\tend\n\n\t-- Remove a package\n\tif keymaps.remove then\n\t\tvim.api.nvim_set_keymap(\n\t\t\t\"n\",\n\t\t\tprefix .. \"d\",\n\t\t\t\"<cmd>lua vim.ui.input({prompt = 'Enter package name: '}, function(input) if input and input ~= '' then require('uv').run_command('uv remove ' .. input) end end)<CR>\",\n\t\t\t{ noremap = true, silent = true, desc = \"UV Remove Package\" }\n\t\t)\n\tend\n\n\t-- Sync packages\n\tif keymaps.sync then\n\t\tvim.api.nvim_set_keymap(\n\t\t\t\"n\",\n\t\t\tprefix .. \"c\",\n\t\t\t\"<cmd>lua require('uv').run_command('uv sync')<CR>\",\n\t\t\t{ noremap = true, silent = true, desc = \"UV Sync Packages\" }\n\t\t)\n\tend\n\tif keymaps.sync_all then\n\t\tvim.api.nvim_set_keymap(\n\t\t\t\"n\",\n\t\t\tprefix .. \"C\",\n\t\t\t\"<cmd>lua require('uv').run_command('uv sync --all-extras --all-packages --all-groups')<CR>\",\n\t\t\t{ noremap = true, silent = true, desc = \"UV Sync All Extras, Groups and Packages\" }\n\t\t)\n\tend\nend\n\n-- Set up auto commands\nfunction M.setup_autocommands()\n\tif M.config.auto_commands then\n\t\t-- Auto-activate .venv if it exists\n\t\tif M.config.auto_activate_venv then\n\t\t\tM.auto_activate_venv()\n\n\t\t\t-- Also set up auto-command to check when entering a directory\n\t\t\tvim.api.nvim_create_autocmd({ \"DirChanged\" }, {\n\t\t\t\tpattern = { \"global\" },\n\t\t\t\tcallback = function()\n\t\t\t\t\tM.auto_activate_venv()\n\t\t\t\tend,\n\t\t\t})\n\t\tend\n\tend\nend\n\n-- Main setup function\nfunction M.setup(opts)\n\t-- Merge user configuration with defaults\n\tM.config = vim.tbl_deep_extend(\"force\", M.config, opts or {})\n\n\t-- Set up commands\n\tM.setup_commands()\n\n\t-- Set up keymaps if enabled\n\tif M.config.keymaps ~= false then\n\t\tM.setup_keymaps()\n\tend\n\n\t-- Set up autocommands if enabled\n\tif M.config.auto_commands ~= false then\n\t\tM.setup_autocommands()\n\tend\n\n\t-- Set up pickers if integration is enabled\n\tif M.config.picker_integration then\n\t\tM.setup_pickers()\n\tend\n\n\t-- Make run_command globally accessible (can be removed if not needed)\n\t_G.run_command = M.run_command\nend\n\nreturn M\n\n```\n\nFile: init.lua","assistant":"{\n  \"issues\": [\n    {\n      \"issue_snippet\": \"opts.args\",\n      \"severity\": \"error\",\n      \"message\": \"User input from `opts.args` in user commands (`UVAddPackage`, `UVRemovePackage`) is directly concatenated into shell commands without being escaped. A malicious user could inject arbitrary shell commands (e.g., `my_package; rm -rf \/`), leading to a critical remote code execution vulnerability.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Escape user command arguments for 'UVAddPackage'.\",\n          \"target_snippet\": \"opts.args\",\n          \"replacement_snippet\": \"vim.fn.shellescape(opts.args)\"\n        },\n        {\n          \"title\": \"Escape user command arguments for 'UVRemovePackage'.\",\n          \"target_snippet\": \"opts.args\",\n          \"replacement_snippet\": \"vim.fn.shellescape(opts.args)\"\n        }\n      ]\n    },\n    {\n      \"issue_snippet\": \"input\",\n      \"severity\": \"error\",\n      \"message\": \"User input obtained via `vim.ui.input` (e.g., for adding\/removing packages from pickers or keymaps) is directly concatenated into shell commands without being escaped. This is a critical remote code execution vulnerability, as an attacker can inject malicious shell commands (e.g., `my_package; rm -rf \/`). This pattern is repeated in Snacks picker, Telescope picker, and direct keymaps for `uv add` and `uv remove`.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Escape user input for Snacks picker commands.\",\n          \"target_snippet\": \"local actual_cmd = cmd:gsub(\\\"%[(.-)%]\\\", input)\",\n          \"replacement_snippet\": \"local actual_cmd = cmd:gsub(\\\"%[(.-)%]\\\", vim.fn.shellescape(input))\"\n        },\n        {\n          \"title\": \"Escape user input for Telescope picker commands.\",\n          \"target_snippet\": \"local cmd = selection.cmd .. input\",\n          \"replacement_snippet\": \"local cmd = selection.cmd .. vim.fn.shellescape(input)\"\n        },\n        {\n          \"title\": \"Escape user input for 'add package' keymap.\",\n          \"target_snippet\": \"require('uv').run_command('uv add ' .. input)\",\n          \"replacement_snippet\": \"require('uv').run_command('uv add ' .. vim.fn.shellescape(input))\"\n        },\n        {\n          \"title\": \"Escape user input for 'remove package' keymap.\",\n          \"target_snippet\": \"require('uv').run_command('uv remove ' .. input)\",\n          \"replacement_snippet\": \"require('uv').run_command('uv remove ' .. vim.fn.shellescape(input))\"\n        }\n      ]\n    },\n    {\n      \"issue_snippet\": \"local command = \\\"source \\\" .. venv_path .. \\\"\/bin\/activate\\\"\",\n      \"severity\": \"warning\",\n      \"message\": \"The `source` command is executed in a subshell via `vim.fn.jobstart`. The `source` command is a shell built-in that modifies the *current* shell's environment. Running it in a subshell means its effects on environment variables are confined to that subshell and do not propagate back to the Neovim process. While `vim.env.VIRTUAL_ENV` and `vim.env.PATH` are manually updated, this might not fully replicate all environment changes typically made by a complete virtual environment activation script, potentially leading to an incomplete setup for subsequent Python commands.\",\n      \"suggested_fixes\": null\n    },\n    {\n      \"issue_snippet\": \"if not in_class and not line:match(\\\"^%s*def \\\") and line:match(\\\"^%s*[%w_]+ *=\\\") then\",\n      \"severity\": \"warning\",\n      \"message\": \"The logic to extract global variables (`get_buffer_globals`) relies on simplistic regex matching and indentation checks. It might inaccurately classify local variables within top-level functions or complex assignments as globals, especially in non-trivial Python codebases. This can lead to `NameError` or unexpected behavior when the selected Python code is executed in isolation, as its dependencies might not be correctly provided. A more robust solution would involve proper Python AST parsing.\",\n      \"suggested_fixes\": null\n    },\n    {\n      \"issue_snippet\": \"print(f\\\"Expression result: {' .. selection:gsub(\\\"^%s+\\\", \\\"\\\"):gsub(\\\"%s+$\\\", \\\"\\\") .. '}\\\")\",\n      \"severity\": \"warning\",\n      \"message\": \"When automatically wrapping selected expressions for printing, inserting the expression directly into an f-string can lead to `SyntaxError` if the expression itself contains f-string syntax (e.g., `{}`) or unescaped quotes. A safer approach is to assign the expression to a temporary variable and then print its `str()` representation.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Use a temporary variable and `str()` for safer expression printing.\",\n          \"target_snippet\": \"file:write('print(f\\\"Expression result: {' .. selection:gsub(\\\"^%s+\\\", \\\"\\\"):gsub(\\\"%s+$\\\", \\\"\\\") .. '}\\\")\\\\n')\",\n          \"replacement_snippet\": \"local cleaned_selection = selection:gsub(\\\"^%s+\\\", \\\"\\\"):gsub(\\\"%s+$\\\", \\\"\\\")\\nfile:write(\\\"_uv_expr_result = (\\\" .. cleaned_selection .. \\\")\\\\n\\\")\\nfile:write('print(\\\"Expression result: \\\" + str(_uv_expr_result))\\\\n')\"\n        }\n      ]\n    },\n    {\n      \"issue_snippet\": \"if is_all_indented then\",\n      \"severity\": \"warning\",\n      \"message\": \"The logic for `M.run_python_selection` wraps all indented selected code in a new function (`def run_selection():`). However, if the selected code itself is an indented function or class definition (e.g., a method inside a class), this wrapping will result in a `SyntaxError` (e.g., `def` nested at the same level) or incorrect execution context. The checks for `is_function_def` and `is_class_def` should explicitly prevent this wrapping.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Avoid redundant function wrapping for indented function\/class definitions.\",\n          \"target_snippet\": \"if is_all_indented then\",\n          \"replacement_snippet\": \"if is_all_indented and not is_function_def and not is_class_def then\"\n        }\n      ]\n    },\n    {\n      \"issue_snippet\": \"local temp_dir = vim.fn.expand(\\\"$HOME\\\") .. \\\"\/.cache\/nvim\/uv_run\\\"\",\n      \"severity\": \"info\",\n      \"message\": \"The plugin creates temporary Python files for executing selections and functions in `~\/.cache\/nvim\/uv_run`. There is no explicit mechanism to clean up these temporary files after execution, which can lead to accumulation and unnecessary disk space usage over time.\",\n      \"suggested_fixes\": null\n    },\n    {\n      \"issue_snippet\": \"_G.run_command = M.run_command\",\n      \"severity\": \"info\",\n      \"message\": \"Exposing `M.run_command` globally as `_G.run_command` pollutes the global namespace. While the comment suggests it 'can be removed if not needed', its presence can lead to naming conflicts with other plugins or scripts and makes the module less encapsulated. It is generally better to explicitly require the module to access its functions.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Remove global exposure if not strictly necessary.\",\n          \"target_snippet\": \"_G.run_command = M.run_command\",\n          \"replacement_snippet\": \"-- _G.run_command = M.run_command -- Removed global exposure to prevent namespace pollution\"\n        }\n      ]\n    },\n    {\n      \"issue_snippet\": \"import \\\" .. module_name .. \\\"\\\\n\\\\n\\\"\",\n      \"severity\": \"info\",\n      \"message\": \"When running a specific Python function (`M.run_python_function`), the temporary script imports the entire current Python file as a module. This means all top-level code in that module will be executed upon import, including `if __name__ == \\\"__main__\\\":` blocks, global variable assignments, and any other statements outside of function definitions. This can lead to unintended side effects, inefficient execution, or incorrect behavior if the module's top-level code relies on a specific execution context.\",\n      \"suggested_fixes\": null\n    },\n    {\n      \"issue_snippet\": \"finder = function()\",\n      \"severity\": \"info\",\n      \"message\": \"The logic for integrating with `Snacks` and `Telescope` pickers contains significant duplication in defining command items and the `on_select`\/`confirm` logic. This violates the DRY (Don't Repeat Yourself) principle, making the code harder to maintain and update. Refactoring into shared data structures and helper functions would improve maintainability.\",\n      \"suggested_fixes\": null\n    }\n  ]\n}"}
{"system":"You are an AI code analyzer that provides semantic insights that traditional LSPs cannot detect.\n\nONLY flag issues that require deep semantic understanding:\n- Logic errors in algorithms or business logic\n- Subtle race conditions or concurrency issues  \n- Architectural problems and design pattern violations\n- Security vulnerabilities requiring context understanding\n- Performance anti-patterns that need semantic analysis\n- Complex data flow issues\n- Domain-specific best practice violations\n- Accessibility issues requiring UX understanding\n\nDO NOT flag issues that normal LSPs handle:\n- Syntax errors\n- Basic type errors  \n- Undefined variables\n- Import issues\n- Basic formatting problems\n- Simple linting rules\n\nFor each issue, provide:\n- The exact issue_snippet that has the problem (ONLY the problematic token\/value, e.g. just \"python\" not 'command = \"python\"')\n- Clear explanation of WHY this needs human attention in the message\n- Use severity: \"info\" for suggestions, \"warning\" for concerns, \"error\" for serious logic issues\n- When possible, provide suggested_fixes with:\n  - target_snippet: the exact code to replace (same as issue_snippet usually)\n  - replacement_snippet: the replacement code\n  - title: clear description of the fix\n\nFocus on insights that require understanding code intent and context. Keep issue_snippet to the absolute minimum - just the problematic token.","user":"Analyze this lua code for issues:\n\n```lua\nreturn {\n  -- \"benomahony\/uv.nvim\",\n  dir = \"\/Users\/benomahony\/Code\/open_source\/uv.nvim-amirreza\/\n  opts = {\n    notify_activate_venv = false,\n    picker_integration = true,\n  },\n}\n\n```\n\nFile: uv.lua","assistant":"{\n  \"issues\": []\n}"}
{"system":"You are an AI code analyzer that provides semantic insights that traditional LSPs cannot detect.\n\nONLY flag issues that require deep semantic understanding:\n- Logic errors in algorithms or business logic\n- Subtle race conditions or concurrency issues  \n- Architectural problems and design pattern violations\n- Security vulnerabilities requiring context understanding\n- Performance anti-patterns that need semantic analysis\n- Complex data flow issues\n- Domain-specific best practice violations\n- Accessibility issues requiring UX understanding\n\nDO NOT flag issues that normal LSPs handle:\n- Syntax errors\n- Basic type errors  \n- Undefined variables\n- Import issues\n- Basic formatting problems\n- Simple linting rules\n\nFor each issue, provide:\n- The exact issue_snippet that has the problem (ONLY the problematic token\/value, e.g. just \"python\" not 'command = \"python\"')\n- Clear explanation of WHY this needs human attention in the message\n- Use severity: \"info\" for suggestions, \"warning\" for concerns, \"error\" for serious logic issues\n- When possible, provide suggested_fixes with:\n  - target_snippet: the exact code to replace (same as issue_snippet usually)\n  - replacement_snippet: the replacement code\n  - title: clear description of the fix\n\nFocus on insights that require understanding code intent and context. Keep issue_snippet to the absolute minimum - just the problematic token.","user":"Analyze this python code for issues:\n\n```python\nimport asyncio\nimport os\nfrom pathlib import Path\nfrom typing import Any, Literal\nfrom importlib.metadata import version\nimport logfire\n\n# pyrefly: ignore [missing-import]\nfrom lsprotocol.types import (\n    TEXT_DOCUMENT_CODE_ACTION,\n    TEXT_DOCUMENT_DID_CHANGE,\n    TEXT_DOCUMENT_DID_OPEN,\n    TEXT_DOCUMENT_DID_SAVE,\n    CodeAction,\n    CodeActionKind,\n    CodeActionOptions,\n    CodeActionParams,\n    Command,\n    Diagnostic,\n    DiagnosticSeverity,\n    DidChangeTextDocumentParams,\n    DidOpenTextDocumentParams,\n    DidSaveTextDocumentParams,\n    Position,\n    Range,\n    TextEdit,\n    WorkspaceEdit,\n)\nfrom pydantic import BaseModel, Field\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models import KnownModelName\nfrom pydantic_settings import BaseSettings\n\n# pyrefly: ignore [missing-import]\nfrom pygls.server import LanguageServer\n\n\nclass Settings(BaseSettings):\n    ai_lsp_model: KnownModelName = Field(default=\"google-gla:gemini-2.5-flash\")\n    debounce_ms: int = Field(default=1000)\n    max_cache_size: int = Field(default=50)\n    configure_logfire: bool = Field(default=True)\n    otel_exporter_otlp_endpoint: str = Field(default=\"http:\/\/localhost:4318\")\n\n\nsettings = Settings()\n\n\nos.environ[\"OTEL_EXPORTER_OTLP_ENDPOINT\"] = settings.otel_exporter_otlp_endpoint\n\nif settings.configure_logfire:\n    logfire.configure(send_to_logfire=False, service_name=\"ai-lsp\")\n    logfire.instrument_pydantic_ai()\n    logfire.instrument_httpx(capture_all=True)\n\n\nclass SuggestedFix(BaseModel):\n    title: str\n    target_snippet: str\n    replacement_snippet: str\n\n\nclass CodeIssue(BaseModel):\n    issue_snippet: str\n    severity: Literal[\"error\", \"warning\", \"info\", \"hint\"]\n    message: str\n    suggested_fixes: list[SuggestedFix] | None = None\n\n\nclass DiagnosticResult(BaseModel):\n    issues: list[CodeIssue]\n\n\nclass AILanguageServer(LanguageServer):\n    def __init__(self):\n        super().__init__(\"ai-lsp\", version(\"ai-lsp\"))\n        logfire.info(\"Initializing AI Language Server\")\n        self._pending_tasks: dict[str, asyncio.Task[Any]] = {}\n        self._analysis_locks: dict[str, asyncio.Lock] = {}\n\n        self.agent: Agent[DiagnosticResult, Any] = Agent(\n            model=settings.ai_lsp_model,\n            output_type=DiagnosticResult,\n            system_prompt=\"\"\"You are an AI code analyzer that provides semantic insights that traditional LSPs cannot detect.\n\nONLY flag issues that require deep semantic understanding:\n- Logic errors in algorithms or business logic\n- Subtle race conditions or concurrency issues  \n- Architectural problems and design pattern violations\n- Security vulnerabilities requiring context understanding\n- Performance anti-patterns that need semantic analysis\n- Complex data flow issues\n- Domain-specific best practice violations\n- Accessibility issues requiring UX understanding\n\nDO NOT flag issues that normal LSPs handle:\n- Syntax errors\n- Basic type errors  \n- Undefined variables\n- Import issues\n- Basic formatting problems\n- Simple linting rules\n\nFor each issue, provide:\n- The exact issue_snippet that has the problem (ONLY the problematic token\/value, e.g. just \"python\" not 'command = \"python\"')\n- Clear explanation of WHY this needs human attention in the message\n- Use severity: \"info\" for suggestions, \"warning\" for concerns, \"error\" for serious logic issues\n- When possible, provide suggested_fixes with:\n  - target_snippet: the exact code to replace (same as issue_snippet usually)\n  - replacement_snippet: the replacement code\n  - title: clear description of the fix\n\nFocus on insights that require understanding code intent and context. Keep issue_snippet to the absolute minimum - just the problematic token.\"\"\",\n        )\n        logfire.info(\"AI agent initialized successfully\")\n\n    def find_snippet_in_text(\n        self, text: str, snippet: str\n    ) -> list[tuple[int, int, int, int]]:\n        \"\"\"Find all occurrences of code snippet in text, return positions as (start_line, start_col, end_line, end_col)\"\"\"\n        snippet = snippet.strip()\n        positions = []\n\n        # Search for all occurrences of snippet\n        start_pos = 0\n        while True:\n            start_pos = text.find(snippet, start_pos)\n            if start_pos == -1:\n                break\n\n            # Convert character position to line\/column\n            lines = text[:start_pos].split(\"\\n\")\n            start_line = len(lines) - 1\n            start_col = len(lines[-1])\n\n            # Calculate end position\n            snippet_lines = snippet.split(\"\\n\")\n            if len(snippet_lines) == 1:\n                end_line = start_line\n                end_col = start_col + len(snippet)\n            else:\n                end_line = start_line + len(snippet_lines) - 1\n                end_col = len(snippet_lines[-1])\n\n            positions.append((start_line, start_col, end_line, end_col))\n            start_pos += 1  # Move past this occurrence\n\n        if not positions:\n            logfire.warn(f\"Could not find snippet '{snippet}' in text\")\n        else:\n            logfire.debug(f\"Found {len(positions)} occurrences of '{snippet[:20]}...'\")\n\n        return positions\n\n    async def debounced_analyze(self, uri: str, text: str):\n        \"\"\"Debounced analysis that cancels previous calls\"\"\"\n        # Cancel any existing task for this URI\n        if uri in self._pending_tasks:\n            self._pending_tasks[uri].cancel()\n            _ = self._pending_tasks.pop(uri, None)\n\n        # Create new task\n        task: asyncio.Task[None] = asyncio.create_task(self._delayed_analyze(uri, text))\n        self._pending_tasks[uri] = task\n\n        try:\n            await task\n        except asyncio.CancelledError:\n            logfire.debug(f\"Analysis cancelled for {uri}\")\n        finally:\n            # Clean up completed task\n            if uri in self._pending_tasks and self._pending_tasks[uri] == task:\n                _ = self._pending_tasks.pop(uri)\n\n    async def _delayed_analyze(self, uri: str, text: str):\n        \"\"\"Wait for debounce period then analyze\"\"\"\n        await asyncio.sleep(settings.debounce_ms \/ 1000.0)\n        diagnostics = await self.analyze_document(uri, text)\n        # pyrefly: ignore [missing-attribute]\n        self.publish_diagnostics(uri, diagnostics)\n        logfire.debug(f\"Published {len(diagnostics)} diagnostics for {uri}\")\n\n    async def analyze_document(self, uri: str, text: str) -> list[Diagnostic]:\n        # Ensure we have a lock for this URI\n        lock = self._analysis_locks.setdefault(uri, asyncio.Lock())\n        async with lock:\n            with logfire.span(\"analyze_document\", uri=uri):\n                logfire.info(f\"Starting AI analysis for {uri}\")\n\n                try:\n                    file_path = Path(uri.replace(\"file:\/\/\", \"\"))\n                    language = self._detect_language(file_path)\n\n                    prompt = f\"\"\"Analyze this {language} code for issues:\n\n```{language}\n{text}\n```\n\nFile: {file_path.name}\"\"\"\n\n                    result = await self.agent.run(prompt)\n                    logfire.info(\n                        f\"AI analysis completed, found {len(result.output.issues)} issues\"\n                    )\n\n                    diagnostics = []\n                    for issue in result.output.issues:\n                        positions = self.find_snippet_in_text(text, issue.issue_snippet)\n\n                        if positions:\n                            start_line, start_col, end_line, end_col = positions[0]\n                            diagnostic = Diagnostic(\n                                range=Range(\n                                    start=Position(\n                                        line=start_line, character=start_col\n                                    ),\n                                    end=Position(line=end_line, character=end_col),\n                                ),\n                                message=f\"AI LSP: {issue.message}\",\n                                severity=self._get_diagnostic_severity(issue.severity),\n                                source=\"ai-lsp\",\n                                data={\n                                    \"issue_snippet\": issue.issue_snippet,\n                                    \"suggested_fixes\": [\n                                        {\n                                            \"title\": fix.title,\n                                            \"target_snippet\": fix.target_snippet,\n                                            \"replacement_snippet\": fix.replacement_snippet,\n                                        }\n                                        for fix in (issue.suggested_fixes or [])\n                                    ],\n                                },\n                            )\n                            diagnostics.append(diagnostic)\n\n                    return diagnostics\n\n                except Exception as e:\n                    logfire.error(\n                        f\"AI analysis failed for {uri}: {str(e)}\", _exc_info=True\n                    )\n                    return []\n\n    def _get_diagnostic_severity(self, severity: str) -> DiagnosticSeverity:\n        match severity:\n            case \"error\":\n                return DiagnosticSeverity.Error\n            case \"warning\":\n                return DiagnosticSeverity.Warning\n            case \"info\":\n                return DiagnosticSeverity.Information\n            case \"hint\":\n                return DiagnosticSeverity.Hint\n            case _:\n                return DiagnosticSeverity.Information\n\n    def _detect_language(self, file_path: Path) -> str:\n        match file_path.suffix:\n            case \".py\":\n                return \"python\"\n            case \".js\":\n                return \"javascript\"\n            case \".ts\":\n                return \"typescript\"\n            case \".jsx\":\n                return \"jsx\"\n            case \".tsx\":\n                return \"tsx\"\n            case \".rs\":\n                return \"rust\"\n            case \".go\":\n                return \"go\"\n            case \".java\":\n                return \"java\"\n            case \".cpp\":\n                return \"cpp\"\n            case \".c\":\n                return \"c\"\n            case \".lua\":\n                return \"lua\"\n            case _:\n                return \"text\"\n\n\nserver = AILanguageServer()\n\n\n@server.feature(TEXT_DOCUMENT_DID_OPEN)\nasync def did_open(params: DidOpenTextDocumentParams):\n    logfire.info(f\"Document opened: {params.text_document.uri}\")\n    doc = params.text_document\n    await server.debounced_analyze(doc.uri, doc.text)\n\n\n@server.feature(TEXT_DOCUMENT_DID_SAVE)\nasync def did_save(params: DidSaveTextDocumentParams):\n    logfire.info(f\"Document saved: {params.text_document.uri}\")\n    doc = server.workspace.get_text_document(params.text_document.uri)\n    await server.debounced_analyze(doc.uri, doc.source)\n\n\n@server.feature(TEXT_DOCUMENT_DID_CHANGE)\nasync def did_change(params: DidChangeTextDocumentParams):\n    logfire.debug(f\"Document changed: {params.text_document.uri}\")\n    doc = server.workspace.get_text_document(params.text_document.uri)\n    await server.debounced_analyze(doc.uri, doc.source)\n\n\n@server.feature(\n    TEXT_DOCUMENT_CODE_ACTION,\n    CodeActionOptions(code_action_kinds=[CodeActionKind.QuickFix]),\n)\nasync def code_actions(params: CodeActionParams) -> list[CodeAction]:\n    with logfire.span(\"code_actions\", uri=params.text_document.uri):\n        actions: list[CodeAction] = []\n        uri = params.text_document.uri\n        doc = server.workspace.get_text_document(uri)\n\n        for diagnostic in params.context.diagnostics:\n            if diagnostic.source != \"ai-lsp\" or not diagnostic.data:\n                continue\n\n            suggested_fixes = diagnostic.data.get(\"suggested_fixes\", [])\n\n            for fix_data in suggested_fixes:\n                target_positions = server.find_snippet_in_text(\n                    doc.source, fix_data[\"target_snippet\"]\n                )\n\n                if target_positions:\n                    with logfire.span(\"creating_quick_fix\", title=fix_data[\"title\"]):\n                        start_line, start_col, end_line, end_col = target_positions[0]\n                        fix_range = Range(\n                            start=Position(line=start_line, character=start_col),\n                            end=Position(line=end_line, character=end_col),\n                        )\n\n                        edit = WorkspaceEdit(\n                            changes={\n                                uri: [\n                                    TextEdit(\n                                        range=fix_range,\n                                        new_text=fix_data[\"replacement_snippet\"],\n                                    )\n                                ]\n                            }\n                        )\n\n                        action = CodeAction(\n                            title=f\"Apply: {fix_data['title']}\",\n                            kind=CodeActionKind.QuickFix,\n                            edit=edit,\n                            diagnostics=[diagnostic],\n                            is_preferred=True,\n                        )\n                        actions.append(action)\n\n            actions.append(\n                CodeAction(\n                    title=\"Regenerate AI fix\",\n                    kind=CodeActionKind.QuickFix,\n                    command=Command(\n                        title=\"Regenerate fix\",\n                        command=\"ai-lsp.regenerateFix\",\n                        arguments=[\n                            uri,\n                            diagnostic.data.get(\"issue_snippet\"),\n                            diagnostic.range.start.line,\n                            diagnostic.range.start.character,\n                        ],\n                    ),\n                    diagnostics=[diagnostic],\n                )\n            )\n\n            actions.append(\n                CodeAction(\n                    title=\"Dismiss AI suggestion\",\n                    kind=CodeActionKind.QuickFix,\n                    command=Command(\n                        title=\"Dismiss\",\n                        command=\"ai-lsp.dismiss\",\n                        arguments=[\n                            uri,\n                            diagnostic.range.start.line,\n                            diagnostic.range.start.character,\n                        ],\n                    ),\n                    diagnostics=[diagnostic],\n                )\n            )\n\n        return actions\n\n\n@server.command(\"ai-lsp.regenerateFix\")\nasync def regenerate_fix(*args):\n    if len(args) < 4:\n        return\n\n    uri, issue_snippet, line, character = args[0], args[1], args[2], args[3]\n\n    with logfire.span(\"regenerate_fix\", uri=uri, issue_snippet=issue_snippet):\n        logfire.info(\n            f\"Regenerating fix for '{issue_snippet}' at {uri}:{line}:{character}\"\n        )\n\n        doc = server.workspace.get_text_document(uri)\n        file_path = Path(uri.replace(\"file:\/\/\", \"\"))\n        language = server._detect_language(file_path)\n\n        prompt = f\"\"\"Analyze this specific code issue and provide NEW suggested fixes.\n\nIssue snippet: {issue_snippet}\n\nFull code context:\n```{language}\n{doc.source}\n```\n\nFile: {file_path.name}\n\nFocus ONLY on the issue at the snippet shown. Provide fresh, alternative fixes if possible.\"\"\"\n\n        try:\n            result = await server.agent.run(prompt)\n\n            if not result.output.issues:\n                logfire.warn(\"No issues returned for regeneration\")\n                return\n\n            regenerated_issue = result.output.issues[0]\n\n            current_diags = getattr(server.lsp, \"diagnostics\", {}).get(uri, [])\n            updated_diags = []\n\n            for diag in current_diags:\n                if (\n                    diag.source == \"ai-lsp\"\n                    and diag.range.start.line == line\n                    and diag.range.start.character == character\n                ):\n                    positions = server.find_snippet_in_text(\n                        doc.source, regenerated_issue.issue_snippet\n                    )\n                    if positions:\n                        start_line, start_col, end_line, end_col = positions[0]\n                        updated_diag = Diagnostic(\n                            range=Range(\n                                start=Position(line=start_line, character=start_col),\n                                end=Position(line=end_line, character=end_col),\n                            ),\n                            message=f\"AI LSP: {regenerated_issue.message}\",\n                            severity=server._get_diagnostic_severity(\n                                regenerated_issue.severity\n                            ),\n                            source=\"ai-lsp\",\n                            data={\n                                \"issue_snippet\": regenerated_issue.issue_snippet,\n                                \"suggested_fixes\": [\n                                    {\n                                        \"title\": fix.title,\n                                        \"target_snippet\": fix.target_snippet,\n                                        \"replacement_snippet\": fix.replacement_snippet,\n                                    }\n                                    for fix in (regenerated_issue.suggested_fixes or [])\n                                ],\n                            },\n                        )\n                        updated_diags.append(updated_diag)\n                        logfire.info(\n                            f\"Regenerated diagnostic with {len(regenerated_issue.suggested_fixes or [])} new fixes\"\n                        )\n                else:\n                    updated_diags.append(diag)\n\n            server.publish_diagnostics(uri, updated_diags)\n\n        except Exception as e:\n            logfire.error(f\"Failed to regenerate fix: {str(e)}\", _exc_info=True)\n\n\n@server.command(\"ai-lsp.dismiss\")\ndef dismiss_suggestion(*args):\n    if len(args) < 3:\n        return\n\n    uri, line, character = args[0], args[1], args[2]\n\n    with logfire.span(\"dismiss_suggestion\", uri=uri, line=line, character=character):\n        logfire.info(f\"Dismissing suggestion at {uri}:{line}:{character}\")\n\n        doc = server.workspace.get_text_document(uri)\n        diagnostics = []\n\n        current_diags = getattr(server.lsp, \"diagnostics\", {}).get(uri, [])\n        for diag in current_diags:\n            if (\n                diag.source == \"ai-lsp\"\n                and diag.range.start.line == line\n                and diag.range.start.character == character\n            ):\n                continue\n            diagnostics.append(diag)\n\n        server.publish_diagnostics(uri, diagnostics)\n\n\ndef app():\n    server.start_io()\n\n\nif __name__ == \"__main__\":\n    app()\n\n```\n\nFile: main.py","assistant":"{\n  \"issues\": [\n    {\n      \"issue_snippet\": \"snippet.strip()\",\n      \"severity\": \"warning\",\n      \"message\": \"The `find_snippet_in_text` function strips leading and trailing whitespace from the provided snippet before searching. If the AI provides an `issue_snippet` or `target_snippet` that intentionally includes specific whitespace (e.g., indentation or leading\/trailing spaces as part of the match), this stripping could lead to a failure to locate the snippet or an incorrect match. This may result in diagnostics or code actions not being applied as intended. It's generally safer to search for the exact snippet provided by the AI without modification.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Remove snippet stripping\",\n          \"target_snippet\": \"snippet.strip()\",\n          \"replacement_snippet\": \"snippet\"\n        }\n      ]\n    },\n    {\n      \"issue_snippet\": \"positions[0]\",\n      \"severity\": \"error\",\n      \"message\": \"The `analyze_document`, `code_actions`, and `regenerate_fix` functions consistently use `positions[0]` from `find_snippet_in_text`. This means that if an `issue_snippet` or `target_snippet` (as provided by the AI) appears multiple times in the document, diagnostics and code actions will always be applied to the *first* occurrence found. This is an architectural limitation because the AI's current output format lacks the explicit range information needed to pinpoint a specific instance of a repeated code pattern, potentially leading to confusing diagnostics and incorrect application of fixes.\",\n      \"suggested_fixes\": null\n    },\n    {\n      \"issue_snippet\": \"max_cache_size\",\n      \"severity\": \"info\",\n      \"message\": \"The `max_cache_size` setting is defined in the `Settings` class but is not referenced or utilized anywhere within the provided `AILanguageServer` implementation. This indicates a potentially unimplemented feature, a forgotten setting, or dead code. It's good practice to either implement the associated caching logic (e.g., for `_pending_tasks` or `analyze_document` results) or remove the setting to avoid confusion and maintain a clean configuration.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Remove unused setting\",\n          \"target_snippet\": \"max_cache_size: int = Field(default=50)\",\n          \"replacement_snippet\": \"# max_cache_size: int = Field(default=50) # Setting currently unused.\"\n        }\n      ]\n    },\n    {\n      \"issue_snippet\": \"doc.source\",\n      \"severity\": \"warning\",\n      \"message\": \"When regenerating a fix, the `regenerate_fix` command sends the entire document's content (`doc.source`) to the AI for analysis. While providing full context can be beneficial, for a focused regeneration of a specific snippet, sending the full file can be inefficient (higher token usage, slower response) and raises data privacy concerns if the code contains sensitive information. It would be more efficient and privacy-preserving to send only a contextual window of code around the problematic snippet instead of the entire document.\",\n      \"suggested_fixes\": null\n    },\n    {\n      \"issue_snippet\": \"os.environ[\\\"OTEL_EXPORTER_OTLP_ENDPOINT\\\"] = settings.otel_exporter_otlp_endpoint\",\n      \"severity\": \"warning\",\n      \"message\": \"The environment variable `OTEL_EXPORTER_OTLP_ENDPOINT` is set using `os.environ` after `logfire` has already been imported. While `logfire.configure` is called later, some underlying OpenTelemetry components might read environment variables during initial import. To guarantee that all parts of the tracing system correctly pick up the endpoint, it is best practice to set this environment variable at the very top of the script or externally, before any modules that rely on it are imported or initialized.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Suggest moving environment variable setting for early initialization\",\n          \"target_snippet\": \"os.environ[\\\"OTEL_EXPORTER_OTLP_ENDPOINT\\\"] = settings.otel_exporter_otlp_endpoint\",\n          \"replacement_snippet\": \"# To ensure OpenTelemetry components pick up the endpoint consistently,\\n# this line should ideally be moved to the very top of the file,\\n# before any imports that initialize tracing or logging libraries.\\nos.environ[\\\"OTEL_EXPORTER_OTLP_ENDPOINT\\\"] = settings.otel_exporter_otlp_endpoint\"\n        }\n      ]\n    }\n  ]\n}"}
{"system":"You are an AI code analyzer that provides semantic insights that traditional LSPs cannot detect.\n\nONLY flag issues that require deep semantic understanding:\n- Logic errors in algorithms or business logic\n- Subtle race conditions or concurrency issues  \n- Architectural problems and design pattern violations\n- Security vulnerabilities requiring context understanding\n- Performance anti-patterns that need semantic analysis\n- Complex data flow issues\n- Domain-specific best practice violations\n- Accessibility issues requiring UX understanding\n\nDO NOT flag issues that normal LSPs handle:\n- Syntax errors\n- Basic type errors  \n- Undefined variables\n- Import issues\n- Basic formatting problems\n- Simple linting rules\n\nFor each issue, provide:\n- The exact issue_snippet that has the problem (ONLY the problematic token\/value, e.g. just \"python\" not 'command = \"python\"')\n- Clear explanation of WHY this needs human attention in the message\n- Use severity: \"info\" for suggestions, \"warning\" for concerns, \"error\" for serious logic issues\n- When possible, provide suggested_fixes with:\n  - target_snippet: the exact code to replace (same as issue_snippet usually)\n  - replacement_snippet: the replacement code\n  - title: clear description of the fix\n\nFocus on insights that require understanding code intent and context. Keep issue_snippet to the absolute minimum - just the problematic token.","user":"Analyze this lua code for issues:\n\n```lua\n-- uv.nvim - Neovim plugin for uv Python package management integration\n-- Author: Ben O'Mahony\n-- License: MIT\n\nlocal M = {}\n\n-- Default configuration\nM.config = {\n\t-- Auto-activate virtual environments when found\n\tauto_activate_venv = true,\n\tnotify_activate_venv = true,\n\n\t-- Auto commands for directory changes\n\tauto_commands = true,\n\n\t-- Integration with picker (like Telescope or other UI components)\n\tpicker_integration = true,\n\n\t-- Keymaps to register (set to false to disable)\n\tkeymaps = {\n\t\tprefix = \"<leader>x\", -- Main prefix for UV commands\n\t\tcommands = true, -- Show UV commands menu (<leader>x)\n\t\trun_file = true, -- Run current file (<leader>xr)\n\t\trun_selection = true, -- Run selection (<leader>xs)\n\t\trun_function = true, -- Run function (<leader>xf)\n\t\tvenv = true, -- Environment management (<leader>xe)\n\t\tinit = true, -- Initialize UV project (<leader>xi)\n\t\tadd = true, -- Add a package (<leader>xa)\n\t\tremove = true, -- Remove a package (<leader>xd)\n\t\tsync = true, -- Sync packages (<leader>xc)\n\t\tsync_all = true, -- uv sync --all-extras --all-groups --all-packages (<leader>xC)\n\t},\n\n\t-- Execution options\n\texecution = {\n\t\t-- Python run command template\n\t\trun_command = \"uv run python\",\n\n\t\t-- Show output in notifications\n\t\tnotify_output = true,\n\n\t\t-- Notification timeout in ms\n\t\tnotification_timeout = 10000,\n\t},\n}\n\n-- Command runner - runs shell commands and captures output\nfunction M.run_command(cmd)\n\t-- Run command in background and capture output\n\tvim.fn.jobstart(cmd, {\n\t\ton_exit = function(_, exit_code)\n\t\t\tif exit_code == 0 then\n\t\t\t\tvim.notify(\"Command completed successfully: \" .. cmd, vim.log.levels.INFO)\n\t\t\telse\n\t\t\t\tvim.notify(\"Command failed: \" .. cmd, vim.log.levels.ERROR)\n\t\t\tend\n\t\tend,\n\t\ton_stdout = function(_, data)\n\t\t\tif data and #data > 1 then\n\t\t\t\t-- Only show meaningful output (not empty lines)\n\t\t\t\tlocal output = table.concat(data, \"\\n\")\n\t\t\t\tif output and output:match(\"%S\") then\n\t\t\t\t\tvim.notify(output, vim.log.levels.INFO)\n\t\t\t\tend\n\t\t\tend\n\t\tend,\n\t\ton_stderr = function(_, data)\n\t\t\tif data and #data > 1 then\n\t\t\t\t-- Show errors\n\t\t\t\tlocal output = table.concat(data, \"\\n\")\n\t\t\t\tif output and output:match(\"%S\") then\n\t\t\t\t\tvim.notify(output, vim.log.levels.WARN)\n\t\t\t\tend\n\t\t\tend\n\t\tend,\n\t\tstdout_buffered = true,\n\t\tstderr_buffered = true,\n\t})\nend\n\n-- Virtual environment activation\nfunction M.activate_venv(venv_path)\n\t-- For Mac, run the source command to apply to the current shell\n\tlocal command = \"source \" .. venv_path .. \"\/bin\/activate\"\n\t-- Set environment variables for the current Neovim instance\n\tvim.env.VIRTUAL_ENV = venv_path\n\tvim.env.PATH = venv_path .. \"\/bin:\" .. vim.env.PATH\n\t-- Notify user\n\tif M.config.notify_activate_venv then\n\t\tvim.notify(\"Activated virtual environment: \" .. venv_path, vim.log.levels.INFO)\n\tend\nend\n\n-- Auto-activate the .venv if it exists at the project root\nfunction M.auto_activate_venv()\n\tlocal venv_path = vim.fn.getcwd() .. \"\/.venv\"\n\tif vim.fn.isdirectory(venv_path) == 1 then\n\t\tM.activate_venv(venv_path)\n\t\treturn true\n\tend\n\treturn false\nend\n\n-- Function to create a temporary file with the necessary context and selected code\nfunction M.run_python_selection()\n\t-- Get visual selection\n\tlocal get_visual_selection = function()\n\t\tlocal start_pos = vim.fn.getpos(\"'<\")\n\t\tlocal end_pos = vim.fn.getpos(\"'>\")\n\t\tlocal lines = vim.fn.getline(start_pos[2], end_pos[2])\n\n\t\tif #lines == 0 then\n\t\t\treturn \"\"\n\t\tend\n\n\t\t-- Adjust last line to end at the column position of end_pos\n\t\tif #lines > 0 then\n\t\t\tlines[#lines] = lines[#lines]:sub(1, end_pos[3])\n\t\tend\n\n\t\t-- Adjust first line to start at the column position of start_pos\n\t\tif #lines > 0 then\n\t\t\tlines[1] = lines[1]:sub(start_pos[3])\n\t\tend\n\n\t\treturn table.concat(lines, \"\\n\")\n\tend\n\n\t-- Get current buffer content to extract imports and global variables\n\tlocal get_buffer_globals = function()\n\t\tlocal lines = vim.api.nvim_buf_get_lines(0, 0, -1, false)\n\t\tlocal imports = {}\n\t\tlocal globals = {}\n\t\tlocal in_class = false\n\t\tlocal class_indent = 0\n\n\t\tfor _, line in ipairs(lines) do\n\t\t\t-- Detect imports\n\t\t\tif line:match(\"^%s*import \") or line:match(\"^%s*from .+ import\") then\n\t\t\t\ttable.insert(imports, line)\n\t\t\tend\n\n\t\t\t-- Detect class definitions to skip class variables\n\t\t\tif line:match(\"^%s*class \") then\n\t\t\t\tin_class = true\n\t\t\t\tclass_indent = line:match(\"^(%s*)\"):len()\n\t\t\tend\n\n\t\t\t-- Check if we're exiting a class block\n\t\t\tif in_class and line:match(\"^%s*[^%s#]\") then\n\t\t\t\tlocal current_indent = line:match(\"^(%s*)\"):len()\n\t\t\t\tif current_indent <= class_indent then\n\t\t\t\t\tin_class = false\n\t\t\t\tend\n\t\t\tend\n\n\t\t\t-- Detect global variable assignments (not in class, not inside functions)\n\t\t\tif not in_class and not line:match(\"^%s*def \") and line:match(\"^%s*[%w_]+ *=\") then\n\t\t\t\t-- Check if it's not indented (global scope)\n\t\t\t\tif not line:match(\"^%s%s+\") then\n\t\t\t\t\ttable.insert(globals, line)\n\t\t\t\tend\n\t\t\tend\n\t\tend\n\n\t\treturn imports, globals\n\tend\n\n\t-- Get selected code\n\tlocal selection = get_visual_selection()\n\tif selection == \"\" then\n\t\tvim.notify(\"No code selected\", vim.log.levels.WARN)\n\t\treturn\n\tend\n\n\t-- Get imports and globals\n\tlocal imports, globals = get_buffer_globals()\n\n\t-- Create temp file\n\tlocal temp_dir = vim.fn.expand(\"$HOME\") .. \"\/.cache\/nvim\/uv_run\"\n\tvim.fn.mkdir(temp_dir, \"p\")\n\tlocal temp_file = temp_dir .. \"\/run_selection.py\"\n\tlocal file = io.open(temp_file, \"w\")\n\tif not file then\n\t\tvim.notify(\"Failed to create temporary file\", vim.log.levels.ERROR)\n\t\treturn\n\tend\n\n\t-- Write imports\n\tfor _, imp in ipairs(imports) do\n\t\tfile:write(imp .. \"\\n\")\n\tend\n\tfile:write(\"\\n\")\n\n\t-- Write globals\n\tfor _, glob in ipairs(globals) do\n\t\tfile:write(glob .. \"\\n\")\n\tend\n\tfile:write(\"\\n\")\n\n\t-- Write selected code\n\tfile:write(\"# SELECTED CODE\\n\")\n\n\t-- Check if the selection is all indented (which would cause syntax errors)\n\tlocal is_all_indented = true\n\tfor line in selection:gmatch(\"[^\\r\\n]+\") do\n\t\tif not line:match(\"^%s+\") and line ~= \"\" then\n\t\t\tis_all_indented = false\n\t\t\tbreak\n\t\tend\n\tend\n\n\t-- Process the selection to determine what type of code it is\n\tlocal is_function_def = selection:match(\"^%s*def%s+[%w_]+%s*%(\")\n\tlocal is_class_def = selection:match(\"^%s*class%s+[%w_]+\")\n\tlocal has_print = selection:match(\"print%s*%(\")\n\tlocal is_expression = not is_function_def\n\t\tand not is_class_def\n\t\tand not selection:match(\"=\")\n\t\tand not selection:match(\"%s*for%s+\")\n\t\tand not selection:match(\"%s*if%s+\")\n\t\tand not has_print\n\n\t-- If the selection is all indented, we need to dedent it or wrap it in a function\n\tif is_all_indented then\n\t\tfile:write(\"def run_selection():\\n\")\n\t\t-- Write the selection with original indentation\n\t\tfor line in selection:gmatch(\"[^\\r\\n]+\") do\n\t\t\tfile:write(\"    \" .. line .. \"\\n\")\n\t\tend\n\t\tfile:write(\"\\n# Auto-call the wrapper function\\n\")\n\t\tfile:write(\"run_selection()\\n\")\n\telse\n\t\t-- Write the original selection\n\t\tfile:write(selection .. \"\\n\")\n\n\t\t-- For expressions, we'll add a print statement to see the result\n\t\tif is_expression then\n\t\t\tfile:write(\"\\n# Auto-added print for expression\\n\")\n\t\t\tfile:write('print(f\"Expression result: {' .. selection:gsub(\"^%s+\", \"\"):gsub(\"%s+$\", \"\") .. '}\")\\n')\n\t\t-- For function definitions without calls, we'll add a call\n\t\telseif is_function_def then\n\t\t\tlocal function_name = selection:match(\"def%s+([%w_]+)%s*%(\")\n\t\t\t-- Check if the function is already called in the selection\n\t\t\tif function_name and not selection:match(function_name .. \"%s*%(.-%)\") then\n\t\t\t\tfile:write(\"\\n# Auto-added function call\\n\")\n\t\t\t\tfile:write('if __name__ == \"__main__\":\\n')\n\t\t\t\tfile:write('    print(f\"Auto-executing function: ' .. function_name .. '\")\\n')\n\t\t\t\tfile:write(\"    result = \" .. function_name .. \"()\\n\")\n\t\t\t\tfile:write(\"    if result is not None:\\n\")\n\t\t\t\tfile:write('        print(f\"Return value: {result}\")\\n')\n\t\t\tend\n\t\t-- If there's no print statement in the code, add an output marker\n\t\telseif not has_print and not selection:match(\"^%s*#\") then\n\t\t\tfile:write(\"\\n# Auto-added execution marker\\n\")\n\t\t\tfile:write('print(\"Code executed successfully.\")\\n')\n\t\tend\n\tend\n\n\tfile:close()\n\n\t-- Run the temp file\n\tvim.notify(\"Running selected code...\", vim.log.levels.INFO)\n\tvim.fn.jobstart(M.config.execution.run_command .. \" \" .. vim.fn.shellescape(temp_file), {\n\t\ton_stdout = function(_, data)\n\t\t\tif data and #data > 1 then\n\t\t\t\tlocal output = table.concat(data, \"\\n\")\n\t\t\t\tif output and output:match(\"%S\") then\n\t\t\t\t\tvim.notify(output, vim.log.levels.INFO, {\n\t\t\t\t\t\ttitle = \"Python Output\",\n\t\t\t\t\t\ttimeout = M.config.execution.notification_timeout,\n\t\t\t\t\t})\n\t\t\t\tend\n\t\t\tend\n\t\tend,\n\t\ton_stderr = function(_, data)\n\t\t\tif data and #data > 1 then\n\t\t\t\tlocal output = table.concat(data, \"\\n\")\n\t\t\t\tif output and output:match(\"%S\") then\n\t\t\t\t\tvim.notify(output, vim.log.levels.ERROR, {\n\t\t\t\t\t\ttitle = \"Python Error\",\n\t\t\t\t\t\ttimeout = M.config.execution.notification_timeout,\n\t\t\t\t\t})\n\t\t\t\tend\n\t\t\tend\n\t\tend,\n\t\ton_exit = function(_, exit_code)\n\t\t\tif exit_code == 0 then\n\t\t\t\tvim.notify(\"Selected code executed successfully\", vim.log.levels.INFO)\n\t\t\telse\n\t\t\t\tvim.notify(\"Selected code execution failed with exit code: \" .. exit_code, vim.log.levels.ERROR)\n\t\t\tend\n\t\tend,\n\t\tstdout_buffered = true,\n\t\tstderr_buffered = true,\n\t})\nend\n\n-- Function to run a specific Python function\nfunction M.run_python_function()\n\t-- Get current buffer content\n\tlocal lines = vim.api.nvim_buf_get_lines(0, 0, -1, false)\n\tlocal buffer_content = table.concat(lines, \"\\n\")\n\n\t-- Find all function definitions\n\tlocal functions = {}\n\tfor line in buffer_content:gmatch(\"[^\\r\\n]+\") do\n\t\tlocal func_name = line:match(\"^def%s+([%w_]+)%s*%(\")\n\t\tif func_name then\n\t\t\ttable.insert(functions, func_name)\n\t\tend\n\tend\n\n\tif #functions == 0 then\n\t\tvim.notify(\"No functions found in current file\", vim.log.levels.WARN)\n\t\treturn\n\tend\n\n\t-- Create temp file for function selection picker\n\tlocal run_function = function(func_name)\n\t\t-- Create a temporary file with a main block to call the function\n\t\tlocal temp_dir = vim.fn.expand(\"$HOME\") .. \"\/.cache\/nvim\/uv_run\"\n\t\tvim.fn.mkdir(temp_dir, \"p\")\n\t\tlocal temp_file = temp_dir .. \"\/run_function.py\"\n\t\tlocal current_file = vim.fn.expand(\"%:p\")\n\n\t\t-- Create a wrapper script that imports the current file and calls the function\n\t\tlocal file = io.open(temp_file, \"w\")\n\t\tif not file then\n\t\t\tvim.notify(\"Failed to create temporary file\", vim.log.levels.ERROR)\n\t\t\treturn\n\t\tend\n\n\t\t-- Get the module name (file name without .py)\n\t\tlocal module_name = vim.fn.fnamemodify(current_file, \":t:r\")\n\t\tlocal module_dir = vim.fn.fnamemodify(current_file, \":h\")\n\n\t\t-- Write imports\n\t\tfile:write(\"import sys\\n\")\n\t\tfile:write(\"sys.path.insert(0, \" .. vim.inspect(module_dir) .. \")\\n\")\n\t\tfile:write(\"import \" .. module_name .. \"\\n\\n\")\n\t\tfile:write('if __name__ == \"__main__\":\\n')\n\t\tfile:write('    print(f\"Running function: ' .. func_name .. '\")\\n')\n\t\tfile:write(\"    result = \" .. module_name .. \".\" .. func_name .. \"()\\n\")\n\t\tfile:write(\"    if result is not None:\\n\")\n\t\tfile:write('        print(f\"Return value: {result}\")\\n')\n\t\tfile:close()\n\n\t\t-- Run the temp file\n\t\tvim.notify(\"Running function: \" .. func_name, vim.log.levels.INFO)\n\t\tvim.fn.jobstart(M.config.execution.run_command .. \" \" .. vim.fn.shellescape(temp_file), {\n\t\t\ton_stdout = function(_, data)\n\t\t\t\tif data and #data > 1 then\n\t\t\t\t\tlocal output = table.concat(data, \"\\n\")\n\t\t\t\t\tif output and output:match(\"%S\") then\n\t\t\t\t\t\tvim.notify(output, vim.log.levels.INFO, {\n\t\t\t\t\t\t\ttitle = \"Function Output\",\n\t\t\t\t\t\t\ttimeout = M.config.execution.notification_timeout,\n\t\t\t\t\t\t})\n\t\t\t\t\tend\n\t\t\t\tend\n\t\t\tend,\n\t\t\ton_stderr = function(_, data)\n\t\t\t\tif data and #data > 1 then\n\t\t\t\t\tlocal output = table.concat(data, \"\\n\")\n\t\t\t\t\tif output and output:match(\"%S\") then\n\t\t\t\t\t\tvim.notify(output, vim.log.levels.ERROR, {\n\t\t\t\t\t\t\ttitle = \"Function Error\",\n\t\t\t\t\t\t\ttimeout = M.config.execution.notification_timeout,\n\t\t\t\t\t\t})\n\t\t\t\t\tend\n\t\t\t\tend\n\t\t\tend,\n\t\t\ton_exit = function(_, exit_code)\n\t\t\t\tif exit_code == 0 then\n\t\t\t\t\tvim.notify(\"Function executed successfully\", vim.log.levels.INFO)\n\t\t\t\telse\n\t\t\t\t\tvim.notify(\"Function execution failed with exit code: \" .. exit_code, vim.log.levels.ERROR)\n\t\t\t\tend\n\t\t\tend,\n\t\t\tstdout_buffered = true,\n\t\t\tstderr_buffered = true,\n\t\t})\n\tend\n\n\t-- If there's only one function, run it directly\n\tif #functions == 1 then\n\t\trun_function(functions[1])\n\t\treturn\n\tend\n\n\t-- Otherwise, show a picker to select the function\n\tvim.ui.select(functions, {\n\t\tprompt = \"Select function to run:\",\n\t\tformat_item = function(item)\n\t\t\treturn \"def \" .. item .. \"()\"\n\t\tend,\n\t}, function(choice)\n\t\tif choice then\n\t\t\trun_function(choice)\n\t\tend\n\tend)\nend\n\n-- Run current file\nfunction M.run_file()\n\tlocal current_file = vim.fn.expand(\"%:p\")\n\tif current_file and current_file ~= \"\" then\n\t\tvim.notify(\"Running: \" .. vim.fn.expand(\"%:t\"), vim.log.levels.INFO)\n\t\t-- Run python on the current file and capture output to notifications\n\t\tvim.fn.jobstart(M.config.execution.run_command .. \" \" .. vim.fn.shellescape(current_file), {\n\t\t\ton_stdout = function(_, data)\n\t\t\t\tif data and #data > 1 then\n\t\t\t\t\tlocal output = table.concat(data, \"\\n\")\n\t\t\t\t\tif output and output:match(\"%S\") then\n\t\t\t\t\t\tvim.notify(output, vim.log.levels.INFO, {\n\t\t\t\t\t\t\ttitle = \"Python Output\",\n\t\t\t\t\t\t\ttimeout = M.config.execution.notification_timeout,\n\t\t\t\t\t\t})\n\t\t\t\t\tend\n\t\t\t\tend\n\t\t\tend,\n\t\t\ton_stderr = function(_, data)\n\t\t\t\tif data and #data > 1 then\n\t\t\t\t\tlocal output = table.concat(data, \"\\n\")\n\t\t\t\t\tif output and output:match(\"%S\") then\n\t\t\t\t\t\tvim.notify(output, vim.log.levels.ERROR, {\n\t\t\t\t\t\t\ttitle = \"Python Error\",\n\t\t\t\t\t\t\ttimeout = M.config.execution.notification_timeout,\n\t\t\t\t\t\t})\n\t\t\t\t\tend\n\t\t\t\tend\n\t\t\tend,\n\t\t\ton_exit = function(_, exit_code)\n\t\t\t\tif exit_code == 0 then\n\t\t\t\t\tvim.notify(\"Program execution completed successfully\", vim.log.levels.INFO, {\n\t\t\t\t\t\ttitle = \"Python Execution\",\n\t\t\t\t\t})\n\t\t\t\telse\n\t\t\t\t\tvim.notify(\"Program execution failed with exit code: \" .. exit_code, vim.log.levels.ERROR, {\n\t\t\t\t\t\ttitle = \"Python Execution\",\n\t\t\t\t\t})\n\t\t\t\tend\n\t\t\tend,\n\t\t\tstdout_buffered = true,\n\t\t\tstderr_buffered = true,\n\t\t})\n\telse\n\t\tvim.notify(\"No file is open\", vim.log.levels.WARN)\n\tend\nend\n\n-- Set up command pickers for integration with UI plugins\nfunction M.setup_pickers()\n\t-- Check if Snacks is available\n\tif _G.Snacks and _G.Snacks.picker then\n\t\t-- Register UV command source\n\t\tSnacks.picker.sources.uv_commands = {\n\t\t\tfinder = function()\n\t\t\t\treturn {\n\t\t\t\t\t{ text = \"Run current file\", desc = \"Run current file with Python\", is_run_current = true },\n\t\t\t\t\t{ text = \"Run selection\", desc = \"Run selected Python code\", is_run_selection = true },\n\t\t\t\t\t{ text = \"Run function\", desc = \"Run specific Python function\", is_run_function = true },\n\t\t\t\t\t{ text = \"uv add [package]\", desc = \"Install a package\" },\n\t\t\t\t\t{ text = \"uv sync\", desc = \"Sync packages from lockfile\" },\n\t\t\t\t\t{\n\t\t\t\t\t\ttext = \"uv sync --all-extras --all-packages --all-groups\",\n\t\t\t\t\t\tdesc = \"Sync all extras, groups and packages\",\n\t\t\t\t\t},\n\t\t\t\t\t{ text = \"uv remove [package]\", desc = \"Remove a package\" },\n\t\t\t\t\t{ text = \"uv init\", desc = \"Initialize a new project\" },\n\t\t\t\t}\n\t\t\tend,\n\t\t\tformat = function(item)\n\t\t\t\treturn { { item.text .. \" - \" .. item.desc } }\n\t\t\tend,\n\t\t\tconfirm = function(picker, item)\n\t\t\t\tif item then\n\t\t\t\t\tpicker:close()\n\t\t\t\t\tif item.is_run_current then\n\t\t\t\t\t\tM.run_file()\n\t\t\t\t\t\treturn\n\t\t\t\t\telseif item.is_run_selection then\n\t\t\t\t\t\t-- Check if there's a visual selection\n\t\t\t\t\t\tlocal mode = vim.fn.mode()\n\n\t\t\t\t\t\tif mode == \"v\" or mode == \"V\" or mode == \"\" then\n\t\t\t\t\t\t\tvim.cmd(\"normal! \\27\") -- Exit visual mode\n\t\t\t\t\t\t\tvim.defer_fn(function()\n\t\t\t\t\t\t\t\tM.run_python_selection()\n\t\t\t\t\t\t\tend, 100)\n\t\t\t\t\t\telse\n\t\t\t\t\t\t\t-- If not in visual mode, prompt the user to select text\n\t\t\t\t\t\t\tvim.notify(\n\t\t\t\t\t\t\t\t\"Please select text first. Enter visual mode (v) and select code to run.\",\n\t\t\t\t\t\t\t\tvim.log.levels.INFO\n\t\t\t\t\t\t\t)\n\t\t\t\t\t\t\t-- After notification, we'll set up a one-time autocmd to catch when visual mode is exited\n\t\t\t\t\t\t\tvim.api.nvim_create_autocmd(\"ModeChanged\", {\n\t\t\t\t\t\t\t\tpattern = \"[vV\\x16]*:n\", -- When changing from any visual mode to normal mode\n\t\t\t\t\t\t\t\tcallback = function(ev)\n\t\t\t\t\t\t\t\t\tM.run_python_selection()\n\t\t\t\t\t\t\t\t\treturn true -- Delete the autocmd after it's been triggered\n\t\t\t\t\t\t\t\tend,\n\t\t\t\t\t\t\t\tonce = true,\n\t\t\t\t\t\t\t})\n\t\t\t\t\t\tend\n\t\t\t\t\t\treturn\n\t\t\t\t\telseif item.is_run_function then\n\t\t\t\t\t\tM.run_python_function()\n\t\t\t\t\t\treturn\n\t\t\t\t\tend\n\n\t\t\t\t\tlocal cmd = item.text\n\t\t\t\t\t-- Check if command needs input\n\t\t\t\t\tif cmd:match(\"%[(.-)%]\") then\n\t\t\t\t\t\tlocal param_name = cmd:match(\"%[(.-)%]\")\n\t\t\t\t\t\tvim.ui.input({ prompt = \"Enter \" .. param_name .. \": \" }, function(input)\n\t\t\t\t\t\t\tif not input or input == \"\" then\n\t\t\t\t\t\t\t\tvim.notify(\"Cancelled\", vim.log.levels.INFO)\n\t\t\t\t\t\t\t\treturn\n\t\t\t\t\t\t\tend\n\t\t\t\t\t\t\t-- Replace the placeholder with actual input\n\t\t\t\t\t\t\tlocal actual_cmd = cmd:gsub(\"%[\" .. param_name .. \"%]\", input)\n\t\t\t\t\t\t\tM.run_command(actual_cmd)\n\t\t\t\t\t\tend)\n\t\t\t\t\telse\n\t\t\t\t\t\t-- Run the command directly\n\t\t\t\t\t\tM.run_command(cmd)\n\t\t\t\t\tend\n\t\t\t\tend\n\t\t\tend,\n\t\t}\n\n\t\t-- Register UV venv source\n\t\tSnacks.picker.sources.uv_venv = {\n\t\t\tfinder = function()\n\t\t\t\tlocal venvs = {}\n\t\t\t\t-- Check for .venv directory (uv's default)\n\t\t\t\tif vim.fn.isdirectory(\".venv\") == 1 then\n\t\t\t\t\ttable.insert(venvs, {\n\t\t\t\t\t\ttext = \".venv\",\n\t\t\t\t\t\tpath = vim.fn.getcwd() .. \"\/.venv\",\n\t\t\t\t\t\tis_current = vim.env.VIRTUAL_ENV and vim.env.VIRTUAL_ENV:match(\".venv$\") ~= nil,\n\t\t\t\t\t})\n\t\t\t\tend\n\t\t\t\tif #venvs == 0 then\n\t\t\t\t\ttable.insert(venvs, {\n\t\t\t\t\t\ttext = \"Create new virtual environment (uv venv)\",\n\t\t\t\t\t\tis_create = true,\n\t\t\t\t\t})\n\t\t\t\tend\n\t\t\t\treturn venvs\n\t\t\tend,\n\t\t\tformat = function(item)\n\t\t\t\tif item.is_create then\n\t\t\t\t\treturn { { \"+ \" .. item.text } }\n\t\t\t\telse\n\t\t\t\t\tlocal icon = item.is_current and \"\u25cf \" or \"\u25cb \"\n\t\t\t\t\treturn { { icon .. item.text .. \" (Activate)\" } }\n\t\t\t\tend\n\t\t\tend,\n\t\t\tconfirm = function(picker, item)\n\t\t\t\tpicker:close()\n\t\t\t\tif item then\n\t\t\t\t\tif item.is_create then\n\t\t\t\t\t\tM.run_command(\"uv venv\")\n\t\t\t\t\telse\n\t\t\t\t\t\tM.activate_venv(item.path)\n\t\t\t\t\tend\n\t\t\t\tend\n\t\t\tend,\n\t\t}\n\tend\n\n\t-- Check if Telescope is available\n\tlocal has_telescope, telescope = pcall(require, \"telescope\")\n\tif has_telescope then\n\t\tlocal pickers = require(\"telescope.pickers\")\n\t\tlocal finders = require(\"telescope.finders\")\n\t\tlocal sorters = require(\"telescope.sorters\")\n\t\tlocal actions = require(\"telescope.actions\")\n\t\tlocal action_state = require(\"telescope.actions.state\")\n\n\t\t-- UV Commands picker for Telescope\n\t\tM.pick_uv_commands = function()\n\t\t\tlocal items = {\n\t\t\t\t{ text = \"Run current file\", is_run_current = true },\n\t\t\t\t{ text = \"Run selection\", is_run_selection = true },\n\t\t\t\t{ text = \"Run function\", is_run_function = true },\n\t\t\t\t{ text = \"uv add [package]\", cmd = \"uv add \", needs_input = true },\n\t\t\t\t{ text = \"uv sync\", cmd = \"uv sync\" },\n\t\t\t\t{\n\t\t\t\t\ttext = \"uv sync --all-extras --all-packages --all-groups\",\n\t\t\t\t\tcmd = \"uv sync --all-extras --all-packages --all-groups\",\n\t\t\t\t},\n\t\t\t\t{ text = \"uv remove [package]\", cmd = \"uv remove \", needs_input = true },\n\t\t\t\t{ text = \"uv init\", cmd = \"uv init\" },\n\t\t\t}\n\n\t\t\tpickers\n\t\t\t\t.new({}, {\n\t\t\t\t\tprompt_title = \"UV Commands\",\n\t\t\t\t\tfinder = finders.new_table({\n\t\t\t\t\t\tresults = items,\n\t\t\t\t\t\tentry_maker = function(entry)\n\t\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\t\tvalue = entry,\n\t\t\t\t\t\t\t\tdisplay = entry.text,\n\t\t\t\t\t\t\t\tordinal = entry.text,\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\tend,\n\t\t\t\t\t}),\n\t\t\t\t\tsorter = sorters.get_generic_fuzzy_sorter(),\n\t\t\t\t\tattach_mappings = function(prompt_bufnr, map)\n\t\t\t\t\t\tlocal function on_select()\n\t\t\t\t\t\t\tlocal selection = action_state.get_selected_entry().value\n\t\t\t\t\t\t\tactions.close(prompt_bufnr)\n\t\t\t\t\t\t\tif selection.is_run_current then\n\t\t\t\t\t\t\t\tM.run_file()\n\t\t\t\t\t\t\telseif selection.is_run_selection then\n\t\t\t\t\t\t\t\tlocal mode = vim.fn.mode()\n\t\t\t\t\t\t\t\tif mode == \"v\" or mode == \"V\" or mode == \"\" then\n\t\t\t\t\t\t\t\t\tvim.cmd(\"normal! \\27\")\n\t\t\t\t\t\t\t\t\tvim.defer_fn(function()\n\t\t\t\t\t\t\t\t\t\tM.run_python_selection()\n\t\t\t\t\t\t\t\t\tend, 100)\n\t\t\t\t\t\t\t\telse\n\t\t\t\t\t\t\t\t\tvim.notify(\n\t\t\t\t\t\t\t\t\t\t\"Please select text first. Enter visual mode (v) and select code to run.\",\n\t\t\t\t\t\t\t\t\t\tvim.log.levels.INFO\n\t\t\t\t\t\t\t\t\t)\n\t\t\t\t\t\t\t\t\tvim.api.nvim_create_autocmd(\"ModeChanged\", {\n\t\t\t\t\t\t\t\t\t\tpattern = \"[vV\\x16]*:n\",\n\t\t\t\t\t\t\t\t\t\tcallback = function()\n\t\t\t\t\t\t\t\t\t\t\tM.run_python_selection()\n\t\t\t\t\t\t\t\t\t\t\treturn true\n\t\t\t\t\t\t\t\t\t\tend,\n\t\t\t\t\t\t\t\t\t\tonce = true,\n\t\t\t\t\t\t\t\t\t})\n\t\t\t\t\t\t\t\tend\n\t\t\t\t\t\t\telseif selection.is_run_function then\n\t\t\t\t\t\t\t\tM.run_python_function()\n\t\t\t\t\t\t\telse\n\t\t\t\t\t\t\t\tif selection.needs_input then\n\t\t\t\t\t\t\t\t\tlocal placeholder = selection.text:match(\"%[(.-)%]\")\n\t\t\t\t\t\t\t\t\tvim.ui.input(\n\t\t\t\t\t\t\t\t\t\t{ prompt = \"Enter \" .. (placeholder or \"value\") .. \": \" },\n\t\t\t\t\t\t\t\t\t\tfunction(input)\n\t\t\t\t\t\t\t\t\t\t\tif input and input ~= \"\" then\n\t\t\t\t\t\t\t\t\t\t\t\tlocal cmd = selection.cmd .. input\n\t\t\t\t\t\t\t\t\t\t\t\tM.run_command(cmd)\n\t\t\t\t\t\t\t\t\t\t\telse\n\t\t\t\t\t\t\t\t\t\t\t\tvim.notify(\"Cancelled\", vim.log.levels.INFO)\n\t\t\t\t\t\t\t\t\t\t\tend\n\t\t\t\t\t\t\t\t\t\tend\n\t\t\t\t\t\t\t\t\t)\n\t\t\t\t\t\t\t\telse\n\t\t\t\t\t\t\t\t\tM.run_command(selection.cmd)\n\t\t\t\t\t\t\t\tend\n\t\t\t\t\t\t\tend\n\t\t\t\t\t\tend\n\n\t\t\t\t\t\tmap(\"i\", \"<CR>\", on_select)\n\t\t\t\t\t\tmap(\"n\", \"<CR>\", on_select)\n\t\t\t\t\t\treturn true\n\t\t\t\t\tend,\n\t\t\t\t})\n\t\t\t\t:find()\n\t\tend\n\n\t\t-- UV venv picker for Telescope\n\t\tM.pick_uv_venv = function()\n\t\t\tlocal items = {}\n\t\t\tif vim.fn.isdirectory(\".venv\") == 1 then\n\t\t\t\ttable.insert(items, {\n\t\t\t\t\ttext = \".venv\",\n\t\t\t\t\tpath = vim.fn.getcwd() .. \"\/.venv\",\n\t\t\t\t\tis_current = vim.env.VIRTUAL_ENV and vim.env.VIRTUAL_ENV:match(\".venv$\") ~= nil,\n\t\t\t\t})\n\t\t\tend\n\t\t\tif #items == 0 then\n\t\t\t\ttable.insert(items, { text = \"Create new virtual environment (uv venv)\", is_create = true })\n\t\t\tend\n\n\t\t\tpickers\n\t\t\t\t.new({}, {\n\t\t\t\t\tprompt_title = \"UV Virtual Environments\",\n\t\t\t\t\tfinder = finders.new_table({\n\t\t\t\t\t\tresults = items,\n\t\t\t\t\t\tentry_maker = function(entry)\n\t\t\t\t\t\t\tlocal display = entry.is_create and \"+ \" .. entry.text\n\t\t\t\t\t\t\t\tor ((entry.is_current and \"\u25cf \" or \"\u25cb \") .. entry.text .. \" (Activate)\")\n\t\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\t\tvalue = entry,\n\t\t\t\t\t\t\t\tdisplay = display,\n\t\t\t\t\t\t\t\tordinal = display,\n\t\t\t\t\t\t\t}\n\t\t\t\t\t\tend,\n\t\t\t\t\t}),\n\t\t\t\t\tsorter = sorters.get_generic_fuzzy_sorter(),\n\t\t\t\t\tattach_mappings = function(prompt_bufnr, map)\n\t\t\t\t\t\tlocal function on_select()\n\t\t\t\t\t\t\tlocal selection = action_state.get_selected_entry().value\n\t\t\t\t\t\t\tactions.close(prompt_bufnr)\n\t\t\t\t\t\t\tif selection.is_create then\n\t\t\t\t\t\t\t\tM.run_command(\"uv venv\")\n\t\t\t\t\t\t\telse\n\t\t\t\t\t\t\t\tM.activate_venv(selection.path)\n\t\t\t\t\t\t\tend\n\t\t\t\t\t\tend\n\n\t\t\t\t\t\tmap(\"i\", \"<CR>\", on_select)\n\t\t\t\t\t\tmap(\"n\", \"<CR>\", on_select)\n\t\t\t\t\t\treturn true\n\t\t\t\t\tend,\n\t\t\t\t})\n\t\t\t\t:find()\n\t\tend\n\tend\nend\n\n-- Set up user commands\nfunction M.setup_commands()\n\t-- Set up UV commands\n\tvim.api.nvim_create_user_command(\"UVInit\", function()\n\t\tM.run_command(\"uv init\")\n\tend, {})\n\n\t-- Command to run selected code\n\tvim.api.nvim_create_user_command(\"UVRunSelection\", function()\n\t\tM.run_python_selection()\n\tend, { range = true })\n\n\t-- Command to run a specific function\n\tvim.api.nvim_create_user_command(\"UVRunFunction\", function()\n\t\tM.run_python_function()\n\tend, {})\n\n\t-- Command to run the current file\n\tvim.api.nvim_create_user_command(\"UVRunFile\", function()\n\t\tM.run_file()\n\tend, {})\n\n\t-- Command to add a package\n\tvim.api.nvim_create_user_command(\"UVAddPackage\", function(opts)\n\t\tM.run_command(\"uv add \" .. opts.args)\n\tend, { nargs = 1 })\n\n\t-- Command to remove a package\n\tvim.api.nvim_create_user_command(\"UVRemovePackage\", function(opts)\n\t\tM.run_command(\"uv remove \" .. opts.args)\n\tend, { nargs = 1 })\nend\n\n-- Set up keymaps\nfunction M.setup_keymaps()\n\tlocal keymaps = M.config.keymaps\n\tlocal prefix = keymaps.prefix or \"<leader>x\"\n\n\t-- Main UV command menu\n\tif keymaps.commands then\n\t\tif _G.Snacks and _G.Snacks.picker then\n\t\t\tvim.api.nvim_set_keymap(\n\t\t\t\t\"n\",\n\t\t\t\tprefix,\n\t\t\t\t\"<cmd>lua Snacks.picker.pick('uv_commands')<CR>\",\n\t\t\t\t{ noremap = true, silent = true, desc = \"UV Commands\" }\n\t\t\t)\n\t\t\tvim.api.nvim_set_keymap(\n\t\t\t\t\"v\",\n\t\t\t\tprefix,\n\t\t\t\t\":<C-u>lua Snacks.picker.pick('uv_commands')<CR>\",\n\t\t\t\t{ noremap = true, silent = true, desc = \"UV Commands\" }\n\t\t\t)\n\t\tend\n\t\tlocal has_telescope = pcall(require, \"telescope\")\n\t\tif has_telescope then\n\t\t\tvim.api.nvim_set_keymap(\n\t\t\t\t\"n\",\n\t\t\t\tprefix,\n\t\t\t\t\"<cmd>lua require('uv').pick_uv_commands()<CR>\",\n\t\t\t\t{ noremap = true, silent = true, desc = \"UV Commands (Telescope)\" }\n\t\t\t)\n\t\t\tvim.api.nvim_set_keymap(\n\t\t\t\t\"v\",\n\t\t\t\tprefix,\n\t\t\t\t\":<C-u>lua require('uv').pick_uv_commands()<CR>\",\n\t\t\t\t{ noremap = true, silent = true, desc = \"UV Commands (Telescope)\" }\n\t\t\t)\n\t\tend\n\tend\n\n\t-- Run current file\n\tif keymaps.run_file then\n\t\tvim.api.nvim_set_keymap(\n\t\t\t\"n\",\n\t\t\tprefix .. \"r\",\n\t\t\t\"<cmd>UVRunFile<CR>\",\n\t\t\t{ noremap = true, silent = true, desc = \"UV Run Current File\" }\n\t\t)\n\tend\n\n\t-- Run selection\n\tif keymaps.run_selection then\n\t\tvim.api.nvim_set_keymap(\n\t\t\t\"v\",\n\t\t\tprefix .. \"s\",\n\t\t\t\":<C-u>UVRunSelection<CR>\",\n\t\t\t{ noremap = true, silent = true, desc = \"UV Run Selection\" }\n\t\t)\n\tend\n\n\t-- Run function\n\tif keymaps.run_function then\n\t\tvim.api.nvim_set_keymap(\n\t\t\t\"n\",\n\t\t\tprefix .. \"f\",\n\t\t\t\"<cmd>UVRunFunction<CR>\",\n\t\t\t{ noremap = true, silent = true, desc = \"UV Run Function\" }\n\t\t)\n\tend\n\n\t-- Environment management\n\tif keymaps.venv then\n\t\tif _G.Snacks and _G.Snacks.picker then\n\t\t\tvim.api.nvim_set_keymap(\n\t\t\t\t\"n\",\n\t\t\t\tprefix .. \"e\",\n\t\t\t\t\"<cmd>lua Snacks.picker.pick('uv_venv')<CR>\",\n\t\t\t\t{ noremap = true, silent = true, desc = \"UV Environment\" }\n\t\t\t)\n\t\tend\n\t\tlocal has_telescope_venv = pcall(require, \"telescope\")\n\t\tif has_telescope_venv then\n\t\t\tvim.api.nvim_set_keymap(\n\t\t\t\t\"n\",\n\t\t\t\tprefix .. \"e\",\n\t\t\t\t\"<cmd>lua require('uv').pick_uv_venv()<CR>\",\n\t\t\t\t{ noremap = true, silent = true, desc = \"UV Environment (Telescope)\" }\n\t\t\t)\n\t\tend\n\tend\n\n\t-- Initialize UV project\n\tif keymaps.init then\n\t\tvim.api.nvim_set_keymap(\n\t\t\t\"n\",\n\t\t\tprefix .. \"i\",\n\t\t\t\"<cmd>UVInit<CR>\",\n\t\t\t{ noremap = true, silent = true, desc = \"UV Init\" }\n\t\t)\n\tend\n\n\t-- Add a package\n\tif keymaps.add then\n\t\tvim.api.nvim_set_keymap(\n\t\t\t\"n\",\n\t\t\tprefix .. \"a\",\n\t\t\t\"<cmd>lua vim.ui.input({prompt = 'Enter package name: '}, function(input) if input and input ~= '' then require('uv').run_command('uv add ' .. input) end end)<CR>\",\n\t\t\t{ noremap = true, silent = true, desc = \"UV Add Package\" }\n\t\t)\n\tend\n\n\t-- Remove a package\n\tif keymaps.remove then\n\t\tvim.api.nvim_set_keymap(\n\t\t\t\"n\",\n\t\t\tprefix .. \"d\",\n\t\t\t\"<cmd>lua vim.ui.input({prompt = 'Enter package name: '}, function(input) if input and input ~= '' then require('uv').run_command('uv remove ' .. input) end end)<CR>\",\n\t\t\t{ noremap = true, silent = true, desc = \"UV Remove Package\" }\n\t\t)\n\tend\n\n\t-- Sync packages\n\tif keymaps.sync then\n\t\tvim.api.nvim_set_keymap(\n\t\t\t\"n\",\n\t\t\tprefix .. \"c\",\n\t\t\t\"<cmd>lua require('uv').run_command('uv sync')<CR>\",\n\t\t\t{ noremap = true, silent = true, desc = \"UV Sync Packages\" }\n\t\t)\n\tend\n\tif keymaps.sync_all then\n\t\tvim.api.nvim_set_keymap(\n\t\t\t\"n\",\n\t\t\tprefix .. \"C\",\n\t\t\t\"<cmd>lua require('uv').run_command('uv sync --all-extras --all-packages --all-groups')<CR>\",\n\t\t\t{ noremap = true, silent = true, desc = \"UV Sync All Extras, Groups and Packages\" }\n\t\t)\n\tend\nend\n\n-- Set up auto commands\nfunction M.setup_autocommands()\n\tif M.config.auto_commands then\n\t\t-- Auto-activate .venv if it exists\n\t\tif M.config.auto_activate_venv then\n\t\t\tM.auto_activate_venv()\n\n\t\t\t-- Also set up auto-command to check when entering a directory\n\t\t\tvim.api.nvim_create_autocmd({ \"DirChanged\" }, {\n\t\t\t\tpattern = { \"global\" },\n\t\t\t\tcallback = function()\n\t\t\t\t\tM.auto_activate_venv()\n\t\t\t\tend,\n\t\t\t})\n\t\tend\n\tend\nend\n\n-- Main setup function\nfunction M.setup(opts)\n\t-- Merge user configuration with defaults\n\tM.config = vim.tbl_deep_extend(\"force\", M.config, opts or {})\n\n\t-- Set up commands\n\tM.setup_commands()\n\n\t-- Set up keymaps if enabled\n\tif M.config.keymaps ~= false then\n\t\tM.setup_keymaps()\n\tend\n\n\t-- Set up autocommands if enabled\n\tif M.config.auto_commands ~= false then\n\t\tM.setup_autocommands()\n\tend\n\n\t-- Set up pickers if integration is enabled\n\tif M.config.picker_integration then\n\t\tM.setup_pickers()\n\tend\n\n\t-- Make run_command globally accessible (can be removed if not needed)\n\t_G.run_command = M.run_command\nend\n\nreturn M\n\n```\n\nFile: init.lua","assistant":"{\n  \"issues\": [\n    {\n      \"issue_snippet\": \"source\",\n      \"severity\": \"error\",\n      \"message\": \"The 'source' command for activating the virtual environment is constructed but never actually executed. Manually setting VIRTUAL_ENV and PATH is an incomplete activation and will miss other environment variables or shell functions that the 'activate' script typically sets. This can lead to unexpected behavior or Python not finding correctly configured packages.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Execute the source command via a shell, if Neovim's environment can be directly influenced.\",\n          \"target_snippet\": \"local command = \\\"source \\\" .. venv_path .. \\\"\/bin\/activate\\\"\",\n          \"replacement_snippet\": \"local command = \\\"source \\\" .. venv_path .. \\\"\/bin\/activate\\\"\\n-- This command needs to be run in the shell that Neovim itself runs in,\\n-- or its direct child process, which is complex. For Neovim's internal\\n-- environment, setting vim.env variables is the primary mechanism.\\n-- Consider if the 'source' command is truly necessary or achievable\\n-- given Neovim's job control model. If a full shell environment is needed,\\n-- it might require restarting Neovim within the activated shell or more advanced setup.\\n-- For most cases, setting VIRTUAL_ENV and PATH in vim.env is sufficient for Neovim's internal Python provider.\"\n        }\n      ]\n    },\n    {\n      \"issue_snippet\": \"get_buffer_globals\",\n      \"severity\": \"warning\",\n      \"message\": \"The `get_buffer_globals` function uses fragile heuristics (indentation-based string matching) to identify imports and global variables. This method may incorrectly classify or miss context (e.g., variables defined within top-level if\/try blocks, or complex module structures), leading to runtime errors when the extracted selection is run in a temporary file without its full lexical scope.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Improve global variable detection or provide a disclaimer.\",\n          \"target_snippet\": \"get_buffer_globals = function()\",\n          \"replacement_snippet\": \"get_buffer_globals = function() -- Consider using a more robust Python parser (if available via external tool) or adding a disclaimer about limitations.\"\n        }\n      ]\n    },\n    {\n      \"issue_snippet\": \"function_name .. \\\"()\\\"\",\n      \"severity\": \"warning\",\n      \"message\": \"In `M.run_python_selection`, when auto-calling a detected function, it is invoked without any arguments (e.g., `my_function()`). This will cause a runtime error if the function requires mandatory arguments.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Add a comment about the limitation or provide a mechanism for argument input.\",\n          \"target_snippet\": \"file:write(\\\"    result = \\\" .. function_name .. \\\"()\\\\n\\\")\",\n          \"replacement_snippet\": \"file:write(\\\"    result = \\\" .. function_name .. \\\"() -- NOTE: Assumes no arguments or all arguments have defaults. May fail if mandatory args are missing.\\\\n\\\")\"\n        }\n      ]\n    },\n    {\n      \"issue_snippet\": \"func_name .. \\\"()\\\"\",\n      \"severity\": \"error\",\n      \"message\": \"In `M.run_python_function`, when calling a selected function, it is explicitly invoked without any arguments (e.g., `module.my_function()`). This is a critical limitation; if the Python function requires mandatory arguments, this will result in a runtime error, severely limiting the utility of running functions that aren't self-contained or have defaults.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Provide a mechanism to input function arguments.\",\n          \"target_snippet\": \"file:write(\\\"    result = \\\" .. module_name .. \\\".\\\" .. func_name .. \\\"()\\\\n\\\")\",\n          \"replacement_snippet\": \"file:write(\\\"    result = \\\" .. module_name .. \\\".\\\" .. func_name .. \\\"() -- This call assumes the function takes no arguments or all arguments have defaults. Consider adding a mechanism for user input for function arguments.\\\\n\\\")\"\n        }\n      ]\n    },\n    {\n      \"issue_snippet\": \"vim.api.nvim_set_keymap\",\n      \"severity\": \"info\",\n      \"message\": \"For the main UV command menu (`prefix`) and environment management (`prefix .. \\\"e\\\"`) keymaps, the code defines mappings for both Snacks and Telescope pickers if both are detected. The keymap defined last will always overwrite the previous one. This creates a 'last writer wins' scenario without explicit user preference, potentially leading to inconsistent behavior or a picker being unexpectedly overridden.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Prioritize picker integration or allow user configuration.\",\n          \"target_snippet\": \"if _G.Snacks and _G.Snacks.picker then\",\n          \"replacement_snippet\": \"-- if M.config.use_snacks_picker and _G.Snacks and _G.Snacks.picker then\\nif _G.Snacks and _G.Snacks.picker then\"\n        },\n        {\n          \"title\": \"Prioritize picker integration or allow user configuration (example for Telescope).\",\n          \"target_snippet\": \"if has_telescope then\",\n          \"replacement_snippet\": \"-- elseif M.config.use_telescope_picker and has_telescope then\\n-- Or: if not (_G.Snacks and _G.Snacks.picker) and has_telescope then (prioritize Snacks if both are present)\\nif has_telescope then\"\n        }\n      ]\n    }\n  ]\n}"}
{"system":"You are an AI code analyzer that provides semantic insights that traditional LSPs cannot detect.\n\nONLY flag issues that require deep semantic understanding:\n- Logic errors in algorithms or business logic\n- Subtle race conditions or concurrency issues  \n- Architectural problems and design pattern violations\n- Security vulnerabilities requiring context understanding\n- Performance anti-patterns that need semantic analysis\n- Complex data flow issues\n- Domain-specific best practice violations\n- Accessibility issues requiring UX understanding\n\nDO NOT flag issues that normal LSPs handle:\n- Syntax errors\n- Basic type errors  \n- Undefined variables\n- Import issues\n- Basic formatting problems\n- Simple linting rules\n\nFor each issue, provide:\n- The exact issue_snippet that has the problem (ONLY the problematic token\/value, e.g. just \"python\" not 'command = \"python\"')\n- Clear explanation of WHY this needs human attention in the message\n- Use severity: \"info\" for suggestions, \"warning\" for concerns, \"error\" for serious logic issues\n- When possible, provide suggested_fixes with:\n  - target_snippet: the exact code to replace (same as issue_snippet usually)\n  - replacement_snippet: the replacement code\n  - title: clear description of the fix\n\nFocus on insights that require understanding code intent and context. Keep issue_snippet to the absolute minimum - just the problematic token.","user":"[Scrubbed due to 'API_KEY']","assistant":"{\n  \"issues\": [\n    {\n      \"issue_snippet\": \"\/Users\/benomahony\/Code\/open_source\/ai-lsp\",\n      \"severity\": \"error\",\n      \"message\": \"The path to the 'ai-lsp' server directory is hardcoded. This makes the configuration non-portable and will prevent the LSP from working for other users or if the project directory is moved. Configurations should be environment-agnostic.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Make the server path configurable or dynamic\",\n          \"target_snippet\": \"\/Users\/benomahony\/Code\/open_source\/ai-lsp\",\n          \"replacement_snippet\": \"vim.env.AI_LSP_SERVER_DIR or vim.fn.stdpath(\\\"data\\\") .. \\\"\/ai-lsp-server\\\"\"\n        }\n      ]\n    }\n  ]\n}"}
{"system":"You are an AI code analyzer that provides semantic insights that traditional LSPs cannot detect.\n\nONLY flag issues that require deep semantic understanding:\n- Logic errors in algorithms or business logic\n- Subtle race conditions or concurrency issues  \n- Architectural problems and design pattern violations\n- Security vulnerabilities requiring context understanding\n- Performance anti-patterns that need semantic analysis\n- Complex data flow issues\n- Domain-specific best practice violations\n- Accessibility issues requiring UX understanding\n\nDO NOT flag issues that normal LSPs handle:\n- Syntax errors\n- Basic type errors  \n- Undefined variables\n- Import issues\n- Basic formatting problems\n- Simple linting rules\n\nFor each issue, provide:\n- The exact issue_snippet that has the problem (ONLY the problematic token\/value, e.g. just \"python\" not 'command = \"python\"')\n- Clear explanation of WHY this needs human attention in the message\n- Use severity: \"info\" for suggestions, \"warning\" for concerns, \"error\" for serious logic issues\n- When possible, provide suggested_fixes with:\n  - target_snippet: the exact code to replace (same as issue_snippet usually)\n  - replacement_snippet: the replacement code\n  - title: clear description of the fix\n\nFocus on insights that require understanding code intent and context. Keep issue_snippet to the absolute minimum - just the problematic token.","user":"Analyze this python code for issues:\n\n```python\nimport asyncio\nimport os\nfrom pathlib import Path\nfrom typing import Any, Literal\nfrom importlib.metadata import version\nimport logfire\n\n# pyrefly: ignore [missing-import]\nfrom lsprotocol.types import (\n    TEXT_DOCUMENT_CODE_ACTION,\n    TEXT_DOCUMENT_DID_CHANGE,\n    TEXT_DOCUMENT_DID_OPEN,\n    TEXT_DOCUMENT_DID_SAVE,\n    CodeAction,\n    CodeActionKind,\n    CodeActionOptions,\n    CodeActionParams,\n    Command,\n    Diagnostic,\n    DiagnosticSeverity,\n    DidChangeTextDocumentParams,\n    DidOpenTextDocumentParams,\n    DidSaveTextDocumentParams,\n    Position,\n    Range,\n    TextEdit,\n    WorkspaceEdit,\n)\nfrom pydantic import BaseModel, Field\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models import KnownModelName\nfrom pydantic_settings import BaseSettings\n\n# pyrefly: ignore [missing-import]\nfrom pygls.server import LanguageServer\n\n\nclass Settings(BaseSettings):\n    ai_lsp_model: KnownModelName = Field(default=\"google-gla:gemini-2.5-flash\")\n    debounce_ms: int = Field(default=1000)\n    max_cache_size: int = Field(default=50)\n    configure_logfire: bool = Field(default=True)\n    otel_exporter_otlp_endpoint: str = Field(default=\"http:\/\/localhost:4318\")\n\n\nsettings = Settings()\n\n\nos.environ[\"OTEL_EXPORTER_OTLP_ENDPOINT\"] = settings.otel_exporter_otlp_endpoint\n\nif settings.configure_logfire:\n    logfire.configure(send_to_logfire=False, service_name=\"ai-lsp\")  # pyright: ignore[reportUnusedCallResult]\n    logfire.instrument_pydantic_ai()\n    logfire.instrument_httpx(capture_all=True)\n\n\nclass SuggestedFix(BaseModel):\n    title: str\n    target_snippet: str\n    replacement_snippet: str\n\n\nclass CodeIssue(BaseModel):\n    issue_snippet: str\n    severity: Literal[\"error\", \"warning\", \"info\", \"hint\"]\n    message: str\n    suggested_fixes: list[SuggestedFix] | None = None\n\n\nclass DiagnosticResult(BaseModel):\n    issues: list[CodeIssue]\n\n\nclass AILanguageServer(LanguageServer):\n    def __init__(self):\n        super().__init__(\"ai-lsp\", version(\"ai-lsp\"))\n        logfire.info(\"Initializing AI Language Server\")\n        self._pending_tasks: dict[str, asyncio.Task[Any]] = {}\n        self._analysis_locks: dict[str, asyncio.Lock] = {}\n\n        self.agent: Agent[DiagnosticResult, Any] = Agent(\n            model=settings.ai_lsp_model,\n            output_type=DiagnosticResult,\n            system_prompt=\"\"\"You are an AI code analyzer that provides semantic insights that traditional LSPs cannot detect.\n\nONLY flag issues that require deep semantic understanding:\n- Logic errors in algorithms or business logic\n- Subtle race conditions or concurrency issues  \n- Architectural problems and design pattern violations\n- Security vulnerabilities requiring context understanding\n- Performance anti-patterns that need semantic analysis\n- Complex data flow issues\n- Domain-specific best practice violations\n- Accessibility issues requiring UX understanding\n\nDO NOT flag issues that normal LSPs handle:\n- Syntax errors\n- Basic type errors  \n- Undefined variables\n- Import issues\n- Basic formatting problems\n- Simple linting rules\n\nFor each issue, provide:\n- The exact issue_snippet that has the problem (ONLY the problematic token\/value, e.g. just \"python\" not 'command = \"python\"')\n- Clear explanation of WHY this needs human attention in the message\n- Use severity: \"info\" for suggestions, \"warning\" for concerns, \"error\" for serious logic issues\n- When possible, provide suggested_fixes with:\n  - target_snippet: the exact code to replace (same as issue_snippet usually)\n  - replacement_snippet: the replacement code\n  - title: clear description of the fix\n\nFocus on insights that require understanding code intent and context. Keep issue_snippet to the absolute minimum - just the problematic token.\"\"\",\n        )\n        logfire.info(\"AI agent initialized successfully\")\n\n    def find_snippet_in_text(\n        self, text: str, snippet: str\n    ) -> list[tuple[int, int, int, int]]:\n        \"\"\"Find all occurrences of code snippet in text, return positions as (start_line, start_col, end_line, end_col)\"\"\"\n        snippet = snippet.strip()\n        positions = []\n\n        # Search for all occurrences of snippet\n        start_pos = 0\n        while True:\n            start_pos = text.find(snippet, start_pos)\n            if start_pos == -1:\n                break\n\n            # Convert character position to line\/column\n            lines = text[:start_pos].split(\"\\n\")\n            start_line = len(lines) - 1\n            start_col = len(lines[-1])\n\n            # Calculate end position\n            snippet_lines = snippet.split(\"\\n\")\n            if len(snippet_lines) == 1:\n                end_line = start_line\n                end_col = start_col + len(snippet)\n            else:\n                end_line = start_line + len(snippet_lines) - 1\n                end_col = len(snippet_lines[-1])\n\n            positions.append((start_line, start_col, end_line, end_col))\n            start_pos += 1  # Move past this occurrence\n\n        if not positions:\n            logfire.warn(f\"Could not find snippet '{snippet}' in text\")\n        else:\n            logfire.debug(f\"Found {len(positions)} occurrences of '{snippet[:20]}...'\")\n\n        return positions\n\n    async def debounced_analyze(self, uri: str, text: str):\n        \"\"\"Debounced analysis that cancels previous calls\"\"\"\n        # Cancel any existing task for this URI\n        if uri in self._pending_tasks:\n            self._pending_tasks[uri].cancel()\n            _ = self._pending_tasks.pop(uri, None)\n\n        # Create new task\n        task: asyncio.Task[None] = asyncio.create_task(self._delayed_analyze(uri, text))\n        self._pending_tasks[uri] = task\n\n        try:\n            await task\n        except asyncio.CancelledError:\n            logfire.debug(f\"Analysis cancelled for {uri}\")\n        finally:\n            # Clean up completed task\n            if uri in self._pending_tasks and self._pending_tasks[uri] == task:\n                _ = self._pending_tasks.pop(uri)\n\n    async def _delayed_analyze(self, uri: str, text: str):\n        \"\"\"Wait for debounce period then analyze\"\"\"\n        await asyncio.sleep(settings.debounce_ms \/ 1000.0)\n        diagnostics = await self.analyze_document(uri, text)\n        # pyrefly: ignore [missing-attribute]\n        self.publish_diagnostics(uri, diagnostics)\n        logfire.debug(f\"Published {len(diagnostics)} diagnostics for {uri}\")\n\n    async def analyze_document(self, uri: str, text: str) -> list[Diagnostic]:\n        # Ensure we have a lock for this URI\n        lock = self._analysis_locks.setdefault(uri, asyncio.Lock())\n        async with lock:\n            with logfire.span(\"analyze_document\", uri=uri):\n                logfire.info(f\"Starting AI analysis for {uri}\")\n\n                try:\n                    file_path = Path(uri.replace(\"file:\/\/\", \"\"))\n                    language = self._detect_language(file_path)\n\n                    prompt = f\"\"\"Analyze this {language} code for issues:\n\n```{language}\n{text}\n```\n\nFile: {file_path.name}\"\"\"\n\n                    result = await self.agent.run(prompt)\n                    logfire.info(\n                        f\"AI analysis completed, found {len(result.output.issues)} issues\"\n                    )\n\n                    diagnostics = []\n                    for issue in result.output.issues:\n                        positions = self.find_snippet_in_text(text, issue.issue_snippet)\n\n                        if positions:\n                            start_line, start_col, end_line, end_col = positions[0]\n                            diagnostic = Diagnostic(\n                                range=Range(\n                                    start=Position(\n                                        line=start_line, character=start_col\n                                    ),\n                                    end=Position(line=end_line, character=end_col),\n                                ),\n                                message=f\"AI LSP: {issue.message}\",\n                                severity=self._get_diagnostic_severity(issue.severity),\n                                source=\"ai-lsp\",\n                                data={\n                                    \"issue_snippet\": issue.issue_snippet,\n                                    \"suggested_fixes\": [\n                                        {\n                                            \"title\": fix.title,\n                                            \"target_snippet\": fix.target_snippet,\n                                            \"replacement_snippet\": fix.replacement_snippet,\n                                        }\n                                        for fix in (issue.suggested_fixes or [])\n                                    ],\n                                },\n                            )\n                            diagnostics.append(diagnostic)\n\n                    return diagnostics\n\n                except Exception as e:\n                    logfire.error(\n                        f\"AI analysis failed for {uri}: {str(e)}\", _exc_info=True\n                    )\n                    return []\n\n    def _get_diagnostic_severity(self, severity: str) -> DiagnosticSeverity:\n        match severity:\n            case \"error\":\n                return DiagnosticSeverity.Error\n            case \"warning\":\n                return DiagnosticSeverity.Warning\n            case \"info\":\n                return DiagnosticSeverity.Information\n            case \"hint\":\n                return DiagnosticSeverity.Hint\n            case _:\n                return DiagnosticSeverity.Information\n\n    def _detect_language(self, file_path: Path) -> str:\n        match file_path.suffix:\n            case \".py\":\n                return \"python\"\n            case \".js\":\n                return \"javascript\"\n            case \".ts\":\n                return \"typescript\"\n            case \".jsx\":\n                return \"jsx\"\n            case \".tsx\":\n                return \"tsx\"\n            case \".rs\":\n                return \"rust\"\n            case \".go\":\n                return \"go\"\n            case \".java\":\n                return \"java\"\n            case \".cpp\":\n                return \"cpp\"\n            case \".c\":\n                return \"c\"\n            case \".lua\":\n                return \"lua\"\n            case _:\n                return \"text\"\n\n\nserver = AILanguageServer()\n\n\n@server.feature(TEXT_DOCUMENT_DID_OPEN)\nasync def did_open(params: DidOpenTextDocumentParams):\n    logfire.info(f\"Document opened: {params.text_document.uri}\")\n    doc = params.text_document\n    await server.debounced_analyze(doc.uri, doc.text)\n\n\n@server.feature(TEXT_DOCUMENT_DID_SAVE)\nasync def did_save(params: DidSaveTextDocumentParams):\n    logfire.info(f\"Document saved: {params.text_document.uri}\")\n    doc = server.workspace.get_text_document(params.text_document.uri)\n    await server.debounced_analyze(doc.uri, doc.source)\n\n\n@server.feature(TEXT_DOCUMENT_DID_CHANGE)\nasync def did_change(params: DidChangeTextDocumentParams):\n    logfire.debug(f\"Document changed: {params.text_document.uri}\")\n    doc = server.workspace.get_text_document(params.text_document.uri)\n    await server.debounced_analyze(doc.uri, doc.source)\n\n\n@server.feature(\n    TEXT_DOCUMENT_CODE_ACTION,\n    CodeActionOptions(code_action_kinds=[CodeActionKind.QuickFix]),\n)\nasync def code_actions(params: CodeActionParams) -> list[CodeAction]:\n    with logfire.span(\"code_actions\", uri=params.text_document.uri):\n        actions: list[CodeAction] = []\n        uri = params.text_document.uri\n        doc = server.workspace.get_text_document(uri)\n\n        for diagnostic in params.context.diagnostics:\n            if diagnostic.source != \"ai-lsp\" or not diagnostic.data:\n                continue\n\n            suggested_fixes = diagnostic.data.get(\"suggested_fixes\", [])\n\n            for fix_data in suggested_fixes:\n                target_positions = server.find_snippet_in_text(\n                    doc.source, fix_data[\"target_snippet\"]\n                )\n\n                if target_positions:\n                    with logfire.span(\"creating_quick_fix\", title=fix_data[\"title\"]):\n                        start_line, start_col, end_line, end_col = target_positions[0]\n                        fix_range = Range(\n                            start=Position(line=start_line, character=start_col),\n                            end=Position(line=end_line, character=end_col),\n                        )\n\n                        edit = WorkspaceEdit(\n                            changes={\n                                uri: [\n                                    TextEdit(\n                                        range=fix_range,\n                                        new_text=fix_data[\"replacement_snippet\"],\n                                    )\n                                ]\n                            }\n                        )\n\n                        action = CodeAction(\n                            title=f\"Apply: {fix_data['title']}\",\n                            kind=CodeActionKind.QuickFix,\n                            edit=edit,\n                            diagnostics=[diagnostic],\n                            is_preferred=True,\n                        )\n                        actions.append(action)\n\n            actions.append(\n                CodeAction(\n                    title=\"Regenerate AI fix\",\n                    kind=CodeActionKind.QuickFix,\n                    command=Command(\n                        title=\"Regenerate fix\",\n                        command=\"ai-lsp.regenerateFix\",\n                        arguments=[\n                            uri,\n                            diagnostic.data.get(\"issue_snippet\"),\n                            diagnostic.range.start.line,\n                            diagnostic.range.start.character,\n                        ],\n                    ),\n                    diagnostics=[diagnostic],\n                )\n            )\n\n            actions.append(\n                CodeAction(\n                    title=\"Dismiss AI suggestion\",\n                    kind=CodeActionKind.QuickFix,\n                    command=Command(\n                        title=\"Dismiss\",\n                        command=\"ai-lsp.dismiss\",\n                        arguments=[\n                            uri,\n                            diagnostic.range.start.line,\n                            diagnostic.range.start.character,\n                        ],\n                    ),\n                    diagnostics=[diagnostic],\n                )\n            )\n\n        return actions\n\n\n@server.command(\"ai-lsp.regenerateFix\")\nasync def regenerate_fix(*args):\n    if len(args) < 4:\n        return\n\n    uri, issue_snippet, line, character = args[0], args[1], args[2], args[3]\n\n    with logfire.span(\"regenerate_fix\", uri=uri, issue_snippet=issue_snippet):\n        logfire.info(\n            f\"Regenerating fix for '{issue_snippet}' at {uri}:{line}:{character}\"\n        )\n\n        doc = server.workspace.get_text_document(uri)\n        file_path = Path(uri.replace(\"file:\/\/\", \"\"))\n        language = server._detect_language(file_path)\n\n        prompt = f\"\"\"Analyze this specific code issue and provide NEW suggested fixes.\n\nIssue snippet: {issue_snippet}\n\nFull code context:\n```{language}\n{doc.source}\n```\n\nFile: {file_path.name}\n\nFocus ONLY on the issue at the snippet shown. Provide fresh, alternative fixes if possible.\"\"\"\n\n        try:\n            result = await server.agent.run(prompt)\n\n            if not result.output.issues:\n                logfire.warn(\"No issues returned for regeneration\")\n                return\n\n            regenerated_issue = result.output.issues[0]\n\n            current_diags = getattr(server.lsp, \"diagnostics\", {}).get(uri, [])\n            updated_diags = []\n\n            for diag in current_diags:\n                if (\n                    diag.source == \"ai-lsp\"\n                    and diag.range.start.line == line\n                    and diag.range.start.character == character\n                ):\n                    positions = server.find_snippet_in_text(\n                        doc.source, regenerated_issue.issue_snippet\n                    )\n                    if positions:\n                        start_line, start_col, end_line, end_col = positions[0]\n                        updated_diag = Diagnostic(\n                            range=Range(\n                                start=Position(line=start_line, character=start_col),\n                                end=Position(line=end_line, character=end_col),\n                            ),\n                            message=f\"AI LSP: {regenerated_issue.message}\",\n                            severity=server._get_diagnostic_severity(\n                                regenerated_issue.severity\n                            ),\n                            source=\"ai-lsp\",\n                            data={\n                                \"issue_snippet\": regenerated_issue.issue_snippet,\n                                \"suggested_fixes\": [\n                                    {\n                                        \"title\": fix.title,\n                                        \"target_snippet\": fix.target_snippet,\n                                        \"replacement_snippet\": fix.replacement_snippet,\n                                    }\n                                    for fix in (regenerated_issue.suggested_fixes or [])\n                                ],\n                            },\n                        )\n                        updated_diags.append(updated_diag)\n                        logfire.info(\n                            f\"Regenerated diagnostic with {len(regenerated_issue.suggested_fixes or [])} new fixes\"\n                        )\n                else:\n                    updated_diags.append(diag)\n\n            server.publish_diagnostics(uri, updated_diags)\n\n        except Exception as e:\n            logfire.error(f\"Failed to regenerate fix: {str(e)}\", _exc_info=True)\n\n\n@server.command(\"ai-lsp.dismiss\")\ndef dismiss_suggestion(*args):\n    if len(args) < 3:\n        return\n\n    uri, line, character = args[0], args[1], args[2]\n\n    with logfire.span(\"dismiss_suggestion\", uri=uri, line=line, character=character):\n        logfire.info(f\"Dismissing suggestion at {uri}:{line}:{character}\")\n\n        doc = server.workspace.get_text_document(uri)\n        diagnostics = []\n\n        current_diags = getattr(server.lsp, \"diagnostics\", {}).get(uri, [])\n        for diag in current_diags:\n            if (\n                diag.source == \"ai-lsp\"\n                and diag.range.start.line == line\n                and diag.range.start.character == character\n            ):\n                continue\n            diagnostics.append(diag)\n\n        server.publish_diagnostics(uri, diagnostics)\n\n\ndef app():\n    server.start_io()\n\n\nif __name__ == \"__main__\":\n    app()\n\n```\n\nFile: main.py","assistant":"{\n  \"issues\": [\n    {\n      \"issue_snippet\": \"find_snippet_in_text\",\n      \"severity\": \"error\",\n      \"message\": \"The `find_snippet_in_text` method relies on exact string matching for `issue_snippet` and `target_snippet` from the AI. This approach is brittle and highly susceptible to failure due to minor differences (e.g., whitespace, line endings, or user modifications to the code). If the snippet from the AI does not exactly match the document text, diagnostics will not be placed, or quick-fixes will not be offered, despite the AI identifying a valid issue or fix. This severely impacts the reliability and user experience of the AI-LSP integration.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Implement robust snippet matching\",\n          \"target_snippet\": \"def find_snippet_in_text(\",\n          \"replacement_snippet\": \"def find_snippet_in_text_robust(\"\n        },\n        {\n          \"title\": \"Consider fuzzy matching or AST-based location\",\n          \"target_snippet\": \"snippet = snippet.strip()\",\n          \"replacement_snippet\": \"# Consider fuzzy matching, diff-based matching, or AST-based matching\\nsnippet = snippet.strip()\"\n        }\n      ]\n    },\n    {\n      \"issue_snippet\": \"regenerated_issue.issue_snippet\",\n      \"severity\": \"error\",\n      \"message\": \"In the `regenerate_fix` command, the `range` of the updated diagnostic is determined by re-searching for the `regenerated_issue.issue_snippet`. If the regenerated snippet from the AI differs from the original or if the code has changed, the diagnostic's position might 'jump' to a new, potentially incorrect location or disappear entirely. This breaks the user's mental model of updating a specific issue and leads to a confusing and unstable user experience, as the diagnostic's location loses its anchor to the original problem.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Anchor regenerated diagnostics to original range\",\n          \"target_snippet\": \"positions = server.find_snippet_in_text(\\n                        doc.source, regenerated_issue.issue_snippet\\n                    )\",\n          \"replacement_snippet\": \"# Preserve original diagnostic range or adjust relative to it.\\n# If regenerated_issue.issue_snippet is provided, search within\/near the original range.\\npositions = server.find_snippet_in_text(doc.source, regenerated_issue.issue_snippet)\"\n        },\n        {\n          \"title\": \"Prompt AI for relative range or diffs\",\n          \"target_snippet\": \"prompt = f\\\"\\\"\\\"Analyze this specific code issue and provide NEW suggested fixes.\",\n          \"replacement_snippet\": \"prompt = f\\\"\\\"\\\"Analyze this specific code issue (originally at {line}:{character}) and provide NEW suggested fixes, ideally targeting the same area or providing relative offsets.\"\n        }\n      ]\n    },\n    {\n      \"issue_snippet\": \"server.lsp.diagnostics\",\n      \"severity\": \"warning\",\n      \"message\": \"The `regenerate_fix` and `dismiss_suggestion` commands directly access `server.lsp.diagnostics`. This relies on an internal, undocumented attribute of `pygls` and is not part of its public API. Such direct access creates a brittle dependency that could break with future `pygls` updates, affecting the maintainability and robustness of the LSP server.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Use public pygls API for diagnostics management\",\n          \"target_snippet\": \"current_diags = getattr(server.lsp, \\\"diagnostics\\\", {}).get(uri, [])\",\n          \"replacement_snippet\": \"# Replace with official pygls API for managing diagnostics if available.\\n# Example (concept only): current_diags = server.workspace.get_document_diagnostics(uri)\"\n        },\n        {\n          \"title\": \"Document internal dependency\",\n          \"target_snippet\": \"current_diags = getattr(server.lsp, \\\"diagnostics\\\", {}).get(uri, [])\",\n          \"replacement_snippet\": \"current_diags = getattr(server.lsp, \\\"diagnostics\\\", {}).get(uri, []) # WARNING: Internal pygls API, subject to change. Monitor pygls updates.\"\n        }\n      ]\n    },\n    {\n      \"issue_snippet\": \"send_to_logfire=False\",\n      \"severity\": \"warning\",\n      \"message\": \"The `logfire.configure` call explicitly sets `send_to_logfire=False`. However, `os.environ[\\\"OTEL_EXPORTER_OTLP_ENDPOINT\\\"]` is set to a specific OTLP endpoint, and `logfire.instrument_pydantic_ai()` and `logfire.instrument_httpx()` are called. Setting `send_to_logfire=False` disables Logfire's built-in OTLP exporter, preventing any telemetry generated by the instrumentation from being sent to the configured endpoint. This creates a contradictory configuration that likely results in a lack of observability despite the instrumentation being active.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Enable telemetry sending for Logfire\",\n          \"target_snippet\": \"send_to_logfire=False\",\n          \"replacement_snippet\": \"send_to_logfire=True\"\n        },\n        {\n          \"title\": \"Remove unnecessary OTLP endpoint environment variable if telemetry is not desired\",\n          \"target_snippet\": \"os.environ[\\\"OTEL_EXPORTER_OTLP_ENDPOINT\\\"] = settings.otel_exporter_otlp_endpoint\\n\\nif settings.configure_logfire:\\n    logfire.configure(send_to_logfire=False, service_name=\\\"ai-lsp\\\")\",\n          \"replacement_snippet\": \"if settings.configure_logfire:\\n    # Telemetry sending is explicitly disabled, so OTLP endpoint setting is moot for Logfire.\\n    logfire.configure(send_to_logfire=False, service_name=\\\"ai-lsp\\\")\"\n        }\n      ]\n    }\n  ]\n}"}
{"system":"You are an AI code analyzer that provides semantic insights that traditional LSPs cannot detect.\n\nONLY flag issues that require deep semantic understanding:\n- Logic errors in algorithms or business logic\n- Subtle race conditions or concurrency issues  \n- Architectural problems and design pattern violations\n- Security vulnerabilities requiring context understanding\n- Performance anti-patterns that need semantic analysis\n- Complex data flow issues\n- Domain-specific best practice violations\n- Accessibility issues requiring UX understanding\n\nDO NOT flag issues that normal LSPs handle:\n- Syntax errors\n- Basic type errors  \n- Undefined variables\n- Import issues\n- Basic formatting problems\n- Simple linting rules\n\nFor each issue, provide:\n- The exact issue_snippet that has the problem (ONLY the problematic token\/value, e.g. just \"python\" not 'command = \"python\"')\n- Clear explanation of WHY this needs human attention in the message\n- Use severity: \"info\" for suggestions, \"warning\" for concerns, \"error\" for serious logic issues\n- When possible, provide suggested_fixes with:\n  - target_snippet: the exact code to replace (same as issue_snippet usually)\n  - replacement_snippet: the replacement code\n  - title: clear description of the fix\n\nFocus on insights that require understanding code intent and context. Keep issue_snippet to the absolute minimum - just the problematic token.","user":"Analyze this python code for issues:\n\n```python\n\n\n```\n\nFile: models.py","assistant":"{\n  \"issues\": []\n}"}
{"system":"You are an AI code analyzer that provides semantic insights that traditional LSPs cannot detect.\n\nONLY flag issues that require deep semantic understanding:\n- Logic errors in algorithms or business logic\n- Subtle race conditions or concurrency issues  \n- Architectural problems and design pattern violations\n- Security vulnerabilities requiring context understanding\n- Performance anti-patterns that need semantic analysis\n- Complex data flow issues\n- Domain-specific best practice violations\n- Accessibility issues requiring UX understanding\n\nDO NOT flag issues that normal LSPs handle:\n- Syntax errors\n- Basic type errors  \n- Undefined variables\n- Import issues\n- Basic formatting problems\n- Simple linting rules\n\nFor each issue, provide:\n- The exact issue_snippet that has the problem (ONLY the problematic token\/value, e.g. just \"python\" not 'command = \"python\"')\n- Clear explanation of WHY this needs human attention in the message\n- Use severity: \"info\" for suggestions, \"warning\" for concerns, \"error\" for serious logic issues\n- When possible, provide suggested_fixes with:\n  - target_snippet: the exact code to replace (same as issue_snippet usually)\n  - replacement_snippet: the replacement code\n  - title: clear description of the fix\n\nFocus on insights that require understanding code intent and context. Keep issue_snippet to the absolute minimum - just the problematic token.","user":"Analyze this python code for issues:\n\n```python\nimport asyncio\nimport os\nfrom pathlib import Path\nfrom typing import Any, Literal\nfrom importlib.metadata import version\nimport logfire\n\n# pyrefly: ignore [missing-import]\nfrom lsprotocol.types import (\n    TEXT_DOCUMENT_CODE_ACTION,\n    TEXT_DOCUMENT_DID_CHANGE,\n    TEXT_DOCUMENT_DID_OPEN,\n    TEXT_DOCUMENT_DID_SAVE,\n    CodeAction,\n    CodeActionKind,\n    CodeActionOptions,\n    CodeActionParams,\n    Command,\n    Diagnostic,\n    DiagnosticSeverity,\n    DidChangeTextDocumentParams,\n    DidOpenTextDocumentParams,\n    DidSaveTextDocumentParams,\n    Position,\n    Range,\n    TextEdit,\n    WorkspaceEdit,\n)\nfrom pydantic import BaseModel, Field\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models import KnownModelName\nfrom pydantic_settings import BaseSettings\n\n# pyrefly: ignore [missing-import]\nfrom pygls.server import LanguageServer\n\n\nclass Settings(BaseSettings):\n    ai_lsp_model: KnownModelName = Field(default=\"google-gla:gemini-2.5-flash\")\n    debounce_ms: int = Field(default=1000)\n    max_cache_size: int = Field(default=50)\n    configure_logfire: bool = Field(default=True)\n    otel_exporter_otlp_endpoint: str = Field(default=\"http:\/\/localhost:4318\")\n\n\n\n\nclass SuggestedFix(BaseModel):\n    title: str\n    target_snippet: str\n    replacement_snippet: str\n\n\nclass CodeIssue(BaseModel):\n    issue_snippet: str\n    severity: Literal[\"error\", \"warning\", \"info\", \"hint\"]\n    message: str\n    suggested_fixes: list[SuggestedFix] | None = None\n\n\nclass DiagnosticResult(BaseModel):\n    issues: list[CodeIssue]\n\nsettings = Settings()\n\n\nos.environ[\"OTEL_EXPORTER_OTLP_ENDPOINT\"] = settings.otel_exporter_otlp_endpoint\n\nif settings.configure_logfire:\n    logfire.configure(send_to_logfire=False, service_name=\"ai-lsp\")  # pyright: ignore[reportUnusedCallResult]\n    logfire.instrument_pydantic_ai()\n    logfire.instrument_httpx(capture_all=True)\n\nclass AILanguageServer(LanguageServer):\n    def __init__(self):\n        super().__init__(\"ai-lsp\", version(\"ai-lsp\"))\n        logfire.info(\"Initializing AI Language Server\")\n        self._pending_tasks: dict[str, asyncio.Task[Any]] = {}\n        self._analysis_locks: dict[str, asyncio.Lock] = {}\n\n        self.agent: Agent[DiagnosticResult, Any] = Agent(\n            model=settings.ai_lsp_model,\n            output_type=DiagnosticResult,\n            system_prompt=\"\"\"You are an AI code analyzer that provides semantic insights that traditional LSPs cannot detect.\n\nONLY flag issues that require deep semantic understanding:\n- Logic errors in algorithms or business logic\n- Subtle race conditions or concurrency issues  \n- Architectural problems and design pattern violations\n- Security vulnerabilities requiring context understanding\n- Performance anti-patterns that need semantic analysis\n- Complex data flow issues\n- Domain-specific best practice violations\n- Accessibility issues requiring UX understanding\n\nDO NOT flag issues that normal LSPs handle:\n- Syntax errors\n- Basic type errors  \n- Undefined variables\n- Import issues\n- Basic formatting problems\n- Simple linting rules\n\nFor each issue, provide:\n- The exact issue_snippet that has the problem (ONLY the problematic token\/value, e.g. just \"python\" not 'command = \"python\"')\n- Clear explanation of WHY this needs human attention in the message\n- Use severity: \"info\" for suggestions, \"warning\" for concerns, \"error\" for serious logic issues\n- When possible, provide suggested_fixes with:\n  - target_snippet: the exact code to replace (same as issue_snippet usually)\n  - replacement_snippet: the replacement code\n  - title: clear description of the fix\n\nFocus on insights that require understanding code intent and context. Keep issue_snippet to the absolute minimum - just the problematic token.\"\"\",\n        )\n        logfire.info(\"AI agent initialized successfully\")\n\n    def find_snippet_in_text(\n        self, text: str, snippet: str\n    ) -> list[tuple[int, int, int, int]]:\n        \"\"\"Find all occurrences of code snippet in text, return positions as (start_line, start_col, end_line, end_col)\"\"\"\n        snippet = snippet.strip()\n        positions = []\n\n        # Search for all occurrences of snippet\n        start_pos = 0\n        while True:\n            start_pos = text.find(snippet, start_pos)\n            if start_pos == -1:\n                break\n\n            # Convert character position to line\/column\n            lines = text[:start_pos].split(\"\\n\")\n            start_line = len(lines) - 1\n            start_col = len(lines[-1])\n\n            # Calculate end position\n            snippet_lines = snippet.split(\"\\n\")\n            if len(snippet_lines) == 1:\n                end_line = start_line\n                end_col = start_col + len(snippet)\n            else:\n                end_line = start_line + len(snippet_lines) - 1\n                end_col = len(snippet_lines[-1])\n\n            positions.append((start_line, start_col, end_line, end_col))\n            start_pos += 1  # Move past this occurrence\n\n        if not positions:\n            logfire.warn(f\"Could not find snippet '{snippet}' in text\")\n        else:\n            logfire.debug(f\"Found {len(positions)} occurrences of '{snippet[:20]}...'\")\n\n        return positions\n\n    async def debounced_analyze(self, uri: str, text: str):\n        \"\"\"Debounced analysis that cancels previous calls\"\"\"\n        # Cancel any existing task for this URI\n        if uri in self._pending_tasks:\n            self._pending_tasks[uri].cancel()\n            _ = self._pending_tasks.pop(uri, None)\n\n        # Create new task\n        task: asyncio.Task[None] = asyncio.create_task(self._delayed_analyze(uri, text))\n        self._pending_tasks[uri] = task\n\n        try:\n            await task\n        except asyncio.CancelledError:\n            logfire.debug(f\"Analysis cancelled for {uri}\")\n        finally:\n            # Clean up completed task\n            if uri in self._pending_tasks and self._pending_tasks[uri] == task:\n                _ = self._pending_tasks.pop(uri)\n\n    async def _delayed_analyze(self, uri: str, text: str):\n        \"\"\"Wait for debounce period then analyze\"\"\"\n        await asyncio.sleep(settings.debounce_ms \/ 1000.0)\n        diagnostics = await self.analyze_document(uri, text)\n        # pyrefly: ignore [missing-attribute]\n        self.publish_diagnostics(uri, diagnostics)\n        logfire.debug(f\"Published {len(diagnostics)} diagnostics for {uri}\")\n\n    async def analyze_document(self, uri: str, text: str) -> list[Diagnostic]:\n        # Ensure we have a lock for this URI\n        lock = self._analysis_locks.setdefault(uri, asyncio.Lock())\n        async with lock:\n            with logfire.span(\"analyze_document\", uri=uri):\n                logfire.info(f\"Starting AI analysis for {uri}\")\n\n                try:\n                    file_path = Path(uri.replace(\"file:\/\/\", \"\"))\n                    language = self._detect_language(file_path)\n\n                    prompt = f\"\"\"Analyze this {language} code for issues:\n\n```{language}\n{text}\n```\n\nFile: {file_path.name}\"\"\"\n\n                    result = await self.agent.run(prompt)\n                    logfire.info(\n                        f\"AI analysis completed, found {len(result.output.issues)} issues\"\n                    )\n\n                    diagnostics = []\n                    for issue in result.output.issues:\n                        positions = self.find_snippet_in_text(text, issue.issue_snippet)\n\n                        if positions:\n                            start_line, start_col, end_line, end_col = positions[0]\n                            diagnostic = Diagnostic(\n                                range=Range(\n                                    start=Position(\n                                        line=start_line, character=start_col\n                                    ),\n                                    end=Position(line=end_line, character=end_col),\n                                ),\n                                message=f\"AI LSP: {issue.message}\",\n                                severity=self._get_diagnostic_severity(issue.severity),\n                                source=\"ai-lsp\",\n                                data={\n                                    \"issue_snippet\": issue.issue_snippet,\n                                    \"suggested_fixes\": [\n                                        {\n                                            \"title\": fix.title,\n                                            \"target_snippet\": fix.target_snippet,\n                                            \"replacement_snippet\": fix.replacement_snippet,\n                                        }\n                                        for fix in (issue.suggested_fixes or [])\n                                    ],\n                                },\n                            )\n                            diagnostics.append(diagnostic)\n\n                    return diagnostics\n\n                except Exception as e:\n                    logfire.error(\n                        f\"AI analysis failed for {uri}: {str(e)}\", _exc_info=True\n                    )\n                    return []\n\n    def _get_diagnostic_severity(self, severity: str) -> DiagnosticSeverity:\n        match severity:\n            case \"error\":\n                return DiagnosticSeverity.Error\n            case \"warning\":\n                return DiagnosticSeverity.Warning\n            case \"info\":\n                return DiagnosticSeverity.Information\n            case \"hint\":\n                return DiagnosticSeverity.Hint\n            case _:\n                return DiagnosticSeverity.Information\n\n    def _detect_language(self, file_path: Path) -> str:\n        match file_path.suffix:\n            case \".py\":\n                return \"python\"\n            case \".js\":\n                return \"javascript\"\n            case \".ts\":\n                return \"typescript\"\n            case \".jsx\":\n                return \"jsx\"\n            case \".tsx\":\n                return \"tsx\"\n            case \".rs\":\n                return \"rust\"\n            case \".go\":\n                return \"go\"\n            case \".java\":\n                return \"java\"\n            case \".cpp\":\n                return \"cpp\"\n            case \".c\":\n                return \"c\"\n            case \".lua\":\n                return \"lua\"\n            case _:\n                return \"text\"\n\n\nserver = AILanguageServer()\n\n\n@server.feature(TEXT_DOCUMENT_DID_OPEN)\nasync def did_open(params: DidOpenTextDocumentParams):\n    logfire.info(f\"Document opened: {params.text_document.uri}\")\n    doc = params.text_document\n    await server.debounced_analyze(doc.uri, doc.text)\n\n\n@server.feature(TEXT_DOCUMENT_DID_SAVE)\nasync def did_save(params: DidSaveTextDocumentParams):\n    logfire.info(f\"Document saved: {params.text_document.uri}\")\n    doc = server.workspace.get_text_document(params.text_document.uri)\n    await server.debounced_analyze(doc.uri, doc.source)\n\n\n@server.feature(TEXT_DOCUMENT_DID_CHANGE)\nasync def did_change(params: DidChangeTextDocumentParams):\n    logfire.debug(f\"Document changed: {params.text_document.uri}\")\n    doc = server.workspace.get_text_document(params.text_document.uri)\n    await server.debounced_analyze(doc.uri, doc.source)\n\n\n@server.feature(\n    TEXT_DOCUMENT_CODE_ACTION,\n    CodeActionOptions(code_action_kinds=[CodeActionKind.QuickFix]),\n)\nasync def code_actions(params: CodeActionParams) -> list[CodeAction]:\n    with logfire.span(\"code_actions\", uri=params.text_document.uri):\n        actions: list[CodeAction] = []\n        uri = params.text_document.uri\n        doc = server.workspace.get_text_document(uri)\n\n        for diagnostic in params.context.diagnostics:\n            if diagnostic.source != \"ai-lsp\" or not diagnostic.data:\n                continue\n\n            suggested_fixes = diagnostic.data.get(\"suggested_fixes\", [])\n\n            for fix_data in suggested_fixes:\n                target_positions = server.find_snippet_in_text(\n                    doc.source, fix_data[\"target_snippet\"]\n                )\n\n                if target_positions:\n                    with logfire.span(\"creating_quick_fix\", title=fix_data[\"title\"]):\n                        start_line, start_col, end_line, end_col = target_positions[0]\n                        fix_range = Range(\n                            start=Position(line=start_line, character=start_col),\n                            end=Position(line=end_line, character=end_col),\n                        )\n\n                        edit = WorkspaceEdit(\n                            changes={\n                                uri: [\n                                    TextEdit(\n                                        range=fix_range,\n                                        new_text=fix_data[\"replacement_snippet\"],\n                                    )\n                                ]\n                            }\n                        )\n\n                        action = CodeAction(\n                            title=f\"Apply: {fix_data['title']}\",\n                            kind=CodeActionKind.QuickFix,\n                            edit=edit,\n                            diagnostics=[diagnostic],\n                            is_preferred=True,\n                        )\n                        actions.append(action)\n\n            actions.append(\n                CodeAction(\n                    title=\"Regenerate AI fix\",\n                    kind=CodeActionKind.QuickFix,\n                    command=Command(\n                        title=\"Regenerate fix\",\n                        command=\"ai-lsp.regenerateFix\",\n                        arguments=[\n                            uri,\n                            diagnostic.data.get(\"issue_snippet\"),\n                            diagnostic.range.start.line,\n                            diagnostic.range.start.character,\n                        ],\n                    ),\n                    diagnostics=[diagnostic],\n                )\n            )\n\n            actions.append(\n                CodeAction(\n                    title=\"Dismiss AI suggestion\",\n                    kind=CodeActionKind.QuickFix,\n                    command=Command(\n                        title=\"Dismiss\",\n                        command=\"ai-lsp.dismiss\",\n                        arguments=[\n                            uri,\n                            diagnostic.range.start.line,\n                            diagnostic.range.start.character,\n                        ],\n                    ),\n                    diagnostics=[diagnostic],\n                )\n            )\n\n        return actions\n\n\n@server.command(\"ai-lsp.regenerateFix\")\nasync def regenerate_fix(*args):\n    if len(args) < 4:\n        return\n\n    uri, issue_snippet, line, character = args[0], args[1], args[2], args[3]\n\n    with logfire.span(\"regenerate_fix\", uri=uri, issue_snippet=issue_snippet):\n        logfire.info(\n            f\"Regenerating fix for '{issue_snippet}' at {uri}:{line}:{character}\"\n        )\n\n        doc = server.workspace.get_text_document(uri)\n        file_path = Path(uri.replace(\"file:\/\/\", \"\"))\n        language = server._detect_language(file_path)\n\n        prompt = f\"\"\"Analyze this specific code issue and provide NEW suggested fixes.\n\nIssue snippet: {issue_snippet}\n\nFull code context:\n```{language}\n{doc.source}\n```\n\nFile: {file_path.name}\n\nFocus ONLY on the issue at the snippet shown. Provide fresh, alternative fixes if possible.\"\"\"\n\n        try:\n            result = await server.agent.run(prompt)\n\n            if not result.output.issues:\n                logfire.warn(\"No issues returned for regeneration\")\n                return\n\n            regenerated_issue = result.output.issues[0]\n\n            current_diags = getattr(server.lsp, \"diagnostics\", {}).get(uri, [])\n            updated_diags = []\n\n            for diag in current_diags:\n                if (\n                    diag.source == \"ai-lsp\"\n                    and diag.range.start.line == line\n                    and diag.range.start.character == character\n                ):\n                    positions = server.find_snippet_in_text(\n                        doc.source, regenerated_issue.issue_snippet\n                    )\n                    if positions:\n                        start_line, start_col, end_line, end_col = positions[0]\n                        updated_diag = Diagnostic(\n                            range=Range(\n                                start=Position(line=start_line, character=start_col),\n                                end=Position(line=end_line, character=end_col),\n                            ),\n                            message=f\"AI LSP: {regenerated_issue.message}\",\n                            severity=server._get_diagnostic_severity(\n                                regenerated_issue.severity\n                            ),\n                            source=\"ai-lsp\",\n                            data={\n                                \"issue_snippet\": regenerated_issue.issue_snippet,\n                                \"suggested_fixes\": [\n                                    {\n                                        \"title\": fix.title,\n                                        \"target_snippet\": fix.target_snippet,\n                                        \"replacement_snippet\": fix.replacement_snippet,\n                                    }\n                                    for fix in (regenerated_issue.suggested_fixes or [])\n                                ],\n                            },\n                        )\n                        updated_diags.append(updated_diag)\n                        logfire.info(\n                            f\"Regenerated diagnostic with {len(regenerated_issue.suggested_fixes or [])} new fixes\"\n                        )\n                else:\n                    updated_diags.append(diag)\n\n            server.publish_diagnostics(uri, updated_diags)\n\n        except Exception as e:\n            logfire.error(f\"Failed to regenerate fix: {str(e)}\", _exc_info=True)\n\n\n@server.command(\"ai-lsp.dismiss\")\ndef dismiss_suggestion(*args):\n    if len(args) < 3:\n        return\n\n    uri, line, character = args[0], args[1], args[2]\n\n    with logfire.span(\"dismiss_suggestion\", uri=uri, line=line, character=character):\n        logfire.info(f\"Dismissing suggestion at {uri}:{line}:{character}\")\n\n        doc = server.workspace.get_text_document(uri)\n        diagnostics = []\n\n        current_diags = getattr(server.lsp, \"diagnostics\", {}).get(uri, [])\n        for diag in current_diags:\n            if (\n                diag.source == \"ai-lsp\"\n                and diag.range.start.line == line\n                and diag.range.start.character == character\n            ):\n                continue\n            diagnostics.append(diag)\n\n        server.publish_diagnostics(uri, diagnostics)\n\n\ndef app():\n    server.start_io()\n\n\nif __name__ == \"__main__\":\n    app()\n\n```\n\nFile: main.py","assistant":"{\n  \"issues\": [\n    {\n      \"issue_snippet\": \"positions[0]\",\n      \"severity\": \"error\",\n      \"message\": \"The AI analysis relies on `issue_snippet` and `target_snippet` to locate problems and apply fixes. The current implementation, however, only uses the *first* occurrence of these snippets found in the document (`positions[0]`). If the same snippet appears multiple times, the diagnostic or code action might be applied to an incorrect location, leading to misinterpretations or unintended code changes. This severely compromises the precision and reliability of the AI-powered LSP features.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Enhance AI output with precise location data\",\n          \"target_snippet\": \"positions[0]\",\n          \"replacement_snippet\": \"This issue requires a fundamental change to the `DiagnosticResult` and `CodeIssue` models, as well as the AI agent's prompt, to include line and character information for `issue_snippet` and `target_snippet`. This precise location data should then be used directly to create `Range` objects, rather than relying on string searching and `positions[0]`.\"\n        }\n      ]\n    },\n    {\n      \"issue_snippet\": \"getattr(server.lsp, \\\"diagnostics\\\", {}).get(uri, [])\",\n      \"severity\": \"warning\",\n      \"message\": \"Accessing `server.lsp.diagnostics` directly is an architectural anti-pattern. This relies on internal implementation details of `pygls` and can lead to fragile code that breaks if the library's internals change. While `server` itself is a `LanguageServer` instance, `_diagnostics` is a private attribute. A more robust solution would involve `AILanguageServer` managing its own diagnostic state or using a public API if `pygls` were to provide one for retrieving current diagnostics.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Use `server._diagnostics` directly (with caution)\",\n          \"target_snippet\": \"getattr(server.lsp, \\\"diagnostics\\\", {}).get(uri, [])\",\n          \"replacement_snippet\": \"server._diagnostics.get(uri, [])\"\n        }\n      ]\n    }\n  ]\n}"}
{"system":"You are an AI code analyzer that provides semantic insights that traditional LSPs cannot detect.\n\nONLY flag issues that require deep semantic understanding:\n- Logic errors in algorithms or business logic\n- Subtle race conditions or concurrency issues  \n- Architectural problems and design pattern violations\n- Security vulnerabilities requiring context understanding\n- Performance anti-patterns that need semantic analysis\n- Complex data flow issues\n- Domain-specific best practice violations\n- Accessibility issues requiring UX understanding\n\nDO NOT flag issues that normal LSPs handle:\n- Syntax errors\n- Basic type errors  \n- Undefined variables\n- Import issues\n- Basic formatting problems\n- Simple linting rules\n\nFor each issue, provide:\n- The exact issue_snippet that has the problem (ONLY the problematic token\/value, e.g. just \"python\" not 'command = \"python\"')\n- Clear explanation of WHY this needs human attention in the message\n- Use severity: \"info\" for suggestions, \"warning\" for concerns, \"error\" for serious logic issues\n- When possible, provide suggested_fixes with:\n  - target_snippet: the exact code to replace (same as issue_snippet usually)\n  - replacement_snippet: the replacement code\n  - title: clear description of the fix\n\nFocus on insights that require understanding code intent and context. Keep issue_snippet to the absolute minimum - just the problematic token.","user":"Analyze this python code for issues:\n\n```python\nfrom typing import Literal\n\n# pyrefly: ignore [missing-import]\nfrom pydantic import BaseModel, Field\nfrom pydantic_ai.models import KnownModelName\nfrom pydantic_settings import BaseSettings\n\n# pyrefly: ignore [missing-import]\n\n\nclass Settings(BaseSettings):\n    ai_lsp_model: KnownModelName = Field(default=\"google-gla:gemini-2.5-flash\")\n    debounce_ms: int = Field(default=1000)\n    max_cache_size: int = Field(default=50)\n    configure_logfire: bool = Field(default=True)\n    otel_exporter_otlp_endpoint: str = Field(default=\"http:\/\/localhost:4318\")\n\n\nclass SuggestedFix(BaseModel):\n    title: str\n    target_snippet: str\n    replacement_snippet: str\n\n\nclass CodeIssue(BaseModel):\n    issue_snippet: str\n    severity: Literal[\"error\", \"warning\", \"info\", \"hint\"]\n    message: str\n    suggested_fixes: list[SuggestedFix] | None = None\n\n\nclass DiagnosticResult(BaseModel):\n    issues: list[CodeIssue]\n\n```\n\nFile: models.py","assistant":"{\n  \"issues\": [\n    {\n      \"issue_snippet\": \"http:\/\/localhost:4318\",\n      \"severity\": \"warning\",\n      \"message\": \"The default OTLP exporter endpoint points to `localhost`. In a production or deployed environment, this will likely fail as `localhost` refers to the container or machine itself, not an external OpenTelemetry collector. This default can lead to silent failures in observability data collection if not explicitly overridden for deployment. Consider making this an environment-specific setting or defaulting to `None` if it's mandatory.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Make OTLP endpoint configurable and default to None\",\n          \"target_snippet\": \"http:\/\/localhost:4318\",\n          \"replacement_snippet\": \"None\"\n        },\n        {\n          \"title\": \"Use an empty string as a default placeholder to indicate it needs configuration\",\n          \"target_snippet\": \"http:\/\/localhost:4318\",\n          \"replacement_snippet\": \"\\\"\\\"\"\n        }\n      ]\n    }\n  ]\n}"}
{"system":"You are an AI code analyzer that provides semantic insights that traditional LSPs cannot detect.\n\nONLY flag issues that require deep semantic understanding:\n- Logic errors in algorithms or business logic\n- Subtle race conditions or concurrency issues  \n- Architectural problems and design pattern violations\n- Security vulnerabilities requiring context understanding\n- Performance anti-patterns that need semantic analysis\n- Complex data flow issues\n- Domain-specific best practice violations\n- Accessibility issues requiring UX understanding\n\nDO NOT flag issues that normal LSPs handle:\n- Syntax errors\n- Basic type errors  \n- Undefined variables\n- Import issues\n- Basic formatting problems\n- Simple linting rules\n\nFor each issue, provide:\n- The exact issue_snippet that has the problem (ONLY the problematic token\/value, e.g. just \"python\" not 'command = \"python\"')\n- Clear explanation of WHY this needs human attention in the message\n- Use severity: \"info\" for suggestions, \"warning\" for concerns, \"error\" for serious logic issues\n- When possible, provide suggested_fixes with:\n  - target_snippet: the exact code to replace (same as issue_snippet usually)\n  - replacement_snippet: the replacement code\n  - title: clear description of the fix\n\nFocus on insights that require understanding code intent and context. Keep issue_snippet to the absolute minimum - just the problematic token.","user":"Analyze this python code for issues:\n\n```python\nfrom ai_lsp.models import DiagnosticResult\nfrom ai_lsp.models import Settings\nimport asyncio\nimport os\nfrom pathlib import Path\nfrom typing import Any, Literal\nfrom importlib.metadata import version\nimport logfire\n\n# pyrefly: ignore [missing-import]\nfrom lsprotocol.types import (\n    TEXT_DOCUMENT_CODE_ACTION,\n    TEXT_DOCUMENT_DID_CHANGE,\n    TEXT_DOCUMENT_DID_OPEN,\n    TEXT_DOCUMENT_DID_SAVE,\n    CodeAction,\n    CodeActionKind,\n    CodeActionOptions,\n    CodeActionParams,\n    Command,\n    Diagnostic,\n    DiagnosticSeverity,\n    DidChangeTextDocumentParams,\n    DidOpenTextDocumentParams,\n    DidSaveTextDocumentParams,\n    Position,\n    Range,\n    TextEdit,\n    WorkspaceEdit,\n)\nfrom pydantic import BaseModel, Field\nfrom pydantic_ai import Agent\nfrom pydantic_ai.models import KnownModelName\nfrom pydantic_settings import BaseSettings\n\n# pyrefly: ignore [missing-import]\nfrom pygls.server import LanguageServer\n\n\n\nsettings = Settings()\n\n\nos.environ[\"OTEL_EXPORTER_OTLP_ENDPOINT\"] = settings.otel_exporter_otlp_endpoint\n\nif settings.configure_logfire:\n    logfire.configure(send_to_logfire=False, service_name=\"ai-lsp\")  # pyright: ignore[reportUnusedCallResult]\n    logfire.instrument_pydantic_ai()\n    logfire.instrument_httpx(capture_all=True)\n\nclass AILanguageServer(LanguageServer):\n    def __init__(self):\n        super().__init__(\"ai-lsp\", version(\"ai-lsp\"))\n        logfire.info(\"Initializing AI Language Server\")\n        self._pending_tasks: dict[str, asyncio.Task[Any]] = {}\n        self._analysis_locks: dict[str, asyncio.Lock] = {}\n\n        self.agent: Agent[DiagnosticResult, Any] = Agent(\n            model=settings.ai_lsp_model,\n            output_type=DiagnosticResult,\n            system_prompt=\"\"\"You are an AI code analyzer that provides semantic insights that traditional LSPs cannot detect.\n\nONLY flag issues that require deep semantic understanding:\n- Logic errors in algorithms or business logic\n- Subtle race conditions or concurrency issues  \n- Architectural problems and design pattern violations\n- Security vulnerabilities requiring context understanding\n- Performance anti-patterns that need semantic analysis\n- Complex data flow issues\n- Domain-specific best practice violations\n- Accessibility issues requiring UX understanding\n\nDO NOT flag issues that normal LSPs handle:\n- Syntax errors\n- Basic type errors  \n- Undefined variables\n- Import issues\n- Basic formatting problems\n- Simple linting rules\n\nFor each issue, provide:\n- The exact issue_snippet that has the problem (ONLY the problematic token\/value, e.g. just \"python\" not 'command = \"python\"')\n- Clear explanation of WHY this needs human attention in the message\n- Use severity: \"info\" for suggestions, \"warning\" for concerns, \"error\" for serious logic issues\n- When possible, provide suggested_fixes with:\n  - target_snippet: the exact code to replace (same as issue_snippet usually)\n  - replacement_snippet: the replacement code\n  - title: clear description of the fix\n\nFocus on insights that require understanding code intent and context. Keep issue_snippet to the absolute minimum - just the problematic token.\"\"\",\n        )\n        logfire.info(\"AI agent initialized successfully\")\n\n    def find_snippet_in_text(\n        self, text: str, snippet: str\n    ) -> list[tuple[int, int, int, int]]:\n        \"\"\"Find all occurrences of code snippet in text, return positions as (start_line, start_col, end_line, end_col)\"\"\"\n        snippet = snippet.strip()\n        positions = []\n\n        # Search for all occurrences of snippet\n        start_pos = 0\n        while True:\n            start_pos = text.find(snippet, start_pos)\n            if start_pos == -1:\n                break\n\n            # Convert character position to line\/column\n            lines = text[:start_pos].split(\"\\n\")\n            start_line = len(lines) - 1\n            start_col = len(lines[-1])\n\n            # Calculate end position\n            snippet_lines = snippet.split(\"\\n\")\n            if len(snippet_lines) == 1:\n                end_line = start_line\n                end_col = start_col + len(snippet)\n            else:\n                end_line = start_line + len(snippet_lines) - 1\n                end_col = len(snippet_lines[-1])\n\n            positions.append((start_line, start_col, end_line, end_col))\n            start_pos += 1  # Move past this occurrence\n\n        if not positions:\n            logfire.warn(f\"Could not find snippet '{snippet}' in text\")\n        else:\n            logfire.debug(f\"Found {len(positions)} occurrences of '{snippet[:20]}...'\")\n\n        return positions\n\n    async def debounced_analyze(self, uri: str, text: str):\n        \"\"\"Debounced analysis that cancels previous calls\"\"\"\n        # Cancel any existing task for this URI\n        if uri in self._pending_tasks:\n            self._pending_tasks[uri].cancel()\n            _ = self._pending_tasks.pop(uri, None)\n\n        # Create new task\n        task: asyncio.Task[None] = asyncio.create_task(self._delayed_analyze(uri, text))\n        self._pending_tasks[uri] = task\n\n        try:\n            await task\n        except asyncio.CancelledError:\n            logfire.debug(f\"Analysis cancelled for {uri}\")\n        finally:\n            # Clean up completed task\n            if uri in self._pending_tasks and self._pending_tasks[uri] == task:\n                _ = self._pending_tasks.pop(uri)\n\n    async def _delayed_analyze(self, uri: str, text: str):\n        \"\"\"Wait for debounce period then analyze\"\"\"\n        await asyncio.sleep(settings.debounce_ms \/ 1000.0)\n        diagnostics = await self.analyze_document(uri, text)\n        # pyrefly: ignore [missing-attribute]\n        self.publish_diagnostics(uri, diagnostics)\n        logfire.debug(f\"Published {len(diagnostics)} diagnostics for {uri}\")\n\n    async def analyze_document(self, uri: str, text: str) -> list[Diagnostic]:\n        # Ensure we have a lock for this URI\n        lock = self._analysis_locks.setdefault(uri, asyncio.Lock())\n        async with lock:\n            with logfire.span(\"analyze_document\", uri=uri):\n                logfire.info(f\"Starting AI analysis for {uri}\")\n\n                try:\n                    file_path = Path(uri.replace(\"file:\/\/\", \"\"))\n                    language = self._detect_language(file_path)\n\n                    prompt = f\"\"\"Analyze this {language} code for issues:\n\n```{language}\n{text}\n```\n\nFile: {file_path.name}\"\"\"\n\n                    result = await self.agent.run(prompt)\n                    logfire.info(\n                        f\"AI analysis completed, found {len(result.output.issues)} issues\"\n                    )\n\n                    diagnostics = []\n                    for issue in result.output.issues:\n                        positions = self.find_snippet_in_text(text, issue.issue_snippet)\n\n                        if positions:\n                            start_line, start_col, end_line, end_col = positions[0]\n                            diagnostic = Diagnostic(\n                                range=Range(\n                                    start=Position(\n                                        line=start_line, character=start_col\n                                    ),\n                                    end=Position(line=end_line, character=end_col),\n                                ),\n                                message=f\"AI LSP: {issue.message}\",\n                                severity=self._get_diagnostic_severity(issue.severity),\n                                source=\"ai-lsp\",\n                                data={\n                                    \"issue_snippet\": issue.issue_snippet,\n                                    \"suggested_fixes\": [\n                                        {\n                                            \"title\": fix.title,\n                                            \"target_snippet\": fix.target_snippet,\n                                            \"replacement_snippet\": fix.replacement_snippet,\n                                        }\n                                        for fix in (issue.suggested_fixes or [])\n                                    ],\n                                },\n                            )\n                            diagnostics.append(diagnostic)\n\n                    return diagnostics\n\n                except Exception as e:\n                    logfire.error(\n                        f\"AI analysis failed for {uri}: {str(e)}\", _exc_info=True\n                    )\n                    return []\n\n    def _get_diagnostic_severity(self, severity: str) -> DiagnosticSeverity:\n        match severity:\n            case \"error\":\n                return DiagnosticSeverity.Error\n            case \"warning\":\n                return DiagnosticSeverity.Warning\n            case \"info\":\n                return DiagnosticSeverity.Information\n            case \"hint\":\n                return DiagnosticSeverity.Hint\n            case _:\n                return DiagnosticSeverity.Information\n\n    def _detect_language(self, file_path: Path) -> str:\n        match file_path.suffix:\n            case \".py\":\n                return \"python\"\n            case \".js\":\n                return \"javascript\"\n            case \".ts\":\n                return \"typescript\"\n            case \".jsx\":\n                return \"jsx\"\n            case \".tsx\":\n                return \"tsx\"\n            case \".rs\":\n                return \"rust\"\n            case \".go\":\n                return \"go\"\n            case \".java\":\n                return \"java\"\n            case \".cpp\":\n                return \"cpp\"\n            case \".c\":\n                return \"c\"\n            case \".lua\":\n                return \"lua\"\n            case _:\n                return \"text\"\n\n\nserver = AILanguageServer()\n\n\n@server.feature(TEXT_DOCUMENT_DID_OPEN)\nasync def did_open(params: DidOpenTextDocumentParams):\n    logfire.info(f\"Document opened: {params.text_document.uri}\")\n    doc = params.text_document\n    await server.debounced_analyze(doc.uri, doc.text)\n\n\n@server.feature(TEXT_DOCUMENT_DID_SAVE)\nasync def did_save(params: DidSaveTextDocumentParams):\n    logfire.info(f\"Document saved: {params.text_document.uri}\")\n    doc = server.workspace.get_text_document(params.text_document.uri)\n    await server.debounced_analyze(doc.uri, doc.source)\n\n\n@server.feature(TEXT_DOCUMENT_DID_CHANGE)\nasync def did_change(params: DidChangeTextDocumentParams):\n    logfire.debug(f\"Document changed: {params.text_document.uri}\")\n    doc = server.workspace.get_text_document(params.text_document.uri)\n    await server.debounced_analyze(doc.uri, doc.source)\n\n\n@server.feature(\n    TEXT_DOCUMENT_CODE_ACTION,\n    CodeActionOptions(code_action_kinds=[CodeActionKind.QuickFix]),\n)\nasync def code_actions(params: CodeActionParams) -> list[CodeAction]:\n    with logfire.span(\"code_actions\", uri=params.text_document.uri):\n        actions: list[CodeAction] = []\n        uri = params.text_document.uri\n        doc = server.workspace.get_text_document(uri)\n\n        for diagnostic in params.context.diagnostics:\n            if diagnostic.source != \"ai-lsp\" or not diagnostic.data:\n                continue\n\n            suggested_fixes = diagnostic.data.get(\"suggested_fixes\", [])\n\n            for fix_data in suggested_fixes:\n                target_positions = server.find_snippet_in_text(\n                    doc.source, fix_data[\"target_snippet\"]\n                )\n\n                if target_positions:\n                    with logfire.span(\"creating_quick_fix\", title=fix_data[\"title\"]):\n                        start_line, start_col, end_line, end_col = target_positions[0]\n                        fix_range = Range(\n                            start=Position(line=start_line, character=start_col),\n                            end=Position(line=end_line, character=end_col),\n                        )\n\n                        edit = WorkspaceEdit(\n                            changes={\n                                uri: [\n                                    TextEdit(\n                                        range=fix_range,\n                                        new_text=fix_data[\"replacement_snippet\"],\n                                    )\n                                ]\n                            }\n                        )\n\n                        action = CodeAction(\n                            title=f\"Apply: {fix_data['title']}\",\n                            kind=CodeActionKind.QuickFix,\n                            edit=edit,\n                            diagnostics=[diagnostic],\n                            is_preferred=True,\n                        )\n                        actions.append(action)\n\n            actions.append(\n                CodeAction(\n                    title=\"Regenerate AI fix\",\n                    kind=CodeActionKind.QuickFix,\n                    command=Command(\n                        title=\"Regenerate fix\",\n                        command=\"ai-lsp.regenerateFix\",\n                        arguments=[\n                            uri,\n                            diagnostic.data.get(\"issue_snippet\"),\n                            diagnostic.range.start.line,\n                            diagnostic.range.start.character,\n                        ],\n                    ),\n                    diagnostics=[diagnostic],\n                )\n            )\n\n            actions.append(\n                CodeAction(\n                    title=\"Dismiss AI suggestion\",\n                    kind=CodeActionKind.QuickFix,\n                    command=Command(\n                        title=\"Dismiss\",\n                        command=\"ai-lsp.dismiss\",\n                        arguments=[\n                            uri,\n                            diagnostic.range.start.line,\n                            diagnostic.range.start.character,\n                        ],\n                    ),\n                    diagnostics=[diagnostic],\n                )\n            )\n\n        return actions\n\n\n@server.command(\"ai-lsp.regenerateFix\")\nasync def regenerate_fix(*args):\n    if len(args) < 4:\n        return\n\n    uri, issue_snippet, line, character = args[0], args[1], args[2], args[3]\n\n    with logfire.span(\"regenerate_fix\", uri=uri, issue_snippet=issue_snippet):\n        logfire.info(\n            f\"Regenerating fix for '{issue_snippet}' at {uri}:{line}:{character}\"\n        )\n\n        doc = server.workspace.get_text_document(uri)\n        file_path = Path(uri.replace(\"file:\/\/\", \"\"))\n        language = server._detect_language(file_path)\n\n        prompt = f\"\"\"Analyze this specific code issue and provide NEW suggested fixes.\n\nIssue snippet: {issue_snippet}\n\nFull code context:\n```{language}\n{doc.source}\n```\n\nFile: {file_path.name}\n\nFocus ONLY on the issue at the snippet shown. Provide fresh, alternative fixes if possible.\"\"\"\n\n        try:\n            result = await server.agent.run(prompt)\n\n            if not result.output.issues:\n                logfire.warn(\"No issues returned for regeneration\")\n                return\n\n            regenerated_issue = result.output.issues[0]\n\n            current_diags = getattr(server.lsp, \"diagnostics\", {}).get(uri, [])\n            updated_diags = []\n\n            for diag in current_diags:\n                if (\n                    diag.source == \"ai-lsp\"\n                    and diag.range.start.line == line\n                    and diag.range.start.character == character\n                ):\n                    positions = server.find_snippet_in_text(\n                        doc.source, regenerated_issue.issue_snippet\n                    )\n                    if positions:\n                        start_line, start_col, end_line, end_col = positions[0]\n                        updated_diag = Diagnostic(\n                            range=Range(\n                                start=Position(line=start_line, character=start_col),\n                                end=Position(line=end_line, character=end_col),\n                            ),\n                            message=f\"AI LSP: {regenerated_issue.message}\",\n                            severity=server._get_diagnostic_severity(\n                                regenerated_issue.severity\n                            ),\n                            source=\"ai-lsp\",\n                            data={\n                                \"issue_snippet\": regenerated_issue.issue_snippet,\n                                \"suggested_fixes\": [\n                                    {\n                                        \"title\": fix.title,\n                                        \"target_snippet\": fix.target_snippet,\n                                        \"replacement_snippet\": fix.replacement_snippet,\n                                    }\n                                    for fix in (regenerated_issue.suggested_fixes or [])\n                                ],\n                            },\n                        )\n                        updated_diags.append(updated_diag)\n                        logfire.info(\n                            f\"Regenerated diagnostic with {len(regenerated_issue.suggested_fixes or [])} new fixes\"\n                        )\n                else:\n                    updated_diags.append(diag)\n\n            server.publish_diagnostics(uri, updated_diags)\n\n        except Exception as e:\n            logfire.error(f\"Failed to regenerate fix: {str(e)}\", _exc_info=True)\n\n\n@server.command(\"ai-lsp.dismiss\")\ndef dismiss_suggestion(*args):\n    if len(args) < 3:\n        return\n\n    uri, line, character = args[0], args[1], args[2]\n\n    with logfire.span(\"dismiss_suggestion\", uri=uri, line=line, character=character):\n        logfire.info(f\"Dismissing suggestion at {uri}:{line}:{character}\")\n\n        doc = server.workspace.get_text_document(uri)\n        diagnostics = []\n\n        current_diags = getattr(server.lsp, \"diagnostics\", {}).get(uri, [])\n        for diag in current_diags:\n            if (\n                diag.source == \"ai-lsp\"\n                and diag.range.start.line == line\n                and diag.range.start.character == character\n            ):\n                continue\n            diagnostics.append(diag)\n\n        server.publish_diagnostics(uri, diagnostics)\n\n\ndef app():\n    server.start_io()\n\n\nif __name__ == \"__main__\":\n    app()\n\n```\n\nFile: main.py","assistant":"{\n  \"issues\": [\n    {\n      \"issue_snippet\": \"send_to_logfire=False\",\n      \"severity\": \"warning\",\n      \"message\": \"The `logfire.configure` call sets `send_to_logfire=False` even when `settings.configure_logfire` is true. This might be a misconfiguration, preventing logs from being sent to Logfire as intended by the `configure_logfire` setting. If the intent is to send logs, this should be enabled.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Enable sending logs to Logfire\",\n          \"target_snippet\": \"send_to_logfire=False\",\n          \"replacement_snippet\": \"send_to_logfire=True\"\n        }\n      ]\n    },\n    {\n      \"issue_snippet\": \"positions[0]\",\n      \"severity\": \"error\",\n      \"message\": \"When `find_snippet_in_text` returns multiple occurrences of `issue.issue_snippet`, the code only uses the first one (`positions[0]`) to place the diagnostic. This can lead to diagnostics being incorrectly placed if the AI's semantic analysis refers to a later occurrence of the same snippet. The AI output should ideally include precise location (line\/column) for issues, or a more sophisticated matching strategy is needed.\",\n      \"suggested_fixes\": null\n    },\n    {\n      \"issue_snippet\": \"target_positions[0]\",\n      \"severity\": \"error\",\n      \"message\": \"When applying code actions, `find_snippet_in_text` is used to locate the `target_snippet` for a fix, and only the first occurrence (`target_positions[0]`) is used. If `target_snippet` is not unique, the code action might modify the wrong part of the code, leading to unintended bugs or corruption.\",\n      \"suggested_fixes\": null\n    },\n    {\n      \"issue_snippet\": \"positions[0]\",\n      \"severity\": \"error\",\n      \"message\": \"During fix regeneration, the new diagnostic's range is determined by `find_snippet_in_text` on the `regenerated_issue.issue_snippet`, taking only `positions[0]`. This combines the problem of ambiguous snippet placement with the risk of losing the original diagnostic's precise location. If the regenerated snippet differs or is not unique, the diagnostic might be incorrectly re-positioned or applied to the wrong instance, despite the original command specifying a precise line\/character for the fix.\",\n      \"suggested_fixes\": null\n    }\n  ]\n}"}
{"system":"You are an AI code analyzer that provides semantic insights that traditional LSPs cannot detect.\n\nONLY flag issues that require deep semantic understanding:\n- Logic errors in algorithms or business logic\n- Subtle race conditions or concurrency issues  \n- Architectural problems and design pattern violations\n- Security vulnerabilities requiring context understanding\n- Performance anti-patterns that need semantic analysis\n- Complex data flow issues\n- Domain-specific best practice violations\n- Accessibility issues requiring UX understanding\n\nDO NOT flag issues that normal LSPs handle:\n- Syntax errors\n- Basic type errors  \n- Undefined variables\n- Import issues\n- Basic formatting problems\n- Simple linting rules\n\nFor each issue, provide:\n- The exact issue_snippet that has the problem (ONLY the problematic token\/value, e.g. just \"python\" not 'command = \"python\"')\n- Clear explanation of WHY this needs human attention in the message\n- Use severity: \"info\" for suggestions, \"warning\" for concerns, \"error\" for serious logic issues\n- When possible, provide suggested_fixes with:\n  - target_snippet: the exact code to replace (same as issue_snippet usually)\n  - replacement_snippet: the replacement code\n  - title: clear description of the fix\n\nFocus on insights that require understanding code intent and context. Keep issue_snippet to the absolute minimum - just the problematic token.","user":"Analyze this python code for issues:\n\n```python\nfrom typing import Literal\n\nfrom pydantic import BaseModel, Field\nfrom pydantic_ai.models import KnownModelName\nfrom pydantic_settings import BaseSettings\n\n\nclass Settings(BaseSettings):\n    ai_lsp_model: KnownModelName = Field(default=\"google-gla:gemini-2.5-flash\")\n    debounce_ms: int = Field(default=1000)\n    max_cache_size: int = Field(default=50)\n    configure_logfire: bool = Field(default=True)\n    otel_exporter_otlp_endpoint: str = Field(default=\"http:\/\/localhost:4318\")\n\n\nclass SuggestedFix(BaseModel):\n    title: str\n    target_snippet: str\n    replacement_snippet: str\n\n\nclass CodeIssue(BaseModel):\n    issue_snippet: str\n    severity: Literal[\"error\", \"warning\", \"info\", \"hint\"]\n    message: str\n    suggested_fixes: list[SuggestedFix] | None = None\n\n\nclass DiagnosticResult(BaseModel):\n    issues: list[CodeIssue]\n\n```\n\nFile: models.py","assistant":"{\n  \"issues\": [\n    {\n      \"issue_snippet\": \"http:\/\/localhost:4318\",\n      \"severity\": \"warning\",\n      \"message\": \"The default OTLP exporter endpoint points to `http:\/\/localhost:4318`. While this is suitable for local development and testing, relying on this default in a production environment will result in telemetry data not being collected or being sent to an incorrect location. This is a common operational oversight that can lead to a lack of observability in deployed applications, making debugging and monitoring significantly more challenging.\",\n      \"suggested_fixes\": null\n    },\n    {\n      \"issue_snippet\": \"True\",\n      \"severity\": \"warning\",\n      \"message\": \"[Scrubbed due to 'API key']\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Default Logfire configuration to opt-in\",\n          \"target_snippet\": \"True\",\n          \"replacement_snippet\": \"False\"\n        }\n      ]\n    }\n  ]\n}"}
{"system":"You are an AI code analyzer that provides semantic insights that traditional LSPs cannot detect.\n\nONLY flag issues that require deep semantic understanding:\n- Logic errors in algorithms or business logic\n- Subtle race conditions or concurrency issues  \n- Architectural problems and design pattern violations\n- Security vulnerabilities requiring context understanding\n- Performance anti-patterns that need semantic analysis\n- Complex data flow issues\n- Domain-specific best practice violations\n- Accessibility issues requiring UX understanding\n\nDO NOT flag issues that normal LSPs handle:\n- Syntax errors\n- Basic type errors  \n- Undefined variables\n- Import issues\n- Basic formatting problems\n- Simple linting rules\n\nFor each issue, provide:\n- The exact issue_snippet that has the problem (ONLY the problematic token\/value, e.g. just \"python\" not 'command = \"python\"')\n- Clear explanation of WHY this needs human attention in the message\n- Use severity: \"info\" for suggestions, \"warning\" for concerns, \"error\" for serious logic issues\n- When possible, provide suggested_fixes with:\n  - target_snippet: the exact code to replace (same as issue_snippet usually)\n  - replacement_snippet: the replacement code\n  - title: clear description of the fix\n\nFocus on insights that require understanding code intent and context. Keep issue_snippet to the absolute minimum - just the problematic token.","user":"Analyze this python code for issues:\n\n```python\nimport asyncio\nimport os\nfrom importlib.metadata import version\nfrom pathlib import Path\nfrom typing import Any\n\nimport logfire\n\n# pyrefly: ignore [missing-import]\nfrom lsprotocol.types import (\n    TEXT_DOCUMENT_CODE_ACTION,\n    TEXT_DOCUMENT_DID_CHANGE,\n    TEXT_DOCUMENT_DID_OPEN,\n    TEXT_DOCUMENT_DID_SAVE,\n    CodeAction,\n    CodeActionKind,\n    CodeActionOptions,\n    CodeActionParams,\n    Command,\n    Diagnostic,\n    DiagnosticSeverity,\n    DidChangeTextDocumentParams,\n    DidOpenTextDocumentParams,\n    DidSaveTextDocumentParams,\n    Position,\n    Range,\n    TextEdit,\n    WorkspaceEdit,\n)\nfrom pydantic_ai import Agent\n\n# pyrefly: ignore [missing-import]\nfrom pygls.server import LanguageServer\n\nfrom ai_lsp.models import DiagnosticResult, Settings\n\nsettings = Settings()\n\n\nos.environ[\"OTEL_EXPORTER_OTLP_ENDPOINT\"] = settings.otel_exporter_otlp_endpoint\n\nif settings.configure_logfire:\n    logfire.configure(send_to_logfire=False, service_name=\"ai-lsp\")  # pyright: ignore[reportUnusedCallResult]\n    logfire.instrument_pydantic_ai()\n    logfire.instrument_httpx(capture_all=True)\n\n\nclass AILanguageServer(LanguageServer):\n    def __init__(self):\n        super().__init__(\"ai-lsp\", version(\"ai-lsp\"))\n        logfire.info(\"Initializing AI Language Server\")\n        self._pending_tasks: dict[str, asyncio.Task[Any]] = {}\n        self._analysis_locks: dict[str, asyncio.Lock] = {}\n\n        self.agent: Agent[DiagnosticResult, Any] = Agent(\n            model=settings.ai_lsp_model,\n            output_type=DiagnosticResult,\n            system_prompt=\"\"\"You are an AI code analyzer that provides semantic insights that traditional LSPs cannot detect.\n\nONLY flag issues that require deep semantic understanding:\n- Logic errors in algorithms or business logic\n- Subtle race conditions or concurrency issues  \n- Architectural problems and design pattern violations\n- Security vulnerabilities requiring context understanding\n- Performance anti-patterns that need semantic analysis\n- Complex data flow issues\n- Domain-specific best practice violations\n- Accessibility issues requiring UX understanding\n\nDO NOT flag issues that normal LSPs handle:\n- Syntax errors\n- Basic type errors  \n- Undefined variables\n- Import issues\n- Basic formatting problems\n- Simple linting rules\n\nFor each issue, provide:\n- The exact issue_snippet that has the problem (ONLY the problematic token\/value, e.g. just \"python\" not 'command = \"python\"')\n- Clear explanation of WHY this needs human attention in the message\n- Use severity: \"info\" for suggestions, \"warning\" for concerns, \"error\" for serious logic issues\n- When possible, provide suggested_fixes with:\n  - target_snippet: the exact code to replace (same as issue_snippet usually)\n  - replacement_snippet: the replacement code\n  - title: clear description of the fix\n\nFocus on insights that require understanding code intent and context. Keep issue_snippet to the absolute minimum - just the problematic token.\"\"\",\n        )\n        logfire.info(\"AI agent initialized successfully\")\n\n    def find_snippet_in_text(\n        self, text: str, snippet: str\n    ) -> list[tuple[int, int, int, int]]:\n        \"\"\"Find all occurrences of code snippet in text, return positions as (start_line, start_col, end_line, end_col)\"\"\"\n        snippet = snippet.strip()\n        positions = []\n\n        # Search for all occurrences of snippet\n        start_pos = 0\n        while True:\n            start_pos = text.find(snippet, start_pos)\n            if start_pos == -1:\n                break\n\n            # Convert character position to line\/column\n            lines = text[:start_pos].split(\"\\n\")\n            start_line = len(lines) - 1\n            start_col = len(lines[-1])\n\n            # Calculate end position\n            snippet_lines = snippet.split(\"\\n\")\n            if len(snippet_lines) == 1:\n                end_line = start_line\n                end_col = start_col + len(snippet)\n            else:\n                end_line = start_line + len(snippet_lines) - 1\n                end_col = len(snippet_lines[-1])\n\n            positions.append((start_line, start_col, end_line, end_col))\n            start_pos += 1  # Move past this occurrence\n\n        if not positions:\n            logfire.warn(f\"Could not find snippet '{snippet}' in text\")\n        else:\n            logfire.debug(f\"Found {len(positions)} occurrences of '{snippet[:20]}...'\")\n\n        return positions\n\n    async def debounced_analyze(self, uri: str, text: str):\n        \"\"\"Debounced analysis that cancels previous calls\"\"\"\n        # Cancel any existing task for this URI\n        if uri in self._pending_tasks:\n            self._pending_tasks[uri].cancel()\n            _ = self._pending_tasks.pop(uri, None)\n\n        # Create new task\n        task: asyncio.Task[None] = asyncio.create_task(self._delayed_analyze(uri, text))\n        self._pending_tasks[uri] = task\n\n        try:\n            await task\n        except asyncio.CancelledError:\n            logfire.debug(f\"Analysis cancelled for {uri}\")\n        finally:\n            # Clean up completed task\n            if uri in self._pending_tasks and self._pending_tasks[uri] == task:\n                _ = self._pending_tasks.pop(uri)\n\n    async def _delayed_analyze(self, uri: str, text: str):\n        \"\"\"Wait for debounce period then analyze\"\"\"\n        await asyncio.sleep(settings.debounce_ms \/ 1000.0)\n        diagnostics = await self.analyze_document(uri, text)\n        # pyrefly: ignore [missing-attribute]\n        self.publish_diagnostics(uri, diagnostics)\n        logfire.debug(f\"Published {len(diagnostics)} diagnostics for {uri}\")\n\n    async def analyze_document(self, uri: str, text: str) -> list[Diagnostic]:\n        # Ensure we have a lock for this URI\n        lock = self._analysis_locks.setdefault(uri, asyncio.Lock())\n        async with lock:\n            with logfire.span(\"analyze_document\", uri=uri):\n                logfire.info(f\"Starting AI analysis for {uri}\")\n\n                try:\n                    file_path = Path(uri.replace(\"file:\/\/\", \"\"))\n                    language = self._detect_language(file_path)\n\n                    prompt = f\"\"\"Analyze this {language} code for issues:\n\n```{language}\n{text}\n```\n\nFile: {file_path.name}\"\"\"\n\n                    result = await self.agent.run(prompt)\n                    logfire.info(\n                        f\"AI analysis completed, found {len(result.output.issues)} issues\"\n                    )\n\n                    diagnostics = []\n                    for issue in result.output.issues:\n                        positions = self.find_snippet_in_text(text, issue.issue_snippet)\n\n                        if positions:\n                            start_line, start_col, end_line, end_col = positions[0]\n                            diagnostic = Diagnostic(\n                                range=Range(\n                                    start=Position(\n                                        line=start_line, character=start_col\n                                    ),\n                                    end=Position(line=end_line, character=end_col),\n                                ),\n                                message=f\"AI LSP: {issue.message}\",\n                                severity=self._get_diagnostic_severity(issue.severity),\n                                source=\"ai-lsp\",\n                                data={\n                                    \"issue_snippet\": issue.issue_snippet,\n                                    \"suggested_fixes\": [\n                                        {\n                                            \"title\": fix.title,\n                                            \"target_snippet\": fix.target_snippet,\n                                            \"replacement_snippet\": fix.replacement_snippet,\n                                        }\n                                        for fix in (issue.suggested_fixes or [])\n                                    ],\n                                },\n                            )\n                            diagnostics.append(diagnostic)\n\n                    return diagnostics\n\n                except Exception as e:\n                    logfire.error(\n                        f\"AI analysis failed for {uri}: {str(e)}\", _exc_info=True\n                    )\n                    return []\n\n    def _get_diagnostic_severity(self, severity: str) -> DiagnosticSeverity:\n        match severity:\n            case \"error\":\n                return DiagnosticSeverity.Error\n            case \"warning\":\n                return DiagnosticSeverity.Warning\n            case \"info\":\n                return DiagnosticSeverity.Information\n            case \"hint\":\n                return DiagnosticSeverity.Hint\n            case _:\n                return DiagnosticSeverity.Information\n\n    def _detect_language(self, file_path: Path) -> str:\n        match file_path.suffix:\n            case \".py\":\n                return \"python\"\n            case \".js\":\n                return \"javascript\"\n            case \".ts\":\n                return \"typescript\"\n            case \".jsx\":\n                return \"jsx\"\n            case \".tsx\":\n                return \"tsx\"\n            case \".rs\":\n                return \"rust\"\n            case \".go\":\n                return \"go\"\n            case \".java\":\n                return \"java\"\n            case \".cpp\":\n                return \"cpp\"\n            case \".c\":\n                return \"c\"\n            case \".lua\":\n                return \"lua\"\n            case _:\n                return \"text\"\n\n\nserver = AILanguageServer()\n\n\n@server.feature(TEXT_DOCUMENT_DID_OPEN)\nasync def did_open(params: DidOpenTextDocumentParams):\n    logfire.info(f\"Document opened: {params.text_document.uri}\")\n    doc = params.text_document\n    await server.debounced_analyze(doc.uri, doc.text)\n\n\n@server.feature(TEXT_DOCUMENT_DID_SAVE)\nasync def did_save(params: DidSaveTextDocumentParams):\n    logfire.info(f\"Document saved: {params.text_document.uri}\")\n    doc = server.workspace.get_text_document(params.text_document.uri)\n    await server.debounced_analyze(doc.uri, doc.source)\n\n\n@server.feature(TEXT_DOCUMENT_DID_CHANGE)\nasync def did_change(params: DidChangeTextDocumentParams):\n    logfire.debug(f\"Document changed: {params.text_document.uri}\")\n    doc = server.workspace.get_text_document(params.text_document.uri)\n    await server.debounced_analyze(doc.uri, doc.source)\n\n\n@server.feature(\n    TEXT_DOCUMENT_CODE_ACTION,\n    CodeActionOptions(code_action_kinds=[CodeActionKind.QuickFix]),\n)\nasync def code_actions(params: CodeActionParams) -> list[CodeAction]:\n    with logfire.span(\"code_actions\", uri=params.text_document.uri):\n        actions: list[CodeAction] = []\n        uri = params.text_document.uri\n        doc = server.workspace.get_text_document(uri)\n\n        for diagnostic in params.context.diagnostics:\n            if diagnostic.source != \"ai-lsp\" or not diagnostic.data:\n                continue\n\n            suggested_fixes = diagnostic.data.get(\"suggested_fixes\", [])\n\n            for fix_data in suggested_fixes:\n                target_positions = server.find_snippet_in_text(\n                    doc.source, fix_data[\"target_snippet\"]\n                )\n\n                if target_positions:\n                    with logfire.span(\"creating_quick_fix\", title=fix_data[\"title\"]):\n                        start_line, start_col, end_line, end_col = target_positions[0]\n                        fix_range = Range(\n                            start=Position(line=start_line, character=start_col),\n                            end=Position(line=end_line, character=end_col),\n                        )\n\n                        edit = WorkspaceEdit(\n                            changes={\n                                uri: [\n                                    TextEdit(\n                                        range=fix_range,\n                                        new_text=fix_data[\"replacement_snippet\"],\n                                    )\n                                ]\n                            }\n                        )\n\n                        action = CodeAction(\n                            title=f\"Apply: {fix_data['title']}\",\n                            kind=CodeActionKind.QuickFix,\n                            edit=edit,\n                            diagnostics=[diagnostic],\n                            is_preferred=True,\n                        )\n                        actions.append(action)\n\n            actions.append(\n                CodeAction(\n                    title=\"Regenerate AI fix\",\n                    kind=CodeActionKind.QuickFix,\n                    command=Command(\n                        title=\"Regenerate fix\",\n                        command=\"ai-lsp.regenerateFix\",\n                        arguments=[\n                            uri,\n                            diagnostic.data.get(\"issue_snippet\"),\n                            diagnostic.range.start.line,\n                            diagnostic.range.start.character,\n                        ],\n                    ),\n                    diagnostics=[diagnostic],\n                )\n            )\n\n            actions.append(\n                CodeAction(\n                    title=\"Dismiss AI suggestion\",\n                    kind=CodeActionKind.QuickFix,\n                    command=Command(\n                        title=\"Dismiss\",\n                        command=\"ai-lsp.dismiss\",\n                        arguments=[\n                            uri,\n                            diagnostic.range.start.line,\n                            diagnostic.range.start.character,\n                        ],\n                    ),\n                    diagnostics=[diagnostic],\n                )\n            )\n\n        return actions\n\n\n@server.command(\"ai-lsp.regenerateFix\")\nasync def regenerate_fix(*args):\n    if len(args) < 4:\n        return\n\n    uri, issue_snippet, line, character = args[0], args[1], args[2], args[3]\n\n    with logfire.span(\"regenerate_fix\", uri=uri, issue_snippet=issue_snippet):\n        logfire.info(\n            f\"Regenerating fix for '{issue_snippet}' at {uri}:{line}:{character}\"\n        )\n\n        doc = server.workspace.get_text_document(uri)\n        file_path = Path(uri.replace(\"file:\/\/\", \"\"))\n        language = server._detect_language(file_path)\n\n        prompt = f\"\"\"Analyze this specific code issue and provide NEW suggested fixes.\n\nIssue snippet: {issue_snippet}\n\nFull code context:\n```{language}\n{doc.source}\n```\n\nFile: {file_path.name}\n\nFocus ONLY on the issue at the snippet shown. Provide fresh, alternative fixes if possible.\"\"\"\n\n        try:\n            result = await server.agent.run(prompt)\n\n            if not result.output.issues:\n                logfire.warn(\"No issues returned for regeneration\")\n                return\n\n            regenerated_issue = result.output.issues[0]\n\n            current_diags = getattr(server.lsp, \"diagnostics\", {}).get(uri, [])\n            updated_diags = []\n\n            for diag in current_diags:\n                if (\n                    diag.source == \"ai-lsp\"\n                    and diag.range.start.line == line\n                    and diag.range.start.character == character\n                ):\n                    positions = server.find_snippet_in_text(\n                        doc.source, regenerated_issue.issue_snippet\n                    )\n                    if positions:\n                        start_line, start_col, end_line, end_col = positions[0]\n                        updated_diag = Diagnostic(\n                            range=Range(\n                                start=Position(line=start_line, character=start_col),\n                                end=Position(line=end_line, character=end_col),\n                            ),\n                            message=f\"AI LSP: {regenerated_issue.message}\",\n                            severity=server._get_diagnostic_severity(\n                                regenerated_issue.severity\n                            ),\n                            source=\"ai-lsp\",\n                            data={\n                                \"issue_snippet\": regenerated_issue.issue_snippet,\n                                \"suggested_fixes\": [\n                                    {\n                                        \"title\": fix.title,\n                                        \"target_snippet\": fix.target_snippet,\n                                        \"replacement_snippet\": fix.replacement_snippet,\n                                    }\n                                    for fix in (regenerated_issue.suggested_fixes or [])\n                                ],\n                            },\n                        )\n                        updated_diags.append(updated_diag)\n                        logfire.info(\n                            f\"Regenerated diagnostic with {len(regenerated_issue.suggested_fixes or [])} new fixes\"\n                        )\n                else:\n                    updated_diags.append(diag)\n\n            server.publish_diagnostics(uri, updated_diags)\n\n        except Exception as e:\n            logfire.error(f\"Failed to regenerate fix: {str(e)}\", _exc_info=True)\n\n\n@server.command(\"ai-lsp.dismiss\")\ndef dismiss_suggestion(*args):\n    if len(args) < 3:\n        return\n\n    uri, line, character = args[0], args[1], args[2]\n\n    with logfire.span(\"dismiss_suggestion\", uri=uri, line=line, character=character):\n        logfire.info(f\"Dismissing suggestion at {uri}:{line}:{character}\")\n\n        doc = server.workspace.get_text_document(uri)\n        diagnostics = []\n\n        current_diags = getattr(server.lsp, \"diagnostics\", {}).get(uri, [])\n        for diag in current_diags:\n            if (\n                diag.source == \"ai-lsp\"\n                and diag.range.start.line == line\n                and diag.range.start.character == character\n            ):\n                continue\n            diagnostics.append(diag)\n\n        server.publish_diagnostics(uri, diagnostics)\n\n\ndef app():\n    server.start_io()\n\n\nif __name__ == \"__main__\":\n    app()\n\n```\n\nFile: main.py","assistant":"{\n  \"issues\": [\n    {\n      \"issue_snippet\": \"positions[0]\",\n      \"severity\": \"warning\",\n      \"message\": \"The `analyze_document` function uses `positions[0]` to create a diagnostic, meaning it only flags the very first occurrence of an `issue_snippet` in the document. If the AI detects a problem that appears multiple times (e.g., a repeated anti-pattern or logic error), only the first instance will be shown to the user, reducing the comprehensiveness of the analysis.\",\n      \"suggested_fixes\": null\n    },\n    {\n      \"issue_snippet\": \"target_positions[0]\",\n      \"severity\": \"warning\",\n      \"message\": \"In the `code_actions` function, when constructing a quick fix, `target_positions[0]` is used to define the range for the `TextEdit`. This means if the `target_snippet` (the code segment to be replaced by the fix) appears multiple times in the document, the quick fix will only be offered for, and applied to, the first instance. This limits the utility of automated fixes for recurring issues. A single `WorkspaceEdit` can contain multiple `TextEdit`s for the same URI to fix all occurrences simultaneously.\",\n      \"suggested_fixes\": null\n    },\n    {\n      \"issue_snippet\": \"positions[0]\",\n      \"severity\": \"error\",\n      \"message\": \"The `regenerate_fix` command targets a specific diagnostic for update based on its original `start.line` and `start.character`. However, it then determines the new diagnostic's `range` by searching for the *newly generated* `regenerated_issue.issue_snippet` and using its *first occurrence* (`positions[0]`). If this new snippet is found at a different location than the original diagnostic, the regenerated diagnostic will \\\"move\\\", confusing the user who expected the *specific* diagnostic they interacted with to be updated in place. The range of the updated diagnostic should ideally remain consistent with the original diagnostic's location.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Keep diagnostic at original range\",\n          \"target_snippet\": \"range=Range(\\n                                start=Position(line=start_line, character=start_col),\\n                                end=Position(line=end_line, character=end_col),\\n                            )\",\n          \"replacement_snippet\": \"range=diag.range,\"\n        }\n      ]\n    }\n  ]\n}"}
{"system":"You are an AI code analyzer that provides semantic insights that traditional LSPs cannot detect.\n\nONLY flag issues that require deep semantic understanding:\n- Logic errors in algorithms or business logic\n- Subtle race conditions or concurrency issues  \n- Architectural problems and design pattern violations\n- Security vulnerabilities requiring context understanding\n- Performance anti-patterns that need semantic analysis\n- Complex data flow issues\n- Domain-specific best practice violations\n- Accessibility issues requiring UX understanding\n\nDO NOT flag issues that normal LSPs handle:\n- Syntax errors\n- Basic type errors  \n- Undefined variables\n- Import issues\n- Basic formatting problems\n- Simple linting rules\n\nFor each issue, provide:\n- The exact issue_snippet that has the problem (ONLY the problematic token\/value, e.g. just \"python\" not 'command = \"python\"')\n- Clear explanation of WHY this needs human attention in the message\n- Use severity: \"info\" for suggestions, \"warning\" for concerns, \"error\" for serious logic issues\n- When possible, provide suggested_fixes with:\n  - target_snippet: the exact code to replace (same as issue_snippet usually)\n  - replacement_snippet: the replacement code\n  - title: clear description of the fix\n\nFocus on insights that require understanding code intent and context. Keep issue_snippet to the absolute minimum - just the problematic token.","user":"Analyze this python code for issues:\n\n```python\n# agent.py\nfrom __future__ import annotations\n\nfrom typing import Any\n\nfrom .models import DiagnosticResult\nfrom pydantic_ai import Agent\n\nAI_LSP_SYSTEM_PROMPT = \"\"\"You are an AI code analyzer that provides semantic insights that traditional LSPs cannot detect.\n\nONLY flag issues that require deep semantic understanding:\n- Logic errors in algorithms or business logic\n- Subtle race conditions or concurrency issues  \n- Architectural problems and design pattern violations\n- Security vulnerabilities requiring context understanding\n- Performance anti-patterns that need semantic analysis\n- Complex data flow issues\n- Domain-specific best practice violations\n- Accessibility issues requiring UX understanding\n\nDO NOT flag issues that normal LSPs handle:\n- Syntax errors\n- Basic type errors  \n- Undefined variables\n- Import issues\n- Basic formatting problems\n- Simple linting rules\n\nFor each issue, provide:\n- The exact issue_snippet that has the problem (ONLY the problematic token\/value, e.g. just \"python\" not 'command = \"python\"')\n- Clear explanation of WHY this needs human attention in the message\n- Use severity: \"info\" for suggestions, \"warning\" for concerns, \"error\" for serious logic issues\n- When possible, provide suggested_fixes with:\n  - target_snippet: the exact code to replace (same as issue_snippet usually)\n  - replacement_snippet: the replacement code\n  - title: clear description of the fix\n\nFocus on insights that require understanding code intent and context. Keep issue_snippet to the absolute minimum - just the problematic token.\n\"\"\"\n\n\ndef create_diagnostic_agent() -> Agent[DiagnosticResult, Any]:\n    \"\"\"Factory for the AI diagnostic agent.\"\"\"\n    return Agent(\n        model=settings.ai_lsp_model,\n        output_type=DiagnosticResult,\n        system_prompt=AI_LSP_SYSTEM_PROMPT,\n    )\n\n```\n\nFile: agent.py","assistant":"{\n  \"issues\": [\n    {\n      \"issue_snippet\": \"create_diagnostic_agent\",\n      \"severity\": \"warning\",\n      \"message\": \"The `create_diagnostic_agent` function directly accesses `settings.ai_lsp_model` without it being passed as an argument. This introduces a global dependency, tightly coupling the function to the `settings` object. This pattern reduces testability, makes the function harder to reuse in different contexts, and goes against the principle of dependency injection.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Inject the AI model as an argument\",\n          \"target_snippet\": \"def create_diagnostic_agent() -> Agent[DiagnosticResult, Any]:\",\n          \"replacement_snippet\": \"def create_diagnostic_agent(ai_model: Any) -> Agent[DiagnosticResult, Any]:\"\n        },\n        {\n          \"title\": \"Use the injected AI model\",\n          \"target_snippet\": \"model=settings.ai_lsp_model,\",\n          \"replacement_snippet\": \"model=ai_model,\"\n        }\n      ]\n    }\n  ]\n}"}
{"system":"You are an AI code analyzer that provides semantic insights that traditional LSPs cannot detect.\n\nONLY flag issues that require deep semantic understanding:\n- Logic errors in algorithms or business logic\n- Subtle race conditions or concurrency issues  \n- Architectural problems and design pattern violations\n- Security vulnerabilities requiring context understanding\n- Performance anti-patterns that need semantic analysis\n- Complex data flow issues\n- Domain-specific best practice violations\n- Accessibility issues requiring UX understanding\n\nDO NOT flag issues that normal LSPs handle:\n- Syntax errors\n- Basic type errors  \n- Undefined variables\n- Import issues\n- Basic formatting problems\n- Simple linting rules\n\nFor each issue, provide:\n- The exact issue_snippet that has the problem (ONLY the problematic token\/value, e.g. just \"python\" not 'command = \"python\"')\n- Clear explanation of WHY this needs human attention in the message\n- Use severity: \"info\" for suggestions, \"warning\" for concerns, \"error\" for serious logic issues\n- When possible, provide suggested_fixes with:\n  - target_snippet: the exact code to replace (same as issue_snippet usually)\n  - replacement_snippet: the replacement code\n  - title: clear description of the fix\n\nFocus on insights that require understanding code intent and context. Keep issue_snippet to the absolute minimum - just the problematic token.","user":"Analyze this python code for issues:\n\n```python\n# agent.py\nfrom pydantic_ai.models import KnownModelName\nfrom __future__ import annotations\n\nfrom typing import Any\n\nfrom .models import DiagnosticResult\nfrom pydantic_ai import Agent\n\nAI_LSP_SYSTEM_PROMPT = \"\"\"You are an AI code analyzer that provides semantic insights that traditional LSPs cannot detect.\n\nONLY flag issues that require deep semantic understanding:\n- Logic errors in algorithms or business logic\n- Subtle race conditions or concurrency issues  \n- Architectural problems and design pattern violations\n- Security vulnerabilities requiring context understanding\n- Performance anti-patterns that need semantic analysis\n- Complex data flow issues\n- Domain-specific best practice violations\n- Accessibility issues requiring UX understanding\n\nDO NOT flag issues that normal LSPs handle:\n- Syntax errors\n- Basic type errors  \n- Undefined variables\n- Import issues\n- Basic formatting problems\n- Simple linting rules\n\nFor each issue, provide:\n- The exact issue_snippet that has the problem (ONLY the problematic token\/value, e.g. just \"python\" not 'command = \"python\"')\n- Clear explanation of WHY this needs human attention in the message\n- Use severity: \"info\" for suggestions, \"warning\" for concerns, \"error\" for serious logic issues\n- When possible, provide suggested_fixes with:\n  - target_snippet: the exact code to replace (same as issue_snippet usually)\n  - replacement_snippet: the replacement code\n  - title: clear description of the fix\n\nFocus on insights that require understanding code intent and context. Keep issue_snippet to the absolute minimum - just the problematic token.\n\"\"\"\n\n\ndef create_diagnostic_agent(model: KnownModelName) -> Agent[DiagnosticResult, Any]:\n    \"\"\"Factory for the AI diagnostic agent.\"\"\"\n    return Agent(\n        model=model,\n        output_type=DiagnosticResult,\n        system_prompt=AI_LSP_SYSTEM_PROMPT,\n    )\n\n```\n\nFile: agent.py","assistant":"{\n  \"issues\": [\n    {\n      \"issue_snippet\": \"ONLY the problematic token\/value, e.g. just \\\"python\\\" not 'command = \\\"python\\\"'\",\n      \"severity\": \"warning\",\n      \"message\": \"The instruction for `issue_snippet` to be 'ONLY the problematic token\/value' might be overly restrictive for effectively communicating complex semantic issues. Many deep-seated problems in logic, architecture, or performance involve interactions across multiple tokens or even lines of code. Limiting the snippet to a single token can strip away crucial context, making the diagnostic less clear and harder for a human to act upon. Consider allowing a slightly broader `issue_snippet` when necessary to fully convey the problem.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Allow more flexible `issue_snippet` for complex problems\",\n          \"target_snippet\": \"ONLY the problematic token\/value, e.g. just \\\"python\\\" not 'command = \\\"python\\\"'\",\n          \"replacement_snippet\": \"the most concise and relevant code snippet that captures the problem, which could be a single token or a small expression, e.g., 'command' if the variable name is the issue, or 'list.append(item)' if the entire method call is problematic.\"\n        }\n      ]\n    },\n    {\n      \"issue_snippet\": \"AI_LSP_SYSTEM_PROMPT\",\n      \"severity\": \"info\",\n      \"message\": \"The `AI_LSP_SYSTEM_PROMPT` defines the AI agent's behavior but lacks explicit instructions on how to handle situations of uncertainty, low confidence, or potential false positives. For a diagnostic AI, guiding it to express confidence levels, ask clarifying questions, or indicate when an issue is speculative can significantly enhance the trustworthiness and utility of its reports for human users. Without such guidance, the AI might report issues with absolute certainty even when its confidence is low, potentially leading to wasted human effort or overlooked actual problems.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Add guidance for handling uncertainty and confidence\",\n          \"target_snippet\": \"Focus on insights that require understanding code intent and context. Keep issue_snippet to the absolute minimum - just the problematic token.\",\n          \"replacement_snippet\": \"Focus on insights that require understanding code intent and context. Keep issue_snippet to the absolute minimum - just the problematic token.\\\\nIf you are uncertain about an issue, please state your confidence level or highlight it as a potential concern requiring further investigation.\"\n        }\n      ]\n    }\n  ]\n}"}
{"system":"You are an AI code analyzer that provides semantic insights that traditional LSPs cannot detect.\n\nONLY flag issues that require deep semantic understanding:\n- Logic errors in algorithms or business logic\n- Subtle race conditions or concurrency issues  \n- Architectural problems and design pattern violations\n- Security vulnerabilities requiring context understanding\n- Performance anti-patterns that need semantic analysis\n- Complex data flow issues\n- Domain-specific best practice violations\n- Accessibility issues requiring UX understanding\n\nDO NOT flag issues that normal LSPs handle:\n- Syntax errors\n- Basic type errors  \n- Undefined variables\n- Import issues\n- Basic formatting problems\n- Simple linting rules\n\nFor each issue, provide:\n- The exact issue_snippet that has the problem (ONLY the problematic token\/value, e.g. just \"python\" not 'command = \"python\"')\n- Clear explanation of WHY this needs human attention in the message\n- Use severity: \"info\" for suggestions, \"warning\" for concerns, \"error\" for serious logic issues\n- When possible, provide suggested_fixes with:\n  - target_snippet: the exact code to replace (same as issue_snippet usually)\n  - replacement_snippet: the replacement code\n  - title: clear description of the fix\n\nFocus on insights that require understanding code intent and context. Keep issue_snippet to the absolute minimum - just the problematic token.\n","user":"Analyze this python code for issues:\n\n```python\nfrom ai_lsp.agent import create_diagnostic_agent\nimport asyncio\nimport os\nfrom importlib.metadata import version\nfrom pathlib import Path\nfrom typing import Any\n\nimport logfire\n\n# pyrefly: ignore [missing-import]\nfrom lsprotocol.types import (\n    TEXT_DOCUMENT_CODE_ACTION,\n    TEXT_DOCUMENT_DID_CHANGE,\n    TEXT_DOCUMENT_DID_OPEN,\n    TEXT_DOCUMENT_DID_SAVE,\n    CodeAction,\n    CodeActionKind,\n    CodeActionOptions,\n    CodeActionParams,\n    Command,\n    Diagnostic,\n    DiagnosticSeverity,\n    DidChangeTextDocumentParams,\n    DidOpenTextDocumentParams,\n    DidSaveTextDocumentParams,\n    Position,\n    Range,\n    TextEdit,\n    WorkspaceEdit,\n)\nfrom pydantic_ai import Agent\n\n# pyrefly: ignore [missing-import]\nfrom pygls.server import LanguageServer\n\nfrom ai_lsp.models import DiagnosticResult, Settings\n\nsettings = Settings()\n\n\nos.environ[\"OTEL_EXPORTER_OTLP_ENDPOINT\"] = settings.otel_exporter_otlp_endpoint\n\nif settings.configure_logfire:\n    logfire.configure(send_to_logfire=False, service_name=\"ai-lsp\")  # pyright: ignore[reportUnusedCallResult]\n    logfire.instrument_pydantic_ai()\n    logfire.instrument_httpx(capture_all=True)\n\n\nclass AILanguageServer(LanguageServer):\n    def __init__(self):\n        super().__init__(\"ai-lsp\", version(\"ai-lsp\"))\n        logfire.info(\"Initializing AI Language Server\")\n        self._pending_tasks: dict[str, asyncio.Task[Any]] = {}\n        self._analysis_locks: dict[str, asyncio.Lock] = {}\n        self.agent: Agent[DiagnosticResult, Any] = create_diagnostic_agent(\n            model=settings.ai_lsp_model\n        )\n        logfire.info(\"AI agent initialized successfully\")\n\n    def find_snippet_in_text(\n        self, text: str, snippet: str\n    ) -> list[tuple[int, int, int, int]]:\n        \"\"\"Find all occurrences of code snippet in text, return positions as (start_line, start_col, end_line, end_col)\"\"\"\n        snippet = snippet.strip()\n        positions = []\n\n        # Search for all occurrences of snippet\n        start_pos = 0\n        while True:\n            start_pos = text.find(snippet, start_pos)\n            if start_pos == -1:\n                break\n\n            # Convert character position to line\/column\n            lines = text[:start_pos].split(\"\\n\")\n            start_line = len(lines) - 1\n            start_col = len(lines[-1])\n\n            # Calculate end position\n            snippet_lines = snippet.split(\"\\n\")\n            if len(snippet_lines) == 1:\n                end_line = start_line\n                end_col = start_col + len(snippet)\n            else:\n                end_line = start_line + len(snippet_lines) - 1\n                end_col = len(snippet_lines[-1])\n\n            positions.append((start_line, start_col, end_line, end_col))\n            start_pos += 1  # Move past this occurrence\n\n        if not positions:\n            logfire.warn(f\"Could not find snippet '{snippet}' in text\")\n        else:\n            logfire.debug(f\"Found {len(positions)} occurrences of '{snippet[:20]}...'\")\n\n        return positions\n\n    async def debounced_analyze(self, uri: str, text: str):\n        \"\"\"Debounced analysis that cancels previous calls\"\"\"\n        # Cancel any existing task for this URI\n        if uri in self._pending_tasks:\n            self._pending_tasks[uri].cancel()\n            _ = self._pending_tasks.pop(uri, None)\n\n        # Create new task\n        task: asyncio.Task[None] = asyncio.create_task(self._delayed_analyze(uri, text))\n        self._pending_tasks[uri] = task\n\n        try:\n            await task\n        except asyncio.CancelledError:\n            logfire.debug(f\"Analysis cancelled for {uri}\")\n        finally:\n            # Clean up completed task\n            if uri in self._pending_tasks and self._pending_tasks[uri] == task:\n                _ = self._pending_tasks.pop(uri)\n\n    async def _delayed_analyze(self, uri: str, text: str):\n        \"\"\"Wait for debounce period then analyze\"\"\"\n        await asyncio.sleep(settings.debounce_ms \/ 1000.0)\n        diagnostics = await self.analyze_document(uri, text)\n        # pyrefly: ignore [missing-attribute]\n        self.publish_diagnostics(uri, diagnostics)\n        logfire.debug(f\"Published {len(diagnostics)} diagnostics for {uri}\")\n\n    async def analyze_document(self, uri: str, text: str) -> list[Diagnostic]:\n        # Ensure we have a lock for this URI\n        lock = self._analysis_locks.setdefault(uri, asyncio.Lock())\n        async with lock:\n            with logfire.span(\"analyze_document\", uri=uri):\n                logfire.info(f\"Starting AI analysis for {uri}\")\n\n                try:\n                    file_path = Path(uri.replace(\"file:\/\/\", \"\"))\n                    language = self._detect_language(file_path)\n\n                    prompt = f\"\"\"Analyze this {language} code for issues:\n\n```{language}\n{text}\n```\n\nFile: {file_path.name}\"\"\"\n\n                    result = await self.agent.run(prompt)\n                    logfire.info(\n                        f\"AI analysis completed, found {len(result.output.issues)} issues\"\n                    )\n\n                    diagnostics = []\n                    for issue in result.output.issues:\n                        positions = self.find_snippet_in_text(text, issue.issue_snippet)\n\n                        if positions:\n                            start_line, start_col, end_line, end_col = positions[0]\n                            diagnostic = Diagnostic(\n                                range=Range(\n                                    start=Position(\n                                        line=start_line, character=start_col\n                                    ),\n                                    end=Position(line=end_line, character=end_col),\n                                ),\n                                message=f\"AI LSP: {issue.message}\",\n                                severity=self._get_diagnostic_severity(issue.severity),\n                                source=\"ai-lsp\",\n                                data={\n                                    \"issue_snippet\": issue.issue_snippet,\n                                    \"suggested_fixes\": [\n                                        {\n                                            \"title\": fix.title,\n                                            \"target_snippet\": fix.target_snippet,\n                                            \"replacement_snippet\": fix.replacement_snippet,\n                                        }\n                                        for fix in (issue.suggested_fixes or [])\n                                    ],\n                                },\n                            )\n                            diagnostics.append(diagnostic)\n\n                    return diagnostics\n\n                except Exception as e:\n                    logfire.error(\n                        f\"AI analysis failed for {uri}: {str(e)}\", _exc_info=True\n                    )\n                    return []\n\n    def _get_diagnostic_severity(self, severity: str) -> DiagnosticSeverity:\n        match severity:\n            case \"error\":\n                return DiagnosticSeverity.Error\n            case \"warning\":\n                return DiagnosticSeverity.Warning\n            case \"info\":\n                return DiagnosticSeverity.Information\n            case \"hint\":\n                return DiagnosticSeverity.Hint\n            case _:\n                return DiagnosticSeverity.Information\n\n    def _detect_language(self, file_path: Path) -> str:\n        match file_path.suffix:\n            case \".py\":\n                return \"python\"\n            case \".js\":\n                return \"javascript\"\n            case \".ts\":\n                return \"typescript\"\n            case \".jsx\":\n                return \"jsx\"\n            case \".tsx\":\n                return \"tsx\"\n            case \".rs\":\n                return \"rust\"\n            case \".go\":\n                return \"go\"\n            case \".java\":\n                return \"java\"\n            case \".cpp\":\n                return \"cpp\"\n            case \".c\":\n                return \"c\"\n            case \".lua\":\n                return \"lua\"\n            case _:\n                return \"text\"\n\n\nserver = AILanguageServer()\n\n\n@server.feature(TEXT_DOCUMENT_DID_OPEN)\nasync def did_open(params: DidOpenTextDocumentParams):\n    logfire.info(f\"Document opened: {params.text_document.uri}\")\n    doc = params.text_document\n    await server.debounced_analyze(doc.uri, doc.text)\n\n\n@server.feature(TEXT_DOCUMENT_DID_SAVE)\nasync def did_save(params: DidSaveTextDocumentParams):\n    logfire.info(f\"Document saved: {params.text_document.uri}\")\n    doc = server.workspace.get_text_document(params.text_document.uri)\n    await server.debounced_analyze(doc.uri, doc.source)\n\n\n@server.feature(TEXT_DOCUMENT_DID_CHANGE)\nasync def did_change(params: DidChangeTextDocumentParams):\n    logfire.debug(f\"Document changed: {params.text_document.uri}\")\n    doc = server.workspace.get_text_document(params.text_document.uri)\n    await server.debounced_analyze(doc.uri, doc.source)\n\n\n@server.feature(\n    TEXT_DOCUMENT_CODE_ACTION,\n    CodeActionOptions(code_action_kinds=[CodeActionKind.QuickFix]),\n)\nasync def code_actions(params: CodeActionParams) -> list[CodeAction]:\n    with logfire.span(\"code_actions\", uri=params.text_document.uri):\n        actions: list[CodeAction] = []\n        uri = params.text_document.uri\n        doc = server.workspace.get_text_document(uri)\n\n        for diagnostic in params.context.diagnostics:\n            if diagnostic.source != \"ai-lsp\" or not diagnostic.data:\n                continue\n\n            suggested_fixes = diagnostic.data.get(\"suggested_fixes\", [])\n\n            for fix_data in suggested_fixes:\n                target_positions = server.find_snippet_in_text(\n                    doc.source, fix_data[\"target_snippet\"]\n                )\n\n                if target_positions:\n                    with logfire.span(\"creating_quick_fix\", title=fix_data[\"title\"]):\n                        start_line, start_col, end_line, end_col = target_positions[0]\n                        fix_range = Range(\n                            start=Position(line=start_line, character=start_col),\n                            end=Position(line=end_line, character=end_col),\n                        )\n\n                        edit = WorkspaceEdit(\n                            changes={\n                                uri: [\n                                    TextEdit(\n                                        range=fix_range,\n                                        new_text=fix_data[\"replacement_snippet\"],\n                                    )\n                                ]\n                            }\n                        )\n\n                        action = CodeAction(\n                            title=f\"Apply: {fix_data['title']}\",\n                            kind=CodeActionKind.QuickFix,\n                            edit=edit,\n                            diagnostics=[diagnostic],\n                            is_preferred=True,\n                        )\n                        actions.append(action)\n\n            actions.append(\n                CodeAction(\n                    title=\"Regenerate AI fix\",\n                    kind=CodeActionKind.QuickFix,\n                    command=Command(\n                        title=\"Regenerate fix\",\n                        command=\"ai-lsp.regenerateFix\",\n                        arguments=[\n                            uri,\n                            diagnostic.data.get(\"issue_snippet\"),\n                            diagnostic.range.start.line,\n                            diagnostic.range.start.character,\n                        ],\n                    ),\n                    diagnostics=[diagnostic],\n                )\n            )\n\n            actions.append(\n                CodeAction(\n                    title=\"Dismiss AI suggestion\",\n                    kind=CodeActionKind.QuickFix,\n                    command=Command(\n                        title=\"Dismiss\",\n                        command=\"ai-lsp.dismiss\",\n                        arguments=[\n                            uri,\n                            diagnostic.range.start.line,\n                            diagnostic.range.start.character,\n                        ],\n                    ),\n                    diagnostics=[diagnostic],\n                )\n            )\n\n        return actions\n\n\n@server.command(\"ai-lsp.regenerateFix\")\nasync def regenerate_fix(*args):\n    if len(args) < 4:\n        return\n\n    uri, issue_snippet, line, character = args[0], args[1], args[2], args[3]\n\n    with logfire.span(\"regenerate_fix\", uri=uri, issue_snippet=issue_snippet):\n        logfire.info(\n            f\"Regenerating fix for '{issue_snippet}' at {uri}:{line}:{character}\"\n        )\n\n        doc = server.workspace.get_text_document(uri)\n        file_path = Path(uri.replace(\"file:\/\/\", \"\"))\n        language = server._detect_language(file_path)\n\n        prompt = f\"\"\"Analyze this specific code issue and provide NEW suggested fixes.\n\nIssue snippet: {issue_snippet}\n\nFull code context:\n```{language}\n{doc.source}\n```\n\nFile: {file_path.name}\n\nFocus ONLY on the issue at the snippet shown. Provide fresh, alternative fixes if possible.\"\"\"\n\n        try:\n            result = await server.agent.run(prompt)\n\n            if not result.output.issues:\n                logfire.warn(\"No issues returned for regeneration\")\n                return\n\n            regenerated_issue = result.output.issues[0]\n\n            current_diags = getattr(server.lsp, \"diagnostics\", {}).get(uri, [])\n            updated_diags = []\n\n            for diag in current_diags:\n                if (\n                    diag.source == \"ai-lsp\"\n                    and diag.range.start.line == line\n                    and diag.range.start.character == character\n                ):\n                    positions = server.find_snippet_in_text(\n                        doc.source, regenerated_issue.issue_snippet\n                    )\n                    if positions:\n                        start_line, start_col, end_line, end_col = positions[0]\n                        updated_diag = Diagnostic(\n                            range=Range(\n                                start=Position(line=start_line, character=start_col),\n                                end=Position(line=end_line, character=end_col),\n                            ),\n                            message=f\"AI LSP: {regenerated_issue.message}\",\n                            severity=server._get_diagnostic_severity(\n                                regenerated_issue.severity\n                            ),\n                            source=\"ai-lsp\",\n                            data={\n                                \"issue_snippet\": regenerated_issue.issue_snippet,\n                                \"suggested_fixes\": [\n                                    {\n                                        \"title\": fix.title,\n                                        \"target_snippet\": fix.target_snippet,\n                                        \"replacement_snippet\": fix.replacement_snippet,\n                                    }\n                                    for fix in (regenerated_issue.suggested_fixes or [])\n                                ],\n                            },\n                        )\n                        updated_diags.append(updated_diag)\n                        logfire.info(\n                            f\"Regenerated diagnostic with {len(regenerated_issue.suggested_fixes or [])} new fixes\"\n                        )\n                else:\n                    updated_diags.append(diag)\n\n            server.publish_diagnostics(uri, updated_diags)\n\n        except Exception as e:\n            logfire.error(f\"Failed to regenerate fix: {str(e)}\", _exc_info=True)\n\n\n@server.command(\"ai-lsp.dismiss\")\ndef dismiss_suggestion(*args):\n    if len(args) < 3:\n        return\n\n    uri, line, character = args[0], args[1], args[2]\n\n    with logfire.span(\"dismiss_suggestion\", uri=uri, line=line, character=character):\n        logfire.info(f\"Dismissing suggestion at {uri}:{line}:{character}\")\n\n        doc = server.workspace.get_text_document(uri)\n        diagnostics = []\n\n        current_diags = getattr(server.lsp, \"diagnostics\", {}).get(uri, [])\n        for diag in current_diags:\n            if (\n                diag.source == \"ai-lsp\"\n                and diag.range.start.line == line\n                and diag.range.start.character == character\n            ):\n                continue\n            diagnostics.append(diag)\n\n        server.publish_diagnostics(uri, diagnostics)\n\n\ndef app():\n    server.start_io()\n\n\nif __name__ == \"__main__\":\n    app()\n\n```\n\nFile: main.py","assistant":"{\n  \"issues\": [\n    {\n      \"issue_snippet\": \"find_snippet_in_text\",\n      \"severity\": \"error\",\n      \"message\": \"The `find_snippet_in_text` method is used to locate AI-generated snippets (e.g., `issue_snippet` for diagnostics, `target_snippet` for fixes) within the document. This method performs a simple string search and returns the first match. If the AI provides a snippet that is not unique or is a common substring, the diagnostic or quick-fix will be applied to the wrong location. This can lead to mis-highlighted issues and potentially incorrect application of fixes. A more robust approach is required, such as the AI providing exact line\/column ranges in its output, or a context-aware matching algorithm that considers the surrounding code.\",\n      \"suggested_fixes\": null\n    },\n    {\n      \"issue_snippet\": \"getattr\",\n      \"severity\": \"warning\",\n      \"message\": \"Accessing `server.lsp.diagnostics` via `getattr` relies on an internal, non-public attribute of the `pygls` LanguageServer. This is an architectural anti-pattern that makes the code fragile and prone to breaking with future updates to the `pygls` library. Diagnostics should be managed through the public API or within the `AILanguageServer` class's own state (e.g., a dedicated dictionary `self._diagnostics_cache`) and only published via `server.publish_diagnostics`.\",\n      \"suggested_fixes\": null\n    },\n    {\n      \"issue_snippet\": \"file_path.name\",\n      \"severity\": \"info\",\n      \"message\": \"The `file_path.name` variable is directly interpolated into the LLM prompt. While less critical than code content, unvalidated external input in a prompt can sometimes lead to prompt injection or unintended LLM behavior if the filename contains special characters or patterns recognized by the LLM as instructions or delimiters. It's a good security practice to sanitize or escape all user-controlled inputs provided to an LLM, even for seemingly innocuous fields like filenames.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Escape filename in prompt to prevent misinterpretation\",\n          \"target_snippet\": \"{file_path.name}\",\n          \"replacement_snippet\": \"`{file_path.name}`\"\n        }\n      ]\n    }\n  ]\n}"}
{"system":"You are an AI code analyzer that provides semantic insights that traditional LSPs cannot detect.\n\nONLY flag issues that require deep semantic understanding:\n- Logic errors in algorithms or business logic\n- Subtle race conditions or concurrency issues  \n- Architectural problems and design pattern violations\n- Security vulnerabilities requiring context understanding\n- Performance anti-patterns that need semantic analysis\n- Complex data flow issues\n- Domain-specific best practice violations\n- Accessibility issues requiring UX understanding\n\nDO NOT flag issues that normal LSPs handle:\n- Syntax errors\n- Basic type errors  \n- Undefined variables\n- Import issues\n- Basic formatting problems\n- Simple linting rules\n\nFor each issue, provide:\n- The exact issue_snippet that has the problem (ONLY the problematic token\/value, e.g. just \"python\" not 'command = \"python\"')\n- Clear explanation of WHY this needs human attention in the message\n- Use severity: \"info\" for suggestions, \"warning\" for concerns, \"error\" for serious logic issues\n- When possible, provide suggested_fixes with:\n  - target_snippet: the exact code to replace (same as issue_snippet usually)\n  - replacement_snippet: the replacement code\n  - title: clear description of the fix\n\nFocus on insights that require understanding code intent and context. Keep issue_snippet to the absolute minimum - just the problematic token.\n","user":"Analyze this python code for issues:\n\n```python\n\n\n```\n\nFile: __init__.py","assistant":"{\n  \"issues\": []\n}"}
{"system":"You are an AI code analyzer that provides semantic insights that traditional LSPs cannot detect.\n\nONLY flag issues that require deep semantic understanding:\n- Logic errors in algorithms or business logic\n- Subtle race conditions or concurrency issues  \n- Architectural problems and design pattern violations\n- Security vulnerabilities requiring context understanding\n- Performance anti-patterns that need semantic analysis\n- Complex data flow issues\n- Domain-specific best practice violations\n- Accessibility issues requiring UX understanding\n\nDO NOT flag issues that normal LSPs handle:\n- Syntax errors\n- Basic type errors  \n- Undefined variables\n- Import issues\n- Basic formatting problems\n- Simple linting rules\n\nFor each issue, provide:\n- The exact issue_snippet that has the problem (ONLY the problematic token\/value, e.g. just \"python\" not 'command = \"python\"')\n- Clear explanation of WHY this needs human attention in the message\n- Use severity: \"info\" for suggestions, \"warning\" for concerns, \"error\" for serious logic issues\n- When possible, provide suggested_fixes with:\n  - target_snippet: the exact code to replace (same as issue_snippet usually)\n  - replacement_snippet: the replacement code\n  - title: clear description of the fix\n\nFocus on insights that require understanding code intent and context. Keep issue_snippet to the absolute minimum - just the problematic token.\n","user":"Analyze this python code for issues:\n\n```python\nfrom pathlib import Path\n\nimport typer\nfrom rich.console import Console\n\nfrom ai_lsp.finetune.dataset import convert_otel_to_dataset\nfrom ai_lsp.finetune.train import train_model\n\napp = typer.Typer(name=\"finetune\", help=\"Fine-tune an SLM on otel traces\")\nconsole = Console()\n\n\n@app.command()\ndef prepare_dataset(\n    otel_file: Path = typer.Argument(..., help=\"Path to otel JSONL file\"),\n    output_file: Path = typer.Option(\n        \"dataset.json\", help=\"Output path for processed dataset\"\n    ),\n) -> None:\n    console.print(f\"[bold]Converting {otel_file} to training dataset...[\/bold]\")\n    \n    dataset = convert_otel_to_dataset(otel_file)\n    \n    console.print(f\"[green]\u2713[\/green] Extracted {len(dataset)} training examples\")\n    \n    dataset.to_json(output_file)\n    \n    console.print(f\"[green]\u2713[\/green] Saved dataset to {output_file}\")\n\n\n@app.command()\ndef train(\n    dataset_file: Path = typer.Argument(..., help=\"Path to dataset JSON file\"),\n    model_name: str = typer.Option(\n        \"google\/gemma-2-2b-it\", help=\"Base model to fine-tune\"\n    ),\n    output_dir: Path = typer.Option(\n        \".\/finetuned-model\", help=\"Output directory for fine-tuned model\"\n    ),\n    num_epochs: int = typer.Option(3, help=\"Number of training epochs\"),\n    batch_size: int = typer.Option(2, help=\"Training batch size\"),\n    learning_rate: float = typer.Option(2e-4, help=\"Learning rate\"),\n) -> None:\n    from datasets import Dataset\n    \n    console.print(f\"[bold]Loading dataset from {dataset_file}...[\/bold]\")\n    dataset = Dataset.from_json(str(dataset_file))\n    \n    console.print(f\"[green]\u2713[\/green] Loaded {len(dataset)} training examples\")\n    console.print(f\"[bold]Starting fine-tuning with {model_name}...[\/bold]\")\n    \n    train_model(\n        dataset=dataset,\n        model_name=model_name,\n        output_dir=output_dir,\n        num_epochs=num_epochs,\n        batch_size=batch_size,\n        learning_rate=learning_rate,\n    )\n    \n    console.print(f\"[green]\u2713[\/green] Fine-tuning complete! Model saved to {output_dir}\")\n\n\n@app.command()\ndef pipeline(\n    otel_file: Path = typer.Argument(..., help=\"Path to otel JSONL file\"),\n    model_name: str = typer.Option(\n        \"google\/gemma-2-2b-it\", help=\"Base model to fine-tune\"\n    ),\n    output_dir: Path = typer.Option(\n        \".\/finetuned-model\", help=\"Output directory for fine-tuned model\"\n    ),\n    num_epochs: int = typer.Option(3, help=\"Number of training epochs\"),\n) -> None:\n    console.print(\"[bold]Running complete fine-tuning pipeline...[\/bold]\")\n    \n    console.print(f\"\\n[bold blue]Step 1:[\/bold blue] Converting otel traces to dataset\")\n    dataset = convert_otel_to_dataset(otel_file)\n    console.print(f\"[green]\u2713[\/green] Extracted {len(dataset)} training examples\")\n    \n    console.print(f\"\\n[bold blue]Step 2:[\/bold blue] Fine-tuning {model_name}\")\n    train_model(\n        dataset=dataset,\n        model_name=model_name,\n        output_dir=output_dir,\n        num_epochs=num_epochs,\n    )\n    \n    console.print(f\"\\n[green]\u2713[\/green] Pipeline complete! Model saved to {output_dir}\")\n\n```\n\nFile: cli.py","assistant":"{\n  \"issues\": [\n    {\n      \"issue_snippet\": \"train_model\",\n      \"severity\": \"error\",\n      \"message\": \"The `pipeline` command orchestrates the `convert_otel_to_dataset` and `train_model` steps. However, when calling `train_model`, it omits `batch_size` and `learning_rate` parameters, which are available as options in the standalone `train` command. This inconsistency limits user control over crucial training parameters when using the integrated pipeline, potentially leading to suboptimal or unexpected model training outcomes if the defaults within `train_model` are not suitable.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Add batch_size and learning_rate options to pipeline command\",\n          \"target_snippet\": \"num_epochs: int = typer.Option(3, help=\\\"Number of training epochs\\\"),\",\n          \"replacement_snippet\": \"num_epochs: int = typer.Option(3, help=\\\"Number of training epochs\\\"),\\n    batch_size: int = typer.Option(2, help=\\\"Training batch size\\\"),\\n    learning_rate: float = typer.Option(2e-4, help=\\\"Learning rate\\\"),\"\n        },\n        {\n          \"title\": \"Pass batch_size and learning_rate to train_model in pipeline\",\n          \"target_snippet\": \"num_epochs=num_epochs,\",\n          \"replacement_snippet\": \"num_epochs=num_epochs,\\n        batch_size=batch_size,\\n        learning_rate=learning_rate,\"\n        }\n      ]\n    }\n  ]\n}"}
{"system":"You are an AI code analyzer that provides semantic insights that traditional LSPs cannot detect.\n\nONLY flag issues that require deep semantic understanding:\n- Logic errors in algorithms or business logic\n- Subtle race conditions or concurrency issues  \n- Architectural problems and design pattern violations\n- Security vulnerabilities requiring context understanding\n- Performance anti-patterns that need semantic analysis\n- Complex data flow issues\n- Domain-specific best practice violations\n- Accessibility issues requiring UX understanding\n\nDO NOT flag issues that normal LSPs handle:\n- Syntax errors\n- Basic type errors  \n- Undefined variables\n- Import issues\n- Basic formatting problems\n- Simple linting rules\n\nFor each issue, provide:\n- The exact issue_snippet that has the problem (ONLY the problematic token\/value, e.g. just \"python\" not 'command = \"python\"')\n- Clear explanation of WHY this needs human attention in the message\n- Use severity: \"info\" for suggestions, \"warning\" for concerns, \"error\" for serious logic issues\n- When possible, provide suggested_fixes with:\n  - target_snippet: the exact code to replace (same as issue_snippet usually)\n  - replacement_snippet: the replacement code\n  - title: clear description of the fix\n\nFocus on insights that require understanding code intent and context. Keep issue_snippet to the absolute minimum - just the problematic token.\n","user":"Analyze this python code for issues:\n\n```python\nimport json\nfrom pathlib import Path\n\nfrom datasets import Dataset\nfrom pydantic import BaseModel\n\n\nclass TrainingExample(BaseModel):\n    system: str\n    user: str\n    assistant: str\n\n\ndef extract_code_from_span(span: dict) -> str | None:\n    events = span.get(\"events\", [])\n    for event in events:\n        if event.get(\"name\") == \"gen_ai.user.message\":\n            attrs = event.get(\"attributes\", [])\n            for attr in attrs:\n                if attr.get(\"key\") == \"content\":\n                    content = attr.get(\"value\", {}).get(\"stringValue\", \"\")\n                    if \"```python\" in content:\n                        start = content.find(\"```python\") + 9\n                        end = content.find(\"```\", start)\n                        if end > start:\n                            return content[start:end].strip()\n    return None\n\n\ndef extract_issues_from_span(span: dict) -> list[dict] | None:\n    attrs = span.get(\"attributes\", [])\n    for attr in attrs:\n        if attr.get(\"key\") == \"final_result\":\n            result_str = attr.get(\"value\", {}).get(\"stringValue\", \"\")\n            if result_str:\n                result = json.loads(result_str)\n                return result.get(\"issues\", [])\n    return None\n\n\ndef convert_otel_to_dataset(otel_file: Path) -> Dataset:\n    examples = []\n    \n    with open(otel_file) as f:\n        for line in f:\n            if not line.strip():\n                continue\n                \n            data = json.loads(line)\n            resource_spans = data.get(\"resourceSpans\", [])\n            \n            for resource_span in resource_spans:\n                scope_spans = resource_span.get(\"scopeSpans\", [])\n                \n                for scope_span in scope_spans:\n                    if scope_span.get(\"scope\", {}).get(\"name\") != \"pydantic-ai\":\n                        continue\n                    \n                    spans = scope_span.get(\"spans\", [])\n                    for span in spans:\n                        if span.get(\"name\") != \"agent run\":\n                            continue\n                        \n                        code = extract_code_from_span(span)\n                        issues = extract_issues_from_span(span)\n                        \n                        if code and issues:\n                            system_prompt = (\n                                \"You are an AI code analyzer specialized in identifying \"\n                                \"semantic issues in code that traditional LSPs cannot detect. \"\n                                \"Focus on logic errors, concurrency issues, architectural \"\n                                \"problems, and performance anti-patterns.\"\n                            )\n                            \n                            user_prompt = f\"Analyze this Python code:\\n\\n```python\\n{code}\\n```\"\n                            \n                            assistant_response = json.dumps({\"issues\": issues}, indent=2)\n                            \n                            examples.append({\n                                \"system\": system_prompt,\n                                \"user\": user_prompt,\n                                \"assistant\": assistant_response,\n                            })\n    \n    return Dataset.from_list(examples)\n\n```\n\nFile: dataset.py","assistant":"{\n  \"issues\": [\n    {\n      \"issue_snippet\": \"json.loads(result_str)\",\n      \"severity\": \"error\",\n      \"message\": \"The `json.loads` call in `extract_issues_from_span` does not handle `json.JSONDecodeError`. If 'final_result' is malformed or not valid JSON, this will crash the application. Robust error handling is crucial for processing external or untrusted data.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Add try-except block for JSON decoding\",\n          \"target_snippet\": \"result = json.loads(result_str)\",\n          \"replacement_snippet\": \"try:\\n                    result = json.loads(result_str)\\n                except json.JSONDecodeError:\\n                    # Log error or return None\/empty list as appropriate\\n                    return None\"\n        }\n      ]\n    },\n    {\n      \"issue_snippet\": \"json.loads(line)\",\n      \"severity\": \"error\",\n      \"message\": \"The `json.loads` call when processing each line of the OTEL file does not handle `json.JSONDecodeError`. If any line is not valid JSON, the entire conversion process will crash. This makes the data loading process brittle.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Add try-except block for JSON decoding per line\",\n          \"target_snippet\": \"data = json.loads(line)\",\n          \"replacement_snippet\": \"            try:\\n                data = json.loads(line)\\n            except json.JSONDecodeError:\\n                print(f\\\"Warning: Skipping malformed JSON line: {line.strip()}\\\")\\n                continue\"\n        }\n      ]\n    },\n    {\n      \"issue_snippet\": \"content.find(\\\"```\\\", start)\",\n      \"severity\": \"info\",\n      \"message\": \"The current code extraction logic might be brittle if the closing '```' delimiter appears within the Python code itself (e.g., in a string literal or comment). This could lead to premature truncation of the extracted code. While often handled by markdown parsers, it's a subtle edge case.\",\n      \"suggested_fixes\": []\n    }\n  ]\n}"}
{"system":"You are an AI code analyzer that provides semantic insights that traditional LSPs cannot detect.\n\nONLY flag issues that require deep semantic understanding:\n- Logic errors in algorithms or business logic\n- Subtle race conditions or concurrency issues  \n- Architectural problems and design pattern violations\n- Security vulnerabilities requiring context understanding\n- Performance anti-patterns that need semantic analysis\n- Complex data flow issues\n- Domain-specific best practice violations\n- Accessibility issues requiring UX understanding\n\nDO NOT flag issues that normal LSPs handle:\n- Syntax errors\n- Basic type errors  \n- Undefined variables\n- Import issues\n- Basic formatting problems\n- Simple linting rules\n\nFor each issue, provide:\n- The exact issue_snippet that has the problem (ONLY the problematic token\/value, e.g. just \"python\" not 'command = \"python\"')\n- Clear explanation of WHY this needs human attention in the message\n- Use severity: \"info\" for suggestions, \"warning\" for concerns, \"error\" for serious logic issues\n- When possible, provide suggested_fixes with:\n  - target_snippet: the exact code to replace (same as issue_snippet usually)\n  - replacement_snippet: the replacement code\n  - title: clear description of the fix\n\nFocus on insights that require understanding code intent and context. Keep issue_snippet to the absolute minimum - just the problematic token.\n","user":"Analyze this python code for issues:\n\n```python\nfrom pathlib import Path\n\nimport torch\nfrom datasets import Dataset\nfrom peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    TrainingArguments,\n)\nfrom trl import SFTTrainer\n\n\ndef format_examples(examples: dict) -> list[str]:\n    texts = []\n    for system, user, assistant in zip(\n        examples[\"system\"], examples[\"user\"], examples[\"assistant\"]\n    ):\n        text = f\"<|system|>\\n{system}\\n<|user|>\\n{user}\\n<|assistant|>\\n{assistant}\"\n        texts.append(text)\n    return texts\n\n\ndef train_model(\n    dataset: Dataset,\n    model_name: str = \"google\/gemma-2-2b-it\",\n    output_dir: Path | str = \".\/finetuned-model\",\n    num_epochs: int = 3,\n    batch_size: int = 2,\n    learning_rate: float = 2e-4,\n    max_seq_length: int = 2048,\n) -> None:\n    bnb_config = BitsAndBytesConfig(\n        load_in_4bit=True,\n        bnb_4bit_quant_type=\"nf4\",\n        bnb_4bit_compute_dtype=torch.bfloat16,\n        bnb_4bit_use_double_quant=True,\n    )\n    \n    model = AutoModelForCausalLM.from_pretrained(\n        model_name,\n        quantization_config=bnb_config,\n        device_map=\"auto\",\n        torch_dtype=torch.bfloat16,\n    )\n    \n    model = prepare_model_for_kbit_training(model)\n    \n    peft_config = LoraConfig(\n        r=16,\n        lora_alpha=32,\n        target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n        lora_dropout=0.05,\n        bias=\"none\",\n        task_type=\"CAUSAL_LM\",\n    )\n    \n    model = get_peft_model(model, peft_config)\n    \n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    tokenizer.pad_token = tokenizer.eos_token\n    tokenizer.padding_side = \"right\"\n    \n    training_args = TrainingArguments(\n        output_dir=str(output_dir),\n        num_train_epochs=num_epochs,\n        per_device_train_batch_size=batch_size,\n        gradient_accumulation_steps=4,\n        learning_rate=learning_rate,\n        fp16=False,\n        bf16=True,\n        logging_steps=10,\n        optim=\"paged_adamw_8bit\",\n        save_strategy=\"epoch\",\n        warmup_ratio=0.1,\n        lr_scheduler_type=\"cosine\",\n        report_to=\"none\",\n    )\n    \n    trainer = SFTTrainer(\n        model=model,\n        train_dataset=dataset,\n        peft_config=peft_config,\n        formatting_func=format_examples,\n        max_seq_length=max_seq_length,\n        tokenizer=tokenizer,\n        args=training_args,\n    )\n    \n    trainer.train()\n    \n    trainer.model.save_pretrained(output_dir)\n    tokenizer.save_pretrained(output_dir)\n\n```\n\nFile: train.py","assistant":"{\n  \"issues\": [\n    {\n      \"issue_snippet\": \"\\\"right\\\"\",\n      \"severity\": \"warning\",\n      \"message\": \"For causal language models, it is generally recommended to use `padding_side='left'` when fine-tuning, especially with `SFTTrainer`. Padding on the right can lead to the model learning to predict padding tokens or subtly affect the attention mechanism and generation quality. Left padding ensures that the actual sequence tokens are at the end of the input, which is often more aligned with the causal attention mechanism.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Change padding side to 'left' for causal LMs\",\n          \"target_snippet\": \"\\\"right\\\"\",\n          \"replacement_snippet\": \"\\\"left\\\"\"\n        }\n      ]\n    }\n  ]\n}"}
{"system":"You are an AI code analyzer that provides semantic insights that traditional LSPs cannot detect.\n\nONLY flag issues that require deep semantic understanding:\n- Logic errors in algorithms or business logic\n- Subtle race conditions or concurrency issues  \n- Architectural problems and design pattern violations\n- Security vulnerabilities requiring context understanding\n- Performance anti-patterns that need semantic analysis\n- Complex data flow issues\n- Domain-specific best practice violations\n- Accessibility issues requiring UX understanding\n\nDO NOT flag issues that normal LSPs handle:\n- Syntax errors\n- Basic type errors  \n- Undefined variables\n- Import issues\n- Basic formatting problems\n- Simple linting rules\n\nFor each issue, provide:\n- The exact issue_snippet that has the problem (ONLY the problematic token\/value, e.g. just \"python\" not 'command = \"python\"')\n- Clear explanation of WHY this needs human attention in the message\n- Use severity: \"info\" for suggestions, \"warning\" for concerns, \"error\" for serious logic issues\n- When possible, provide suggested_fixes with:\n  - target_snippet: the exact code to replace (same as issue_snippet usually)\n  - replacement_snippet: the replacement code\n  - title: clear description of the fix\n\nFocus on insights that require understanding code intent and context. Keep issue_snippet to the absolute minimum - just the problematic token.\n","user":"Analyze this text code for issues:\n\n```text\n# Quick Start: Fine-Tuning ai-lsp\n\n## Prerequisites\n\n\u2705 Apple Silicon Mac (M1\/M2\/M3\/M4)\n\u2705 ai-lsp installed and running\n\u2705 At least 50 code analysis examples collected\n\n## Step-by-Step Guide\n\n### 1. Collect Training Data\n\nRun ai-lsp normally in your editor for a few days:\n\n```bash\n# Start ai-lsp\nuv run ai-lsp serve\n\n# Work on your code as usual\n# ai-lsp will analyze and generate otel traces\n```\n\nCheck you have data:\n```bash\nls -lh ai-lsp-otel.jsonl\n# Should be several MB after a day of use\n```\n\n### 2. Convert to Training Dataset\n\n```bash\nuv run ai-lsp finetune prepare-dataset ai-lsp-otel.jsonl\n```\n\nOutput:\n```\n\u2713 Extracted 150 training examples\n\u2713 Saved dataset to dataset.json\n```\n\n### 3. Fine-Tune the Model\n\n```bash\nuv run ai-lsp finetune train dataset.json\n```\n\nThis will:\n- Download Gemma 2B (if not cached)\n- Train LoRA adapters on your data\n- Save model to `.\/finetuned-model\/`\n\nTypical output:\n```\nLoading dataset from dataset.json...\n\u2713 Loaded 150 training examples\nStarting fine-tuning with mlx-community\/gemma-2-2b-it-4bit...\n\nEpoch 1\/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 75\/75 [02:30<00:00]\nEpoch 2\/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 75\/75 [02:28<00:00]\nEpoch 3\/3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 75\/75 [02:29<00:00]\n\n\u2713 Fine-tuning complete! Model saved to .\/finetuned-model\n```\n\n### 4. Test Your Model\n\n```python\nfrom mlx_lm import load, generate\n\nmodel, tokenizer = load(\".\/finetuned-model\/model\")\n\ncode = \"\"\"\ndef process_users(users):\n    result = []\n    for u in users:\n        result.append(u.name)\n    return result\n\"\"\"\n\nprompt = f\"Analyze this Python code:\\n\\n```python\\n{code}\\n```\"\nresponse = generate(model, tokenizer, prompt=prompt, max_tokens=512)\nprint(response)\n```\n\n## One-Command Quickstart\n\nRun the entire pipeline:\n\n```bash\nuv run ai-lsp finetune pipeline ai-lsp-otel.jsonl\n```\n\nThis does steps 2-3 automatically!\n\n## What to Expect\n\n### First 50 examples\n- Model learns your code style\n- Basic pattern recognition\n- May hallucinate occasionally\n\n### 100-200 examples\n- Reliable issue detection\n- Good context awareness\n- Fewer false positives\n\n### 500+ examples\n- Production-ready quality\n- Deep codebase understanding\n- Specialized domain knowledge\n\n## Customization\n\n### Use a different model\n\n```bash\nuv run ai-lsp finetune train dataset.json \\\n  --model-name mlx-community\/Qwen2.5-7B-Instruct-4bit\n```\n\n### Train longer\n\n```bash\nuv run ai-lsp finetune train dataset.json \\\n  --num-epochs 10\n```\n\n### Adjust batch size\n\n```bash\nuv run ai-lsp finetune train dataset.json \\\n  --batch-size 1  # Use if running out of memory\n```\n\n## Common Issues\n\n**\"Not enough examples\"**\n\u2192 Keep using ai-lsp, you need at least 50 examples\n\n**\"Out of memory\"**\n\u2192 Add `--batch-size 1` to training command\n\n**\"Slow training\"**\n\u2192 Normal! ~5 minutes per 100 examples on M2\n\n**\"Model not improving\"**\n\u2192 Try `--num-epochs 10` for more training\n\n## Next Steps\n\n- \u2705 Collect more data by using ai-lsp daily\n- \u2705 Retrain monthly as codebase evolves\n- \u2705 Experiment with different models\n- \u2705 Share your results!\n\n## Getting Help\n\nIssues? Check:\n1. [FINETUNING.md](FINETUNING.md) - Complete architecture guide\n2. [src\/ai_lsp\/finetune\/README.md](src\/ai_lsp\/finetune\/README.md) - Detailed docs\n3. [GitHub Issues](https:\/\/github.com\/benomahony\/ai-lsp\/issues) - Ask questions\n\nHappy fine-tuning! \ud83d\ude80\n\n```\n\nFile: QUICKSTART-FINETUNING.md","assistant":"{\n  \"issues\": [\n    {\n      \"issue_snippet\": \"mlx_lm\",\n      \"severity\": \"error\",\n      \"message\": \"The 'Test Your Model' section uses `mlx_lm` without explicitly mentioning its installation in the prerequisites or setup steps. Users will encounter a `ModuleNotFoundError` if `mlx_lm` is not pre-installed, preventing them from testing their fine-tuned model.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Add mlx-lm installation to prerequisites\",\n          \"target_snippet\": \"\\u2705 ai-lsp installed and running\",\n          \"replacement_snippet\": \"\\u2705 ai-lsp installed and running\\n\\u2705 mlx-lm installed (pip install mlx-lm)\"\n        }\n      ]\n    },\n    {\n      \"issue_snippet\": \"--num-epochs 10\",\n      \"severity\": \"warning\",\n      \"message\": \"Increasing the number of epochs (e.g., to 10) without a robust validation strategy, especially with a limited dataset, significantly increases the risk of overfitting. The model might memorize the training examples rather than learning generalizable patterns, leading to poorer performance on new, unseen code.\",\n      \"suggested_fixes\": null\n    },\n    {\n      \"issue_snippet\": \"--batch-size 1\",\n      \"severity\": \"info\",\n      \"message\": \"While `--batch-size 1` effectively addresses out-of-memory errors, it often leads to highly inefficient GPU utilization and significantly slower training times. This is a common performance anti-pattern unless absolutely necessary, as it prevents the GPU from processing multiple examples in parallel.\",\n      \"suggested_fixes\": null\n    },\n    {\n      \"issue_snippet\": \"uv run ai-lsp finetune train dataset.json\",\n      \"severity\": \"warning\",\n      \"message\": \"The fine-tuning command and subsequent steps lack a clear strategy for model validation (e.g., using a separate validation set or monitoring metrics). Without validation, it's challenging to objectively assess the model's generalization performance, detect overfitting, or determine the optimal number of training epochs, especially when aiming for 'Production-ready quality'.\",\n      \"suggested_fixes\": null\n    }\n  ]\n}"}
{"system":"You are an AI code analyzer that provides semantic insights that traditional LSPs cannot detect.\n\nONLY flag issues that require deep semantic understanding:\n- Logic errors in algorithms or business logic\n- Subtle race conditions or concurrency issues  \n- Architectural problems and design pattern violations\n- Security vulnerabilities requiring context understanding\n- Performance anti-patterns that need semantic analysis\n- Complex data flow issues\n- Domain-specific best practice violations\n- Accessibility issues requiring UX understanding\n\nDO NOT flag issues that normal LSPs handle:\n- Syntax errors\n- Basic type errors  \n- Undefined variables\n- Import issues\n- Basic formatting problems\n- Simple linting rules\n\nFor each issue, provide:\n- The exact issue_snippet that has the problem (ONLY the problematic token\/value, e.g. just \"python\" not 'command = \"python\"')\n- Clear explanation of WHY this needs human attention in the message\n- Use severity: \"info\" for suggestions, \"warning\" for concerns, \"error\" for serious logic issues\n- When possible, provide suggested_fixes with:\n  - target_snippet: the exact code to replace (same as issue_snippet usually)\n  - replacement_snippet: the replacement code\n  - title: clear description of the fix\n\nFocus on insights that require understanding code intent and context. Keep issue_snippet to the absolute minimum - just the problematic token.\n","user":"Analyze this text code for issues:\n\n```text\n# Fine-Tuning Pipeline Architecture\n\n## Overview\n\nThe ai-lsp fine-tuning pipeline enables you to train a custom small language model on your actual code analysis patterns captured via OpenTelemetry traces.\n\n## Components\n\n### 1. Data Collection (`ai-lsp-otel.jsonl`)\n\nWhile ai-lsp runs, it emits OpenTelemetry traces containing:\n- Code being analyzed\n- AI model responses\n- Detected issues and suggestions\n- Performance metrics\n\nThese traces are captured in JSONL format by the OTEL collector.\n\n### 2. Dataset Conversion (`finetune\/dataset.py`)\n\nExtracts training examples from otel traces:\n\n```python\n{\n  \"system\": \"You are an AI code analyzer...\",\n  \"user\": \"Analyze this Python code:\\n\\n```python\\n...\\n```\",\n  \"assistant\": '{\"issues\": [...]}'\n}\n```\n\nKey functions:\n- `extract_code_from_span()` - Finds code in user messages\n- `extract_issues_from_span()` - Extracts AI analysis results\n- `convert_otel_to_dataset()` - Creates Hugging Face Dataset\n\n### 3. Training (`finetune\/train.py`)\n\nUses MLX for Apple Silicon optimization:\n\n```python\ndef train_model(\n    dataset: Dataset,\n    model_name: str = \"mlx-community\/gemma-2-2b-it-4bit\",\n    ...\n):\n    # 1. Format dataset as JSONL chat messages\n    # 2. Train LoRA adapters with mlx-lm\n    # 3. Fuse adapters with base model\n    # 4. Save complete model\n```\n\nTraining configuration:\n- **LoRA rank**: 16 (number of adapter parameters)\n- **Batch size**: 2 (adjustable based on RAM)\n- **Learning rate**: 1e-5 (lower for stability)\n- **Iterations**: `(examples * epochs) \/ batch_size`\n\n### 4. Inference (`finetune\/inference.py`)\n\nLoad and use fine-tuned models:\n\n```python\nfrom mlx_lm import load, generate\n\nmodel, tokenizer = load(\".\/finetuned-model\/model\")\nresponse = generate(model, tokenizer, prompt=...)\n```\n\n### 5. CLI (`finetune\/cli.py`)\n\nThree commands for the complete workflow:\n\n1. `prepare-dataset` - Convert otel \u2192 dataset.json\n2. `train` - Fine-tune model on dataset\n3. `pipeline` - Run both steps at once\n\n## Data Flow\n\n```\nai-lsp running in editor\n    \u2193\nOpenTelemetry traces\n    \u2193\nOTEL Collector\n    \u2193\nai-lsp-otel.jsonl\n    \u2193\n[prepare-dataset command]\n    \u2193\ndataset.json (training examples)\n    \u2193\n[train command]\n    \u2193\nfinetuned-model\/\n  \u251c\u2500\u2500 model\/      (complete fine-tuned model)\n  \u2514\u2500\u2500 adapters\/   (LoRA weights)\n```\n\n## Why MLX?\n\nMLX is Apple's ML framework optimized for Apple Silicon:\n\n\u2705 **Native performance** - Uses Metal for GPU acceleration\n\u2705 **Memory efficient** - Unified memory architecture\n\u2705 **Fast** - Optimized kernels for M-series chips\n\u2705 **Simple** - NumPy-like API, easy to use\n\nCompared to PyTorch + bitsandbytes:\n- 2-3x faster training on Mac\n- Lower memory usage\n- No CUDA dependency\n- Native Mac support\n\n## Model Selection\n\nChoose based on your needs:\n\n| Model | Size | RAM | Speed | Quality |\n|-------|------|-----|-------|---------|\n| Gemma 2B 4-bit | 2B | 8GB | Fast | Good |\n| Llama 3.2 3B 4-bit | 3B | 10GB | Medium | Better |\n| Qwen 2.5 7B 4-bit | 7B | 16GB | Slower | Best |\n| Phi-4 4-bit | 14B | 24GB | Slowest | Excellent |\n\n**Recommendation**: Start with Gemma 2B for prototyping, then scale up.\n\n## Training Best Practices\n\n### Dataset Size\n- **Minimum**: 50 examples (will overfit but usable)\n- **Good**: 100-200 examples (balanced results)\n- **Excellent**: 500+ examples (production quality)\n\n### Epochs\n- Small dataset (< 100): 5-10 epochs\n- Medium dataset (100-500): 3-5 epochs\n- Large dataset (500+): 1-3 epochs\n\n### Learning Rate\n- Start with `1e-5` (default)\n- Too high \u2192 unstable training\n- Too low \u2192 slow convergence\n\n### Monitoring\nCheck loss curves during training:\n- Decreasing \u2192 learning\n- Flat \u2192 increase epochs or learning rate\n- Increasing \u2192 reduce learning rate\n\n## Integration with ai-lsp\n\nAfter fine-tuning, integrate with ai-lsp:\n\n### Option 1: Use as primary model\n\nUpdate settings:\n```python\nAI_LSP_MODEL = \"mlx:\/\/.\/finetuned-model\/model\"\n```\n\n### Option 2: Ensemble approach\n\nUse fine-tuned model for specialized analysis:\n```python\nif is_critical_code():\n    result = finetuned_model.analyze(code)\nelse:\n    result = default_model.analyze(code)\n```\n\n## Performance Metrics\n\nTypical training on M2 Max (32GB):\n\n| Model | Examples | Epochs | Time | Memory |\n|-------|----------|--------|------|--------|\n| Gemma 2B | 100 | 3 | 5 min | 6 GB |\n| Gemma 2B | 500 | 3 | 20 min | 8 GB |\n| Qwen 7B | 100 | 3 | 15 min | 14 GB |\n| Qwen 7B | 500 | 3 | 60 min | 16 GB |\n\n## Troubleshooting\n\n### Common Issues\n\n**1. Empty dataset**\n- Ensure ai-lsp has generated traces\n- Check otel-collector is running\n- Verify file path is correct\n\n**2. Out of memory**\n- Reduce batch size to 1\n- Use smaller model (2B instead of 7B)\n- Close other applications\n- Try more quantized model (4-bit)\n\n**3. Poor quality**\n- Collect more diverse examples\n- Increase training epochs\n- Try larger base model\n- Check dataset for noise\n\n**4. Slow training**\n- Verify running on Apple Silicon\n- Check Activity Monitor for memory pressure\n- Reduce batch size if swapping\n\n## Next Steps\n\n1. **Collect data**: Run ai-lsp in your daily workflow\n2. **Initial training**: Fine-tune with 50-100 examples\n3. **Evaluate**: Test on held-out code samples\n4. **Iterate**: Collect more data and retrain monthly\n5. **Deploy**: Use fine-tuned model in production\n\n## Resources\n\n- [MLX Documentation](https:\/\/ml-explore.github.io\/mlx\/)\n- [mlx-lm Examples](https:\/\/github.com\/ml-explore\/mlx-examples\/tree\/main\/llms)\n- [LoRA Paper](https:\/\/arxiv.org\/abs\/2106.09685)\n- [Hugging Face Datasets](https:\/\/huggingface.co\/docs\/datasets\/)\n\n```\n\nFile: FINETUNING.md","assistant":"{\n  \"issues\": [\n    {\n      \"issue_snippet\": \"50\",\n      \"severity\": \"warning\",\n      \"message\": \"Recommending a minimum dataset size of '50 examples' for fine-tuning a language model for complex code analysis is highly optimistic. Such a small dataset is very likely to result in severe overfitting, poor generalization, and a model that struggles with real-world code diversity, making it practically unusable for robust analysis. Industry best practices for similar tasks often suggest hundreds or thousands of examples for even basic performance.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Increase minimum recommended dataset size for better generalization\",\n          \"target_snippet\": \"50\",\n          \"replacement_snippet\": \"at least 200\"\n        }\n      ]\n    },\n    {\n      \"issue_snippet\": \"is_critical_code\",\n      \"severity\": \"warning\",\n      \"message\": \"In the 'Ensemble approach' for integration, the function `is_critical_code()` is used to conditionally route code analysis. The document does not specify how 'critical code' is determined. This lack of definition represents an architectural ambiguity. Without clear and robust criteria (e.g., specific file paths, code ownership, or annotations), the routing logic could be inconsistent or difficult to maintain, potentially leading to critical code being analyzed by the less specialized `default_model` and missing crucial insights.\",\n      \"suggested_fixes\": null\n    },\n    {\n      \"issue_snippet\": \"1e-5\",\n      \"severity\": \"info\",\n      \"message\": \"The training configuration specifies a fixed learning rate of `1e-5`. While this is a common starting point, using a learning rate scheduler (e.g., cosine decay with warm-up) is generally a best practice for fine-tuning large language models. This can lead to more stable training, faster convergence, and potentially better final model performance by dynamically adjusting the learning rate throughout the training process.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Consider adding a learning rate scheduler for improved training stability and performance\",\n          \"target_snippet\": \"1e-5 (lower for stability)\",\n          \"replacement_snippet\": \"1e-5 (initial; consider using a scheduler like cosine decay for stability and better convergence)\"\n        }\n      ]\n    }\n  ]\n}"}
{"system":"You are an AI code analyzer that provides semantic insights that traditional LSPs cannot detect.\n\nONLY flag issues that require deep semantic understanding:\n- Logic errors in algorithms or business logic\n- Subtle race conditions or concurrency issues  \n- Architectural problems and design pattern violations\n- Security vulnerabilities requiring context understanding\n- Performance anti-patterns that need semantic analysis\n- Complex data flow issues\n- Domain-specific best practice violations\n- Accessibility issues requiring UX understanding\n\nDO NOT flag issues that normal LSPs handle:\n- Syntax errors\n- Basic type errors  \n- Undefined variables\n- Import issues\n- Basic formatting problems\n- Simple linting rules\n\nFor each issue, provide:\n- The exact issue_snippet that has the problem (ONLY the problematic token\/value, e.g. just \"python\" not 'command = \"python\"')\n- Clear explanation of WHY this needs human attention in the message\n- Use severity: \"info\" for suggestions, \"warning\" for concerns, \"error\" for serious logic issues\n- When possible, provide suggested_fixes with:\n  - target_snippet: the exact code to replace (same as issue_snippet usually)\n  - replacement_snippet: the replacement code\n  - title: clear description of the fix\n\nFocus on insights that require understanding code intent and context. Keep issue_snippet to the absolute minimum - just the problematic token.\n","user":"Analyze this python code for issues:\n\n```python\nimport typer\n\nfrom ai_lsp.finetune import cli as finetune_cli\n\napp = typer.Typer(name=\"ai-lsp\", help=\"AI-powered Language Server\")\n\n\napp.add_typer(finetune_cli.app, name=\"finetune\")\n\n\n@app.command()\ndef serve() -> None:\n    from ai_lsp import main\n    \n    main.app()\n\n\nif __name__ == \"__main__\":\n    app()\n\n```\n\nFile: cli.py","assistant":"{\n  \"issues\": [\n    {\n      \"issue_snippet\": \"from ai_lsp import main\",\n      \"severity\": \"warning\",\n      \"message\": \"The import of 'ai_lsp.main' is delayed until the 'serve' command is executed. While this can speed up initial CLI startup for other commands, it means any import errors or module-level issues within 'ai_lsp.main' will only be detected at runtime when 'serve' is invoked, rather than at application startup. For a critical command like 'serve', it's often better to surface such issues earlier to prevent runtime failures.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Move 'ai_lsp.main' import to the top-level\",\n          \"target_snippet\": \"from ai_lsp import main\",\n          \"replacement_snippet\": \"from ai_lsp import main\"\n        }\n      ]\n    }\n  ]\n}"}
{"system":"You are an AI code analyzer that provides semantic insights that traditional LSPs cannot detect.\n\nONLY flag issues that require deep semantic understanding:\n- Logic errors in algorithms or business logic\n- Subtle race conditions or concurrency issues  \n- Architectural problems and design pattern violations\n- Security vulnerabilities requiring context understanding\n- Performance anti-patterns that need semantic analysis\n- Complex data flow issues\n- Domain-specific best practice violations\n- Accessibility issues requiring UX understanding\n\nDO NOT flag issues that normal LSPs handle:\n- Syntax errors\n- Basic type errors  \n- Undefined variables\n- Import issues\n- Basic formatting problems\n- Simple linting rules\n\nFor each issue, provide:\n- The exact issue_snippet that has the problem (ONLY the problematic token\/value, e.g. just \"python\" not 'command = \"python\"')\n- Clear explanation of WHY this needs human attention in the message\n- Use severity: \"info\" for suggestions, \"warning\" for concerns, \"error\" for serious logic issues\n- When possible, provide suggested_fixes with:\n  - target_snippet: the exact code to replace (same as issue_snippet usually)\n  - replacement_snippet: the replacement code\n  - title: clear description of the fix\n\nFocus on insights that require understanding code intent and context. Keep issue_snippet to the absolute minimum - just the problematic token.\n","user":"Analyze this python code for issues:\n\n```python\nimport typer\n\nfrom ai_lsp.finetune import cli as finetune_cli\nfrom ai_lsp import main\n\napp = typer.Typer(\n    name=\"ai-lsp\",\n    help=\"AI-powered Language Server\",\n    no_args_is_help=True,\n    add_completion=True,\n)\n\n\napp.add_typer(finetune_cli.app, name=\"finetune\")\n\n\n@app.command()\ndef serve() -> None:\n    main.app()\n\n\nif __name__ == \"__main__\":\n    app()\n\n```\n\nFile: cli.py","assistant":"{\n  \"issues\": [\n    {\n      \"issue_snippet\": \"main.app()\",\n      \"severity\": \"warning\",\n      \"message\": \"The call to `main.app()` within the `serve` command suggests that `main.app` might be another `typer.Typer` instance. Executing a Typer application directly from within a subcommand of another Typer application is an unconventional pattern and can lead to unexpected behavior in argument parsing and command flow. It's generally better to integrate nested CLIs as subcommands using `app.add_typer()` or to have the called module (`ai_lsp.main`) expose a direct function for server startup (e.g., `main.start_server`) that this command can invoke.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Refactor `ai_lsp.main` to expose a dedicated server startup function\",\n          \"target_snippet\": \"main.app()\",\n          \"replacement_snippet\": \"main.start_server()\"\n        }\n      ]\n    }\n  ]\n}"}
{"system":"You are an AI code analyzer that provides semantic insights that traditional LSPs cannot detect.\n\nONLY flag issues that require deep semantic understanding:\n- Logic errors in algorithms or business logic\n- Subtle race conditions or concurrency issues  \n- Architectural problems and design pattern violations\n- Security vulnerabilities requiring context understanding\n- Performance anti-patterns that need semantic analysis\n- Complex data flow issues\n- Domain-specific best practice violations\n- Accessibility issues requiring UX understanding\n\nDO NOT flag issues that normal LSPs handle:\n- Syntax errors\n- Basic type errors  \n- Undefined variables\n- Import issues\n- Basic formatting problems\n- Simple linting rules\n\nFor each issue, provide:\n- The exact issue_snippet that has the problem (ONLY the problematic token\/value, e.g. just \"python\" not 'command = \"python\"')\n- Clear explanation of WHY this needs human attention in the message\n- Use severity: \"info\" for suggestions, \"warning\" for concerns, \"error\" for serious logic issues\n- When possible, provide suggested_fixes with:\n  - target_snippet: the exact code to replace (same as issue_snippet usually)\n  - replacement_snippet: the replacement code\n  - title: clear description of the fix\n\nFocus on insights that require understanding code intent and context. Keep issue_snippet to the absolute minimum - just the problematic token.\n","user":"Analyze this python code for issues:\n\n```python\nimport typer\n\nfrom ai_lsp.finetune import cli as finetune_cli\n\napp = typer.Typer(\n    name=\"ai-lsp\",\n    help=\"AI-powered Language Server\",\n    no_args_is_help=True,\n    add_completion=True,\n)\n\n\napp.add_typer(finetune_cli.app, name=\"finetune\")\n\n\n@app.command()\ndef serve() -> None:\n    from ai_lsp import main\n\n    main.app()\n\n\nif __name__ == \"__main__\":\n    app()\n\n```\n\nFile: cli.py","assistant":"{\n  \"issues\": [\n    {\n      \"issue_snippet\": \"from ai_lsp import main\",\n      \"severity\": \"warning\",\n      \"message\": \"The import of 'ai_lsp.main' is placed inside the `serve` function. While this can be a deliberate choice for performance optimization (e.g., to only load heavy dependencies when the command is used) or to resolve circular dependencies, it often signals an architectural pattern that warrants review. It can defer potential import errors to runtime, make module dependencies less explicit, and complicate understanding of module initialization and side effects. If not strictly necessary for performance or dependency management, consider moving the import to the top-level of the module for clarity and earlier error detection.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Move 'ai_lsp.main' import to module top-level\",\n          \"target_snippet\": \"from ai_lsp import main\",\n          \"replacement_snippet\": \"\"\n        }\n      ]\n    }\n  ]\n}"}
{"system":"You are an AI code analyzer that provides semantic insights that traditional LSPs cannot detect.\n\nONLY flag issues that require deep semantic understanding:\n- Logic errors in algorithms or business logic\n- Subtle race conditions or concurrency issues  \n- Architectural problems and design pattern violations\n- Security vulnerabilities requiring context understanding\n- Performance anti-patterns that need semantic analysis\n- Complex data flow issues\n- Domain-specific best practice violations\n- Accessibility issues requiring UX understanding\n\nDO NOT flag issues that normal LSPs handle:\n- Syntax errors\n- Basic type errors  \n- Undefined variables\n- Import issues\n- Basic formatting problems\n- Simple linting rules\n\nFor each issue, provide:\n- The exact issue_snippet that has the problem (ONLY the problematic token\/value, e.g. just \"python\" not 'command = \"python\"')\n- Clear explanation of WHY this needs human attention in the message\n- Use severity: \"info\" for suggestions, \"warning\" for concerns, \"error\" for serious logic issues\n- When possible, provide suggested_fixes with:\n  - target_snippet: the exact code to replace (same as issue_snippet usually)\n  - replacement_snippet: the replacement code\n  - title: clear description of the fix\n\nFocus on insights that require understanding code intent and context. Keep issue_snippet to the absolute minimum - just the problematic token.\n","user":"Analyze this python code for issues:\n\n```python\nimport typer\n\nfrom ai_lsp.finetune import cli as finetune_cli\n\napp = typer.Typer(\n    name=\"ai-lsp\",\n    help=\"AI-powered Language Server\",\n    no_args_is_help=True,\n    add_completion=True,\n)\n\n\napp.add_typer(finetune_cli.app, name=\"finetune\")\n\n\n@app.command()\ndef serve() -> None:\n    from ai_lsp import main\n\n    main.app()\n\n\nif __name__ == \"__main__\":\n    app()\n\n```\n\nFile: cli.py","assistant":"{\n  \"issues\": [\n    {\n      \"issue_snippet\": \"from ai_lsp import main\",\n      \"severity\": \"warning\",\n      \"message\": \"The import statement for 'main' is placed inside the 'serve' function. This is a local import, which can defer the cost of importing the 'main' module until the 'serve' command is executed. While this can sometimes be used for performance optimization in rarely used commands or to break circular dependencies, for a core command like 'serve', it often introduces unclear dependencies and can hide potential startup performance issues of the 'main' module itself. It's generally better for clarity and consistency to place all imports at the top of the file.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Move import to top-level\",\n          \"target_snippet\": \"from ai_lsp import main\",\n          \"replacement_snippet\": \"from ai_lsp import main # Moved to top-level for better clarity and consistent dependency loading\"\n        }\n      ]\n    }\n  ]\n}"}
{"system":"You are an AI code analyzer that provides semantic insights that traditional LSPs cannot detect.\n\nONLY flag issues that require deep semantic understanding:\n- Logic errors in algorithms or business logic\n- Subtle race conditions or concurrency issues  \n- Architectural problems and design pattern violations\n- Security vulnerabilities requiring context understanding\n- Performance anti-patterns that need semantic analysis\n- Complex data flow issues\n- Domain-specific best practice violations\n- Accessibility issues requiring UX understanding\n\nDO NOT flag issues that normal LSPs handle:\n- Syntax errors\n- Basic type errors  \n- Undefined variables\n- Import issues\n- Basic formatting problems\n- Simple linting rules\n\nFor each issue, provide:\n- The exact issue_snippet that has the problem (ONLY the problematic token\/value, e.g. just \"python\" not 'command = \"python\"')\n- Clear explanation of WHY this needs human attention in the message\n- Use severity: \"info\" for suggestions, \"warning\" for concerns, \"error\" for serious logic issues\n- When possible, provide suggested_fixes with:\n  - target_snippet: the exact code to replace (same as issue_snippet usually)\n  - replacement_snippet: the replacement code\n  - title: clear description of the fix\n\nFocus on insights that require understanding code intent and context. Keep issue_snippet to the absolute minimum - just the problematic token.\n","user":"Analyze this python code for issues:\n\n```python\nimport typer\n\nfrom ai_lsp.finetune import cli as finetune_cli\n\nfrom ai_lsp import app\n\napp = typer.Typer(\n    name=\"ai-lsp\",\n    help=\"AI-powered Language Server\",\n    no_args_is_help=True,\n    add_completion=True,\n)\n\n\napp.add_typer(finetune_cli.app, name=\"finetune\")\n\n\n@app.command()\ndef serve() -> None:\n    app()\n\n\nif __name__ == \"__main__\":\n    app()\n\n```\n\nFile: cli.py","assistant":"{\n  \"issues\": [\n    {\n      \"issue_snippet\": \"app()\",\n      \"severity\": \"error\",\n      \"message\": \"Calling `app()` inside a Typer command function will cause the Typer application to be executed recursively or redundantly. Typer commands are meant to perform their specific logic, not re-dispatch the CLI application. The main application dispatch should only happen once, typically in the `if __name__ == \\\"__main__\\\":` block.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Remove the redundant app() call.\",\n          \"target_snippet\": \"app()\",\n          \"replacement_snippet\": \"# Your serve logic here (e.g., start a server)\"\n        }\n      ]\n    }\n  ]\n}"}
{"system":"You are an AI code analyzer that provides semantic insights that traditional LSPs cannot detect.\n\nONLY flag issues that require deep semantic understanding:\n- Logic errors in algorithms or business logic\n- Subtle race conditions or concurrency issues  \n- Architectural problems and design pattern violations\n- Security vulnerabilities requiring context understanding\n- Performance anti-patterns that need semantic analysis\n- Complex data flow issues\n- Domain-specific best practice violations\n- Accessibility issues requiring UX understanding\n\nDO NOT flag issues that normal LSPs handle:\n- Syntax errors\n- Basic type errors  \n- Undefined variables\n- Import issues\n- Basic formatting problems\n- Simple linting rules\n\nFor each issue, provide:\n- The exact issue_snippet that has the problem (ONLY the problematic token\/value, e.g. just \"python\" not 'command = \"python\"')\n- Clear explanation of WHY this needs human attention in the message\n- Use severity: \"info\" for suggestions, \"warning\" for concerns, \"error\" for serious logic issues\n- When possible, provide suggested_fixes with:\n  - target_snippet: the exact code to replace (same as issue_snippet usually)\n  - replacement_snippet: the replacement code\n  - title: clear description of the fix\n\nFocus on insights that require understanding code intent and context. Keep issue_snippet to the absolute minimum - just the problematic token.\n","user":"Analyze this python code for issues:\n\n```python\nimport typer\n\nfrom ai_lsp.finetune import cli as finetune_cli\n\nfrom ai_lsp.main import app\n\napp = typer.Typer(\n    name=\"ai-lsp\",\n    help=\"AI-powered Language Server\",\n    no_args_is_help=True,\n    add_completion=True,\n)\n\n\napp.add_typer(finetune_cli.app, name=\"finetune\")\n\n\n@app.command()\ndef serve() -> None:\n    app()\n\n\nif __name__ == \"__main__\":\n    app()\n\n```\n\nFile: cli.py","assistant":"{\n  \"issues\": [\n    {\n      \"issue_snippet\": \"app\",\n      \"severity\": \"error\",\n      \"message\": \"The variable 'app' is imported from 'ai_lsp.main' and then immediately redefined by a new 'typer.Typer' instance. This overwrites the imported 'app', rendering it unused and potentially causing its configurations or commands to be lost. This suggests either an unnecessary import or an architectural conflict regarding the primary 'typer.Typer' application instance.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Remove unused import if this module intends to define the main 'app'\",\n          \"target_snippet\": \"from ai_lsp.main import app\",\n          \"replacement_snippet\": \"# from ai_lsp.main import app\"\n        },\n        {\n          \"title\": \"Remove redefinition and use the 'app' instance imported from 'ai_lsp.main'\",\n          \"target_snippet\": \"app = typer.Typer(\\n    name=\\\"ai-lsp\\\",\\n    help=\\\"AI-powered Language Server\\\",\\n    no_args_is_help=True,\\n    add_completion=True,\\n)\",\n          \"replacement_snippet\": \"\"\n        }\n      ]\n    },\n    {\n      \"issue_snippet\": \"app()\",\n      \"severity\": \"error\",\n      \"message\": \"A Typer command function (like 'serve') is intended to execute specific logic for that command, not to re-run the entire Typer application. Calling 'app()' within a command will lead to recursive invocation or incorrect behavior, as the CLI is already running to execute the 'serve' command.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Replace 'app()' with the actual serving logic for the 'serve' command\",\n          \"target_snippet\": \"app()\",\n          \"replacement_snippet\": \"# Add serving logic here, e.g., start a server\\n    print(\\\"Starting AI-LSP server...\\\")\"\n        }\n      ]\n    }\n  ]\n}"}
{"system":"You are an AI code analyzer that provides semantic insights that traditional LSPs cannot detect.\n\nONLY flag issues that require deep semantic understanding:\n- Logic errors in algorithms or business logic\n- Subtle race conditions or concurrency issues  \n- Architectural problems and design pattern violations\n- Security vulnerabilities requiring context understanding\n- Performance anti-patterns that need semantic analysis\n- Complex data flow issues\n- Domain-specific best practice violations\n- Accessibility issues requiring UX understanding\n\nDO NOT flag issues that normal LSPs handle:\n- Syntax errors\n- Basic type errors  \n- Undefined variables\n- Import issues\n- Basic formatting problems\n- Simple linting rules\n\nFor each issue, provide:\n- The exact issue_snippet that has the problem (ONLY the problematic token\/value, e.g. just \"python\" not 'command = \"python\"')\n- Clear explanation of WHY this needs human attention in the message\n- Use severity: \"info\" for suggestions, \"warning\" for concerns, \"error\" for serious logic issues\n- When possible, provide suggested_fixes with:\n  - target_snippet: the exact code to replace (same as issue_snippet usually)\n  - replacement_snippet: the replacement code\n  - title: clear description of the fix\n\nFocus on insights that require understanding code intent and context. Keep issue_snippet to the absolute minimum - just the problematic token.\n","user":"Analyze this python code for issues:\n\n```python\nimport typer\n\nfrom ai_lsp.finetune import cli as finetune_cli\n\nfrom ai_lsp.main import server\n\nserver = typer.Typer(\n    name=\"ai-lsp\",\n    help=\"AI-powered Language Server\",\n    no_args_is_help=True,\n    add_completion=True,\n)\n\n\napp.add_typer(finetune_cli.app, name=\"finetune\")\n\n\n@app.command()\ndef serve() -> None:\n    server()\n\n\nif __name__ == \"__main__\":\n    app()\n\n```\n\nFile: cli.py","assistant":"{\n  \"issues\": [\n    {\n      \"issue_snippet\": \"server\",\n      \"severity\": \"error\",\n      \"message\": \"The main `typer.Typer` application is assigned to the variable `server`, but later operations (e.g., `app.add_typer`, `@app.command()`, `app()`) incorrectly refer to an undefined variable `app`. This inconsistency will lead to a `NameError`. It's best practice to consistently name the main `typer.Typer` instance, typically `app`.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Rename the main Typer application variable for consistency\",\n          \"target_snippet\": \"server\",\n          \"replacement_snippet\": \"app\"\n        }\n      ]\n    },\n    {\n      \"issue_snippet\": \"server()\",\n      \"severity\": \"warning\",\n      \"message\": \"Within the `serve` command, `server()` is called. After applying the suggested fix to rename the `typer.Typer` instance to `app`, this `server` refers to the imported `server` object from `ai_lsp.main`. Most server libraries require calling a specific method (e.g., `server.run()`, `server.start()`, `server.serve()`) to correctly initiate the server process, rather than calling the object directly. Calling `server()` might not start the LSP server as intended. Please verify the `ai_lsp.main.server` API.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Consider using a specific method to start the imported server\",\n          \"target_snippet\": \"server()\",\n          \"replacement_snippet\": \"server.run()\"\n        }\n      ]\n    }\n  ]\n}"}
{"system":"You are an AI code analyzer that provides semantic insights that traditional LSPs cannot detect.\n\nONLY flag issues that require deep semantic understanding:\n- Logic errors in algorithms or business logic\n- Subtle race conditions or concurrency issues  \n- Architectural problems and design pattern violations\n- Security vulnerabilities requiring context understanding\n- Performance anti-patterns that need semantic analysis\n- Complex data flow issues\n- Domain-specific best practice violations\n- Accessibility issues requiring UX understanding\n\nDO NOT flag issues that normal LSPs handle:\n- Syntax errors\n- Basic type errors  \n- Undefined variables\n- Import issues\n- Basic formatting problems\n- Simple linting rules\n\nFor each issue, provide:\n- The exact issue_snippet that has the problem (ONLY the problematic token\/value, e.g. just \"python\" not 'command = \"python\"')\n- Clear explanation of WHY this needs human attention in the message\n- Use severity: \"info\" for suggestions, \"warning\" for concerns, \"error\" for serious logic issues\n- When possible, provide suggested_fixes with:\n  - target_snippet: the exact code to replace (same as issue_snippet usually)\n  - replacement_snippet: the replacement code\n  - title: clear description of the fix\n\nFocus on insights that require understanding code intent and context. Keep issue_snippet to the absolute minimum - just the problematic token.\n","user":"Analyze this python code for issues:\n\n```python\nimport typer\n\nfrom ai_lsp.finetune import cli as finetune_cli\n\nfrom ai_lsp.main import server\n\nserver = typer.Typer(\n    name=\"ai-lsp\",\n    help=\"AI-powered Language Server\",\n    no_args_is_help=True,\n    add_completion=True,\n)\n\n\napp.add_typer(finetune_cli.app, name=\"finetune\")\n\n\n@app.command()\ndef serve() -> None:\n    server.start_io()\n\n\nif __name__ == \"__main__\":\n    app()\n\n```\n\nFile: cli.py","assistant":"{\n  \"issues\": [\n    {\n      \"issue_snippet\": \"app\",\n      \"severity\": \"error\",\n      \"message\": \"The 'app' variable is used before it is defined. The main Typer application instance is named 'server', but the code attempts to add subcommands and define commands using an undefined 'app' variable. This indicates a naming inconsistency or a logic error in how the CLI application is being constructed.\",\n      \"suggested_fixes\": [\n        {\n          \"title\": \"Use the defined 'server' instance instead of 'app'\",\n          \"target_snippet\": \"app\",\n          \"replacement_snippet\": \"server\"\n        }\n      ]\n    }\n  ]\n}"}
